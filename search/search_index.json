{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to Hyperledger Fabric\n\n\nHyperledger Fabric is a platform for distributed ledger solutions,\nunderpinned by a modular architecture delivering high degrees of\nconfidentiality, resiliency, flexibility and scalability. It is designed\nto support pluggable implementations of different components, and\naccommodate the complexity and intricacies that exist across the\neconomic ecosystem.\n\n\nHyperledger Fabric delivers a uniquely elastic and extensible\narchitecture, distinguishing it from alternative blockchain solutions.\nPlanning for the future of enterprise blockchain requires building on\ntop of a fully-vetted, open source architecture; Hyperledger Fabric is\nyour starting point.\n\n\nIt's recommended for first-time users to begin by going through the\n\nGetting Started\n section in order to gain familiarity with\nthe Hyperledger Fabric components and the basic transaction flow. Once\ncomfortable, continue exploring the library for demos, technical\nspecifications, APIs, etc.\n\n\n!!! warning \"Getting Additional Help\"\n    If you have questions not addressed by this documentation, or run into\n    issues with any of the tutorials, please visit the\n    \nStill Have Questions\n page for some tips on where to find\n    additional help.\n\n\nBefore diving in, watch how Hyperledger Fabric is Building a Blockchain\nfor Business:\n\n\n\n\n\n\n\nThis work is licensed under a \nCreative Commons Attribution 4.0 International License", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome-to-hyperledger-fabric", 
            "text": "Hyperledger Fabric is a platform for distributed ledger solutions,\nunderpinned by a modular architecture delivering high degrees of\nconfidentiality, resiliency, flexibility and scalability. It is designed\nto support pluggable implementations of different components, and\naccommodate the complexity and intricacies that exist across the\neconomic ecosystem.  Hyperledger Fabric delivers a uniquely elastic and extensible\narchitecture, distinguishing it from alternative blockchain solutions.\nPlanning for the future of enterprise blockchain requires building on\ntop of a fully-vetted, open source architecture; Hyperledger Fabric is\nyour starting point.  It's recommended for first-time users to begin by going through the Getting Started  section in order to gain familiarity with\nthe Hyperledger Fabric components and the basic transaction flow. Once\ncomfortable, continue exploring the library for demos, technical\nspecifications, APIs, etc.  !!! warning \"Getting Additional Help\"\n    If you have questions not addressed by this documentation, or run into\n    issues with any of the tutorials, please visit the\n     Still Have Questions  page for some tips on where to find\n    additional help.  Before diving in, watch how Hyperledger Fabric is Building a Blockchain\nfor Business:    This work is licensed under a  Creative Commons Attribution 4.0 International License", 
            "title": "Welcome to Hyperledger Fabric"
        }, 
        {
            "location": "/blockchain/", 
            "text": "Introduction\n\n\nHyperledger Fabric is a platform for distributed ledger solutions\nunderpinned by a modular architecture delivering high degrees of\nconfidentiality, resiliency, flexibility and scalability. It is designed\nto support pluggable implementations of different components and\naccommodate the complexity and intricacies that exist across the\neconomic ecosystem.\n\n\nHyperledger Fabric delivers a uniquely elastic and extensible\narchitecture, distinguishing it from alternative blockchain solutions.\nPlanning for the future of enterprise blockchain requires building on\ntop of a fully vetted, open-source architecture; Hyperledger Fabric is\nyour starting point.\n\n\nWe recommended first-time users begin by going through the rest of the\nintroduction below in order to gain familiarity with how blockchains\nwork and with the specific features and components of Hyperledger\nFabric.\n\n\nOnce comfortable -- or if you\\'re already familiar with blockchain and\nHyperledger Fabric -- go to \nGetting Started\n and from\nthere explore the demos, technical specifications, APIs, etc.\n\n\nWhat is a Blockchain?\n\n\nA Distributed Ledger\n\n\nAt the heart of a blockchain network is a distributed ledger that\nrecords all the transactions that take place on the network.\n\n\nA blockchain ledger is often described as \ndecentralized\n because it\nis replicated across many network participants, each of whom\n\ncollaborate\n in its maintenance. We'll see that decentralization and\ncollaboration are powerful attributes that mirror the way businesses\nexchange goods and services in the real world.\n\n\n\n\nIn addition to being decentralized and collaborative, the information\nrecorded to a blockchain is append-only, using cryptographic techniques\nthat guarantee that once a transaction has been added to the ledger it\ncannot be modified. This property of immutability makes it simple to\ndetermine the provenance of information because participants can be sure\ninformation has not been changed after the fact. It's why blockchains\nare sometimes described as \nsystems of proof\n.\n\n\n*\nSmart Contracts\n*\n\n\nTo support the consistent update of information -- and to enable a whole\nhost of ledger functions (transacting, querying, etc) -- a blockchain\nnetwork uses \nsmart contracts\n to provide controlled access to the\nledger.\n\n\n\n\nSmart contracts are not only a key mechanism for encapsulating\ninformation and keeping it simple across the network, they can also be\nwritten to allow participants to execute certain aspects of transactions\nautomatically.\n\n\nA smart contract can, for example, be written to stipulate the cost of\nshipping an item that changes depending on when it arrives. With the\nterms agreed to by both parties and written to the ledger, the\nappropriate funds change hands automatically when the item is received.\n\n\nConsensus\n\n\nThe process of keeping the ledger transactions synchronized across the\nnetwork -- to ensure that ledgers only update when transactions are\napproved by the appropriate participants, and that when ledgers do\nupdate, they update with the same transactions in the same order -- is\ncalled \nconsensus\n.\n\n\n\n\nWe'll learn a lot more about ledgers, smart contracts and consensus\nlater. For now, it's enough to think of a blockchain as a shared,\nreplicated transaction system which is updated via smart contracts and\nkept consistently synchronized through a collaborative process called\nconsensus.\n\n\nWhy is a Blockchain useful?\n\n\nToday's Systems of Record\n\n\nThe transactional networks of today are little more than slightly\nupdated versions of networks that have existed since business records\nhave been kept. The members of a \nBusiness Network\n transact with each\nother, but they maintain separate records of their transactions. And the\nthings they're transacting -- whether it's Flemish tapestries in the\n16th century or the securities of today -- must have their provenance\nestablished each time they're sold to ensure that the business selling\nan item possesses a chain of title verifying their ownership of it.\n\n\nWhat you're left with is a business network that looks like this:\n\n\n\n\nModern technology has taken this process from stone tablets and paper\nfolders to hard drives and cloud platforms, but the underlying structure\nis the same. Unified systems for managing the identity of network\nparticipants do not exist, establishing provenance is so laborious it\ntakes days to clear securities transactions (the world volume of which\nis numbered in the many trillions of dollars), contracts must be signed\nand executed manually, and every database in the system contains unique\ninformation and therefore represents a single point of failure.\n\n\nIt's impossible with today's fractured approach to information and\nprocess sharing to build a system of record that spans a business\nnetwork, even though the needs of visibility and trust are clear.\n\n\nThe Blockchain Difference\n\n\nWhat if instead of the rat's nest of inefficiencies represented by the\n\"modern\" system of transactions, business networks had standard methods\nfor establishing identity on the network, executing transactions, and\nstoring data? What if establishing the provenance of an asset could be\ndetermined by looking through a list of transactions that, once written,\ncannot be changed, and can therefore be trusted?\n\n\nThat business network would look more like this:\n\n\n\n\nThis is a blockchain network. Every participant in it has their own\nreplicated copy of the ledger. In addition to ledger information being\nshared, the processes which update the ledger are also shared. Unlike\ntoday's systems, where a participant's \nprivate\n programs are used to\nupdate their \nprivate\n ledgers, a blockchain system has \nshared\n\nprograms to update \nshared\n ledgers.\n\n\nWith the ability to coordinate their business network through a shared\nledger, blockchain networks can reduce the time, cost, and risk\nassociated with private information and processing while improving trust\nand visibility.\n\n\nYou now know what blockchain is and why it's useful. There are a lot of\nother details that are important, but they all relate to these\nfundamental ideas of the sharing of information and processes.\n\n\nWhat is Hyperledger Fabric?\n\n\nThe Linux Foundation founded Hyperledger in 2015 to advance\ncross-industry blockchain technologies. Rather than declaring a single\nblockchain standard, it encourages a collaborative approach to\ndeveloping blockchain technologies via a community process, with\nintellectual property rights that encourage open development and the\nadoption of key standards over time.\n\n\nHyperledger Fabric is one of the blockchain projects within Hyperledger.\nLike other blockchain technologies, it has a ledger, uses smart\ncontracts, and is a system by which participants manage their\ntransactions.\n\n\nWhere Hyperledger Fabric breaks from some other blockchain systems is\nthat it is \nprivate\n and \npermissioned\n. Rather than an open\npermissionless system that allows unknown identities to participate in\nthe network (requiring protocols like Proof of Work to validate\ntransactions and secure the network), the members of a Hyperledger\nFabric network enroll through a \nMembership Service Provider (MSP)\n.\n\n\nHyperledger Fabric also offers several pluggable options. Ledger data\ncan be stored in multiple formats, consensus mechanisms can be switched\nin and out, and different MSPs are supported.\n\n\nHyperledger Fabric also offers the ability to create \nchannels\n,\nallowing a group of participants to create a separate ledger of\ntransactions. This is an especially important option for networks where\nsome participants might be competitors and not want every transaction\nthey make - a special price they\\'re offering to some participants and\nnot others, for example - known to every participant. If two\nparticipants form a channel, then those participants -- and no others --\nhave copies of the ledger for that channel.\n\n\nShared Ledger\n\n\nHyperledger Fabric has a ledger subsystem comprising two components: the\n\nworld state\n and the \ntransaction log\n. Each participant has a copy\nof the ledger to every Hyperledger Fabric network they belong to.\n\n\nThe world state component describes the state of the ledger at a given\npoint in time. It's the database of the ledger. The transaction log\ncomponent records all transactions which have resulted in the current\nvalue of the world state. It's the update history for the world state.\nThe ledger, then, is a combination of the world state database and the\ntransaction log history.\n\n\nThe ledger has a replaceable data store for the world state. By default,\nthis is a LevelDB key-value store database. The transaction log does not\nneed to be pluggable. It simply records the before and after values of\nthe ledger database being used by the blockchain network.\n\n\nSmart Contracts\n\n\nHyperledger Fabric smart contracts are written in \nchaincode\n and are\ninvoked by an application external to the blockchain when that\napplication needs to interact with the ledger. In most cases chaincode\nonly interacts with the database component of the ledger, the world\nstate (querying it, for example), and not the transaction log.\n\n\nChaincode can be implemented in several programming languages. The\ncurrently supported chaincode language is \nGo\n with\nsupport for Java and other languages coming in future releases.\n\n\nPrivacy\n\n\nDepending on the needs of a network, participants in a\nBusiness-to-Business (B2B) network might be extremely sensitive about\nhow much information they share. For other networks, privacy will not be\na top concern.\n\n\nHyperledger Fabric supports networks where privacy (using channels) is a\nkey operational requirement as well as networks that are comparatively\nopen.\n\n\nConsensus\n\n\nTransactions must be written to the ledger in the order in which they\noccur, even though they might be between different sets of participants\nwithin the network. For this to happen, the order of transactions must\nbe established and a method for rejecting bad transactions that have\nbeen inserted into the ledger in error (or maliciously) must be put into\nplace.\n\n\nThis is a thoroughly researched area of computer science, and there are\nmany ways to achieve it, each with different trade-offs. For example,\nPBFT (Practical Byzantine Fault Tolerance) can provide a mechanism for\nfile replicas to communicate with each other to keep each copy\nconsistent, even in the event of corruption. Alternatively, in Bitcoin,\nordering happens through a process called mining where competing\ncomputers race to solve a cryptographic puzzle which defines the order\nthat all processes subsequently build upon.\n\n\nHyperledger Fabric has been designed to allow network starters to choose\na consensus mechanism that best represents the relationships that exist\nbetween participants. As with privacy, there is a spectrum of needs;\nfrom networks that are highly structured in their relationships to those\nthat are more peer-to-peer.\n\n\nWe'll learn more about the Hyperledger Fabric consensus mechanisms,\nwhich currently include SOLO, Kafka, and will soon extend to SBFT\n(Simplified Byzantine Fault Tolerance), in another document.\n\n\nWhere can I learn more?\n\n\nWe provide a number of \ntutorials\n and \nsamples\n where you'll be introduced to most of\nthe key components within a blockchain network, learn more about how\nthey interact with each other, and then you'll actually get the code and\nrun some simple transactions against a running blockchain network. We\nalso provide tutorials for those of you thinking of operating a\nblockchain network using Hyperledger Fabric.\n\n\nA \ndeeper look\n at the components and concepts brought up in this\nintroduction as well as a few others and describes how they work\ntogether in a sample transaction flow.", 
            "title": "Key blockchain concepts"
        }, 
        {
            "location": "/blockchain/#introduction", 
            "text": "Hyperledger Fabric is a platform for distributed ledger solutions\nunderpinned by a modular architecture delivering high degrees of\nconfidentiality, resiliency, flexibility and scalability. It is designed\nto support pluggable implementations of different components and\naccommodate the complexity and intricacies that exist across the\neconomic ecosystem.  Hyperledger Fabric delivers a uniquely elastic and extensible\narchitecture, distinguishing it from alternative blockchain solutions.\nPlanning for the future of enterprise blockchain requires building on\ntop of a fully vetted, open-source architecture; Hyperledger Fabric is\nyour starting point.  We recommended first-time users begin by going through the rest of the\nintroduction below in order to gain familiarity with how blockchains\nwork and with the specific features and components of Hyperledger\nFabric.  Once comfortable -- or if you\\'re already familiar with blockchain and\nHyperledger Fabric -- go to  Getting Started  and from\nthere explore the demos, technical specifications, APIs, etc.", 
            "title": "Introduction"
        }, 
        {
            "location": "/blockchain/#what-is-a-blockchain", 
            "text": "A Distributed Ledger  At the heart of a blockchain network is a distributed ledger that\nrecords all the transactions that take place on the network.  A blockchain ledger is often described as  decentralized  because it\nis replicated across many network participants, each of whom collaborate  in its maintenance. We'll see that decentralization and\ncollaboration are powerful attributes that mirror the way businesses\nexchange goods and services in the real world.   In addition to being decentralized and collaborative, the information\nrecorded to a blockchain is append-only, using cryptographic techniques\nthat guarantee that once a transaction has been added to the ledger it\ncannot be modified. This property of immutability makes it simple to\ndetermine the provenance of information because participants can be sure\ninformation has not been changed after the fact. It's why blockchains\nare sometimes described as  systems of proof .  * Smart Contracts *  To support the consistent update of information -- and to enable a whole\nhost of ledger functions (transacting, querying, etc) -- a blockchain\nnetwork uses  smart contracts  to provide controlled access to the\nledger.   Smart contracts are not only a key mechanism for encapsulating\ninformation and keeping it simple across the network, they can also be\nwritten to allow participants to execute certain aspects of transactions\nautomatically.  A smart contract can, for example, be written to stipulate the cost of\nshipping an item that changes depending on when it arrives. With the\nterms agreed to by both parties and written to the ledger, the\nappropriate funds change hands automatically when the item is received.  Consensus  The process of keeping the ledger transactions synchronized across the\nnetwork -- to ensure that ledgers only update when transactions are\napproved by the appropriate participants, and that when ledgers do\nupdate, they update with the same transactions in the same order -- is\ncalled  consensus .   We'll learn a lot more about ledgers, smart contracts and consensus\nlater. For now, it's enough to think of a blockchain as a shared,\nreplicated transaction system which is updated via smart contracts and\nkept consistently synchronized through a collaborative process called\nconsensus.", 
            "title": "What is a Blockchain?"
        }, 
        {
            "location": "/blockchain/#why-is-a-blockchain-useful", 
            "text": "Today's Systems of Record  The transactional networks of today are little more than slightly\nupdated versions of networks that have existed since business records\nhave been kept. The members of a  Business Network  transact with each\nother, but they maintain separate records of their transactions. And the\nthings they're transacting -- whether it's Flemish tapestries in the\n16th century or the securities of today -- must have their provenance\nestablished each time they're sold to ensure that the business selling\nan item possesses a chain of title verifying their ownership of it.  What you're left with is a business network that looks like this:   Modern technology has taken this process from stone tablets and paper\nfolders to hard drives and cloud platforms, but the underlying structure\nis the same. Unified systems for managing the identity of network\nparticipants do not exist, establishing provenance is so laborious it\ntakes days to clear securities transactions (the world volume of which\nis numbered in the many trillions of dollars), contracts must be signed\nand executed manually, and every database in the system contains unique\ninformation and therefore represents a single point of failure.  It's impossible with today's fractured approach to information and\nprocess sharing to build a system of record that spans a business\nnetwork, even though the needs of visibility and trust are clear.  The Blockchain Difference  What if instead of the rat's nest of inefficiencies represented by the\n\"modern\" system of transactions, business networks had standard methods\nfor establishing identity on the network, executing transactions, and\nstoring data? What if establishing the provenance of an asset could be\ndetermined by looking through a list of transactions that, once written,\ncannot be changed, and can therefore be trusted?  That business network would look more like this:   This is a blockchain network. Every participant in it has their own\nreplicated copy of the ledger. In addition to ledger information being\nshared, the processes which update the ledger are also shared. Unlike\ntoday's systems, where a participant's  private  programs are used to\nupdate their  private  ledgers, a blockchain system has  shared \nprograms to update  shared  ledgers.  With the ability to coordinate their business network through a shared\nledger, blockchain networks can reduce the time, cost, and risk\nassociated with private information and processing while improving trust\nand visibility.  You now know what blockchain is and why it's useful. There are a lot of\nother details that are important, but they all relate to these\nfundamental ideas of the sharing of information and processes.", 
            "title": "Why is a Blockchain useful?"
        }, 
        {
            "location": "/blockchain/#what-is-hyperledger-fabric", 
            "text": "The Linux Foundation founded Hyperledger in 2015 to advance\ncross-industry blockchain technologies. Rather than declaring a single\nblockchain standard, it encourages a collaborative approach to\ndeveloping blockchain technologies via a community process, with\nintellectual property rights that encourage open development and the\nadoption of key standards over time.  Hyperledger Fabric is one of the blockchain projects within Hyperledger.\nLike other blockchain technologies, it has a ledger, uses smart\ncontracts, and is a system by which participants manage their\ntransactions.  Where Hyperledger Fabric breaks from some other blockchain systems is\nthat it is  private  and  permissioned . Rather than an open\npermissionless system that allows unknown identities to participate in\nthe network (requiring protocols like Proof of Work to validate\ntransactions and secure the network), the members of a Hyperledger\nFabric network enroll through a  Membership Service Provider (MSP) .  Hyperledger Fabric also offers several pluggable options. Ledger data\ncan be stored in multiple formats, consensus mechanisms can be switched\nin and out, and different MSPs are supported.  Hyperledger Fabric also offers the ability to create  channels ,\nallowing a group of participants to create a separate ledger of\ntransactions. This is an especially important option for networks where\nsome participants might be competitors and not want every transaction\nthey make - a special price they\\'re offering to some participants and\nnot others, for example - known to every participant. If two\nparticipants form a channel, then those participants -- and no others --\nhave copies of the ledger for that channel.  Shared Ledger  Hyperledger Fabric has a ledger subsystem comprising two components: the world state  and the  transaction log . Each participant has a copy\nof the ledger to every Hyperledger Fabric network they belong to.  The world state component describes the state of the ledger at a given\npoint in time. It's the database of the ledger. The transaction log\ncomponent records all transactions which have resulted in the current\nvalue of the world state. It's the update history for the world state.\nThe ledger, then, is a combination of the world state database and the\ntransaction log history.  The ledger has a replaceable data store for the world state. By default,\nthis is a LevelDB key-value store database. The transaction log does not\nneed to be pluggable. It simply records the before and after values of\nthe ledger database being used by the blockchain network.  Smart Contracts  Hyperledger Fabric smart contracts are written in  chaincode  and are\ninvoked by an application external to the blockchain when that\napplication needs to interact with the ledger. In most cases chaincode\nonly interacts with the database component of the ledger, the world\nstate (querying it, for example), and not the transaction log.  Chaincode can be implemented in several programming languages. The\ncurrently supported chaincode language is  Go  with\nsupport for Java and other languages coming in future releases.  Privacy  Depending on the needs of a network, participants in a\nBusiness-to-Business (B2B) network might be extremely sensitive about\nhow much information they share. For other networks, privacy will not be\na top concern.  Hyperledger Fabric supports networks where privacy (using channels) is a\nkey operational requirement as well as networks that are comparatively\nopen.  Consensus  Transactions must be written to the ledger in the order in which they\noccur, even though they might be between different sets of participants\nwithin the network. For this to happen, the order of transactions must\nbe established and a method for rejecting bad transactions that have\nbeen inserted into the ledger in error (or maliciously) must be put into\nplace.  This is a thoroughly researched area of computer science, and there are\nmany ways to achieve it, each with different trade-offs. For example,\nPBFT (Practical Byzantine Fault Tolerance) can provide a mechanism for\nfile replicas to communicate with each other to keep each copy\nconsistent, even in the event of corruption. Alternatively, in Bitcoin,\nordering happens through a process called mining where competing\ncomputers race to solve a cryptographic puzzle which defines the order\nthat all processes subsequently build upon.  Hyperledger Fabric has been designed to allow network starters to choose\na consensus mechanism that best represents the relationships that exist\nbetween participants. As with privacy, there is a spectrum of needs;\nfrom networks that are highly structured in their relationships to those\nthat are more peer-to-peer.  We'll learn more about the Hyperledger Fabric consensus mechanisms,\nwhich currently include SOLO, Kafka, and will soon extend to SBFT\n(Simplified Byzantine Fault Tolerance), in another document.", 
            "title": "What is Hyperledger Fabric?"
        }, 
        {
            "location": "/blockchain/#where-can-i-learn-more", 
            "text": "We provide a number of  tutorials  and  samples  where you'll be introduced to most of\nthe key components within a blockchain network, learn more about how\nthey interact with each other, and then you'll actually get the code and\nrun some simple transactions against a running blockchain network. We\nalso provide tutorials for those of you thinking of operating a\nblockchain network using Hyperledger Fabric.  A  deeper look  at the components and concepts brought up in this\nintroduction as well as a few others and describes how they work\ntogether in a sample transaction flow.", 
            "title": "Where can I learn more?"
        }, 
        {
            "location": "/fabric-sdks/", 
            "text": "Hyperledger Fabric SDKs\n\n\nHyperledger Fabric intends to offer a number of SDKs for a wide variety\nof programming languages. The first two delivered are the Node.js and\nJava SDKs. We hope to provide Python and Go SDKs soon after the 1.0.0\nrelease.\n\n\n\n\n\n\nHyperledger Fabric Node SDK\n    documentation\n.\n\n\nHyperledger Fabric Java SDK\n    documentation\n.", 
            "title": "Applications and the Hyperledger Fabric SDKs"
        }, 
        {
            "location": "/fabric-sdks/#hyperledger-fabric-sdks", 
            "text": "Hyperledger Fabric intends to offer a number of SDKs for a wide variety\nof programming languages. The first two delivered are the Node.js and\nJava SDKs. We hope to provide Python and Go SDKs soon after the 1.0.0\nrelease.    Hyperledger Fabric Node SDK\n    documentation .  Hyperledger Fabric Java SDK\n    documentation .", 
            "title": "Hyperledger Fabric SDKs"
        }, 
        {
            "location": "/chaincode/", 
            "text": "Chaincode Tutorials\n\n\nWhat is Chaincode?\n\n\nChaincode is a program, written in \nGo\n,\n\nnode.js\n, and eventually in other programming\nlanguages such as Java, that implements a prescribed interface.\nChaincode runs in a secured Docker container isolated from the endorsing\npeer process. Chaincode initializes and manages ledger state through\ntransactions submitted by applications.\n\n\nA chaincode typically handles business logic agreed to by members of the\nnetwork, so it may be considered as a \\\"smart contract\\\". State created\nby a chaincode is scoped exclusively to that chaincode and can\\'t be\naccessed directly by another chaincode. However, within the same\nnetwork, given the appropriate permission a chaincode may invoke another\nchaincode to access its state.\n\n\nTwo Personas\n\n\nWe offer two different perspectives on chaincode. One, from the\nperspective of an application developer developing a blockchain\napplication/solution entitled [chaincode4ade]{role=\"doc\"}, and the\nother, [chaincode4noah]{role=\"doc\"} oriented to the blockchain network\noperator who is responsible for managing a blockchain network, and who\nwould leverage the Hyperledger Fabric API to install, instantiate, and\nupgrade chaincode, but would likely not be involved in the development\nof a chaincode application.", 
            "title": "Programming Smart contracts and Chaincode"
        }, 
        {
            "location": "/chaincode/#chaincode-tutorials", 
            "text": "", 
            "title": "Chaincode Tutorials"
        }, 
        {
            "location": "/chaincode/#what-is-chaincode", 
            "text": "Chaincode is a program, written in  Go , node.js , and eventually in other programming\nlanguages such as Java, that implements a prescribed interface.\nChaincode runs in a secured Docker container isolated from the endorsing\npeer process. Chaincode initializes and manages ledger state through\ntransactions submitted by applications.  A chaincode typically handles business logic agreed to by members of the\nnetwork, so it may be considered as a \\\"smart contract\\\". State created\nby a chaincode is scoped exclusively to that chaincode and can\\'t be\naccessed directly by another chaincode. However, within the same\nnetwork, given the appropriate permission a chaincode may invoke another\nchaincode to access its state.", 
            "title": "What is Chaincode?"
        }, 
        {
            "location": "/chaincode/#two-personas", 
            "text": "We offer two different perspectives on chaincode. One, from the\nperspective of an application developer developing a blockchain\napplication/solution entitled [chaincode4ade]{role=\"doc\"}, and the\nother, [chaincode4noah]{role=\"doc\"} oriented to the blockchain network\noperator who is responsible for managing a blockchain network, and who\nwould leverage the Hyperledger Fabric API to install, instantiate, and\nupgrade chaincode, but would likely not be involved in the development\nof a chaincode application.", 
            "title": "Two Personas"
        }, 
        {
            "location": "/txflow/", 
            "text": "Transaction Flow\n\n\nThis document outlines the transactional mechanics that take place\nduring a standard asset exchange. The scenario includes two clients, A\nand B, who are buying and selling radishes. They each have a peer on the\nnetwork through which they send their transactions and interact with the\nledger.\n\n\n\n\nAssumptions\n\n\nThis flow assumes that a channel is set up and running. The application\nuser has registered and enrolled with the organization's certificate\nauthority (CA) and received back necessary cryptographic material, which\nis used to authenticate to the network.\n\n\nThe chaincode (containing a set of key value pairs representing the\ninitial state of the radish market) is installed on the peers and\ninstantiated on the channel. The chaincode contains logic defining a set\nof transaction instructions and the agreed upon price for a radish. An\nendorsement policy has also been set for this chaincode, stating that\nboth \npeerA\n and \npeerB\n must endorse any transaction.\n\n\n\n\n\n\nClient A initiates a transaction\n\n\n\n\nWhat\\'s happening? - Client A is sending a request to purchase radishes.\nThe request targets \npeerA\n and \npeerB\n, who are respectively\nrepresentative of Client A and Client B. The endorsement policy states\nthat both peers must endorse any transaction, therefore the request goes\nto \npeerA\n and \npeerB\n.\n\n\nNext, the transaction proposal is constructed. An application leveraging\na supported SDK (Node, Java, Python) utilizes one of the available\nAPI\\'s which generates a transaction proposal. The proposal is a request\nto invoke a chaincode function so that data can be read and/or written\nto the ledger (i.e. write new key value pairs for the assets). The SDK\nserves as a shim to package the transaction proposal into the properly\narchitected format (protocol buffer over gRPC) and takes the user's\ncryptographic credentials to produce a unique signature for this\ntransaction proposal.\n\n\n\n\n\n\nEndorsing peers verify signature \n execute the transaction\n\n\n\n\nThe endorsing peers verify (1) that the transaction proposal is well\nformed, (2) it has not been submitted already in the past (replay-attack\nprotection), (3) the signature is valid (using MSP), and (4) that the\nsubmitter (Client A, in the example) is properly authorized to perform\nthe proposed operation on that channel (namely, each endorsing peer\nensures that the submitter satisfies the channel\\'s \nWriters\n policy).\nThe endorsing peers take the transaction proposal inputs as arguments to\nthe invoked chaincode\\'s function. The chaincode is then executed\nagainst the current state database to produce transaction results\nincluding a response value, read set, and write set. No updates are made\nto the ledger at this point. The set of these values, along with the\nendorsing peer's signature is passed back as a \"proposal response\" to\nthe SDK which parses the payload for the application to consume.\n\n\n{The MSP is a peer component that allows them to verify transaction\nrequests arriving from clients and to sign transaction\nresults(endorsements). The Writing policy is defined at channel creation\ntime, and determines which user is entitled to submit a transaction to\nthat channel.}\n\n\n\n\n\n\nProposal responses are inspected\n\n\n\n\nThe application verifies the endorsing peer signatures and compares the\nproposal responses to determine if the proposal responses are the same.\nIf the chaincode only queried the ledger, the application would inspect\nthe query response and would typically not submit the transaction to\nOrdering Service. If the client application intends to submit the\ntransaction to Ordering Service to update the ledger, the application\ndetermines if the specified endorsement policy has been fulfilled before\nsubmitting (i.e. did peerA and peerB both endorse). The architecture is\nsuch that even if an application chooses not to inspect responses or\notherwise forwards an unendorsed transaction, the endorsement policy\nwill still be enforced by peers and upheld at the commit validation\nphase.\n\n\n\n\n\n\nClient assembles endorsements into a transaction\n\n\n\n\nThe application \"broadcasts\" the transaction proposal and response\nwithin a \"transaction message\" to the Ordering Service. The transaction\nwill contain the read/write sets, the endorsing peers signatures and the\nChannel ID. The Ordering Service does not need to inspect the entire\ncontent of a transaction in order to perform its operation, it simply\nreceives transactions from all channels in the network, orders them\nchronologically by channel, and creates blocks of transactions per\nchannel.\n\n\n\n\n\n\nTransaction is validated and committed\n\n\n\n\nThe blocks of transactions are \"delivered\" to all peers on the channel.\nThe transactions within the block are validated to ensure endorsement\npolicy is fulfilled and to ensure that there have been no changes to\nledger state for read set variables since the read set was generated by\nthe transaction execution. Transactions in the block are tagged as being\nvalid or invalid.\n\n\n\n\n\n\nLedger updated\n\n\n\n\nEach peer appends the block to the channel's chain, and for each valid\ntransaction the write sets are committed to current state database. An\nevent is emitted, to notify the client application that the transaction\n(invocation) has been immutably appended to the chain, as well as\nnotification of whether the transaction was validated or invalidated.\n\n\nNote\n: See the [swimlane]{role=\"ref\"} diagram to better understand\nthe server side flow and the protobuffers.", 
            "title": "Transaction Flow"
        }, 
        {
            "location": "/txflow/#transaction-flow", 
            "text": "This document outlines the transactional mechanics that take place\nduring a standard asset exchange. The scenario includes two clients, A\nand B, who are buying and selling radishes. They each have a peer on the\nnetwork through which they send their transactions and interact with the\nledger.   Assumptions  This flow assumes that a channel is set up and running. The application\nuser has registered and enrolled with the organization's certificate\nauthority (CA) and received back necessary cryptographic material, which\nis used to authenticate to the network.  The chaincode (containing a set of key value pairs representing the\ninitial state of the radish market) is installed on the peers and\ninstantiated on the channel. The chaincode contains logic defining a set\nof transaction instructions and the agreed upon price for a radish. An\nendorsement policy has also been set for this chaincode, stating that\nboth  peerA  and  peerB  must endorse any transaction.    Client A initiates a transaction   What\\'s happening? - Client A is sending a request to purchase radishes.\nThe request targets  peerA  and  peerB , who are respectively\nrepresentative of Client A and Client B. The endorsement policy states\nthat both peers must endorse any transaction, therefore the request goes\nto  peerA  and  peerB .  Next, the transaction proposal is constructed. An application leveraging\na supported SDK (Node, Java, Python) utilizes one of the available\nAPI\\'s which generates a transaction proposal. The proposal is a request\nto invoke a chaincode function so that data can be read and/or written\nto the ledger (i.e. write new key value pairs for the assets). The SDK\nserves as a shim to package the transaction proposal into the properly\narchitected format (protocol buffer over gRPC) and takes the user's\ncryptographic credentials to produce a unique signature for this\ntransaction proposal.    Endorsing peers verify signature   execute the transaction   The endorsing peers verify (1) that the transaction proposal is well\nformed, (2) it has not been submitted already in the past (replay-attack\nprotection), (3) the signature is valid (using MSP), and (4) that the\nsubmitter (Client A, in the example) is properly authorized to perform\nthe proposed operation on that channel (namely, each endorsing peer\nensures that the submitter satisfies the channel\\'s  Writers  policy).\nThe endorsing peers take the transaction proposal inputs as arguments to\nthe invoked chaincode\\'s function. The chaincode is then executed\nagainst the current state database to produce transaction results\nincluding a response value, read set, and write set. No updates are made\nto the ledger at this point. The set of these values, along with the\nendorsing peer's signature is passed back as a \"proposal response\" to\nthe SDK which parses the payload for the application to consume.  {The MSP is a peer component that allows them to verify transaction\nrequests arriving from clients and to sign transaction\nresults(endorsements). The Writing policy is defined at channel creation\ntime, and determines which user is entitled to submit a transaction to\nthat channel.}    Proposal responses are inspected   The application verifies the endorsing peer signatures and compares the\nproposal responses to determine if the proposal responses are the same.\nIf the chaincode only queried the ledger, the application would inspect\nthe query response and would typically not submit the transaction to\nOrdering Service. If the client application intends to submit the\ntransaction to Ordering Service to update the ledger, the application\ndetermines if the specified endorsement policy has been fulfilled before\nsubmitting (i.e. did peerA and peerB both endorse). The architecture is\nsuch that even if an application chooses not to inspect responses or\notherwise forwards an unendorsed transaction, the endorsement policy\nwill still be enforced by peers and upheld at the commit validation\nphase.    Client assembles endorsements into a transaction   The application \"broadcasts\" the transaction proposal and response\nwithin a \"transaction message\" to the Ordering Service. The transaction\nwill contain the read/write sets, the endorsing peers signatures and the\nChannel ID. The Ordering Service does not need to inspect the entire\ncontent of a transaction in order to perform its operation, it simply\nreceives transactions from all channels in the network, orders them\nchronologically by channel, and creates blocks of transactions per\nchannel.    Transaction is validated and committed   The blocks of transactions are \"delivered\" to all peers on the channel.\nThe transactions within the block are validated to ensure endorsement\npolicy is fulfilled and to ensure that there have been no changes to\nledger state for read set variables since the read set was generated by\nthe transaction execution. Transactions in the block are tagged as being\nvalid or invalid.    Ledger updated   Each peer appends the block to the channel's chain, and for each valid\ntransaction the write sets are committed to current state database. An\nevent is emitted, to notify the client application that the transaction\n(invocation) has been immutably appended to the chain, as well as\nnotification of whether the transaction was validated or invalidated.  Note : See the [swimlane]{role=\"ref\"} diagram to better understand\nthe server side flow and the protobuffers.", 
            "title": "Transaction Flow"
        }, 
        {
            "location": "/tbd/", 
            "text": "PLACEHOLDER", 
            "title": "Accessing the ledger"
        }, 
        {
            "location": "/tbd/#placeholder", 
            "text": "", 
            "title": "PLACEHOLDER"
        }, 
        {
            "location": "/tbd/", 
            "text": "PLACEHOLDER", 
            "title": "Querying the ledger"
        }, 
        {
            "location": "/tbd/#placeholder", 
            "text": "", 
            "title": "PLACEHOLDER"
        }, 
        {
            "location": "/tbd/", 
            "text": "PLACEHOLDER", 
            "title": "Updating the ledger"
        }, 
        {
            "location": "/tbd/#placeholder", 
            "text": "", 
            "title": "PLACEHOLDER"
        }, 
        {
            "location": "/tbd/", 
            "text": "PLACEHOLDER", 
            "title": "Ledger notifications"
        }, 
        {
            "location": "/tbd/#placeholder", 
            "text": "", 
            "title": "PLACEHOLDER"
        }, 
        {
            "location": "/tbd/", 
            "text": "PLACEHOLDER", 
            "title": "Accessing the transaction log"
        }, 
        {
            "location": "/tbd/#placeholder", 
            "text": "", 
            "title": "PLACEHOLDER"
        }, 
        {
            "location": "/peer-chaincode-devmode/", 
            "text": "Using dev mode\n\n\nNormally chaincodes are started and maintained by peer. However in \"dev\"\nmode, chaincode is built and started by the user. This mode is useful\nduring chaincode development phase for rapid code/build/run/debug cycle\nturnaround.\n\n\nTo keep this a realistic \"dev\" environment, we are going to keep it \"out\nof the box\" - with one exception: we create two channels to show how the\nsingle running instance can be accessed from multiple channels.\n\n\n\n\nNote: Make sure peer is not using TLS when running in dev mode.\n\n\n\n\nAll commands are executed from the \nfabric\n folder.\n\n\nStart the orderer\n\n\nORDERER_GENERAL_GENESISPROFILE=SampleDevModeSolo orderer\n\n\n\nThe above starts the orderer in the local environment the orderer\nconfiguration as defined in \nsampleconfig/orderer.yaml\n with the\ngenesisprofile directive overridden to use the SampleDevModeSolo profile\nfor bootstrapping the network.\n\n\nStart the peer in dev mode\n\n\npeer node start --peer-chaincodedev=true\n\n\n\nThe above command starts the peer using the default \nsampleconfig/msp\n\nMSP. The \n--peer-chaincodedev=true\n puts it in \"dev\" mode.\n\n\nCreate channels ch1 and ch2\n\n\nGenerate the transactions for creating the channels using \nconfigtxgen\n\ntool.\n\n\n::\n\n\n:   configtxgen -channelID ch1 -outputCreateChannelTx ch1.tx -profile\n    SampleSingleMSPChannel configtxgen -channelID ch2\n    -outputCreateChannelTx ch2.tx -profile SampleSingleMSPChannel\n\n\nwhere SampleSingleMSPChannel is a channel profile in\n\nsampleconfig/configtx.yaml\n\n\npeer channel create -o 127.0.0.1:7050 -c ch1 -f ch1.tx\npeer channel create -o 127.0.0.1:7050 -c ch2 -f ch2.tx\n\n\n\nAbove assumes orderer is reachable on \n127.0.0.1:7050\n. The orderer now\nis tracking channels ch1 and ch2 for the default configuration.\n\n\npeer channel join -b ch1.block\npeer channel join -b ch2.block\n\n\n\nThe peer has now joined channels cha1 and ch2.\n\n\nStart the chaincode\n\n\ncd examples/chaincode/go/chaincode_example02\ngo build\nCORE_CHAINCODE_LOGLEVEL=debug CORE_PEER_ADDRESS=127.0.0.1:7052 CORE_CHAINCODE_ID_NAME=mycc:0 ./chaincode_example02\n\n\n\nThe chaincode is started with peer and chaincode logs indicating\nsuccessful registration with the peer. Note that at this stage the\nchaincode is not associated with any channel. This is done in subsequent\nsteps using the \ninstantiate\n command.\n\n\nUse the chaincode\n\n\nEven though you are in \n--peer-chaincodedev\n mode, you still have to\ninstall the chaincode so the life-cycle system chaincode can go through\nits checks normally. This requirement may be removed in future when in\n\n--peer-chaincodedev\n mode.\n\n\npeer chaincode install -n mycc -v 0 -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02\n\n\n\nOnce installed, the chaincode is ready to be instantiated.\n\n\npeer chaincode instantiate -n mycc -v 0 -c '{\"Args\":[\"init\",\"a\",\"100\",\"b\",\"200\"]}' -o 127.0.0.1:7050 -C ch1\n\npeer chaincode instantiate -n mycc -v 0 -c '{\"Args\":[\"init\",\"a\",\"100\",\"b\",\"200\"]}' -o 127.0.0.1:7050 -C ch2\n\n\n\nThe above instantiates the chaincode with the two channels. With default\nsettings it might take a few seconds for the transactions to be\ncommitted.\n\n\npeer chaincode invoke -n mycc -c '{\"Args\":[\"invoke\",\"a\",\"b\",\"10\"]}' -o 127.0.0.1:7050 -C ch1\npeer chaincode invoke -n mycc -c '{\"Args\":[\"invoke\",\"a\",\"b\",\"10\"]}' -o 127.0.0.1:7050 -C ch2\n\n\n\nThe above invoke the chaincode over the two channels.\n\n\nFinally, query the chaincode on the two channels.\n\n\npeer chaincode query -n mycc -c '{\"Args\":[\"query\",\"a\"]}' -o 127.0.0.1:7050 -C ch1\npeer chaincode query -n mycc -c '{\"Args\":[\"query\",\"a\"]}' -o 127.0.0.1:7050 -C ch2", 
            "title": "Running Chaincode in Development Mode"
        }, 
        {
            "location": "/peer-chaincode-devmode/#using-dev-mode", 
            "text": "Normally chaincodes are started and maintained by peer. However in \"dev\"\nmode, chaincode is built and started by the user. This mode is useful\nduring chaincode development phase for rapid code/build/run/debug cycle\nturnaround.  To keep this a realistic \"dev\" environment, we are going to keep it \"out\nof the box\" - with one exception: we create two channels to show how the\nsingle running instance can be accessed from multiple channels.   Note: Make sure peer is not using TLS when running in dev mode.   All commands are executed from the  fabric  folder.", 
            "title": "Using dev mode"
        }, 
        {
            "location": "/peer-chaincode-devmode/#start-the-orderer", 
            "text": "ORDERER_GENERAL_GENESISPROFILE=SampleDevModeSolo orderer  The above starts the orderer in the local environment the orderer\nconfiguration as defined in  sampleconfig/orderer.yaml  with the\ngenesisprofile directive overridden to use the SampleDevModeSolo profile\nfor bootstrapping the network.", 
            "title": "Start the orderer"
        }, 
        {
            "location": "/peer-chaincode-devmode/#start-the-peer-in-dev-mode", 
            "text": "peer node start --peer-chaincodedev=true  The above command starts the peer using the default  sampleconfig/msp \nMSP. The  --peer-chaincodedev=true  puts it in \"dev\" mode.", 
            "title": "Start the peer in dev mode"
        }, 
        {
            "location": "/peer-chaincode-devmode/#create-channels-ch1-and-ch2", 
            "text": "Generate the transactions for creating the channels using  configtxgen \ntool.  ::  :   configtxgen -channelID ch1 -outputCreateChannelTx ch1.tx -profile\n    SampleSingleMSPChannel configtxgen -channelID ch2\n    -outputCreateChannelTx ch2.tx -profile SampleSingleMSPChannel  where SampleSingleMSPChannel is a channel profile in sampleconfig/configtx.yaml  peer channel create -o 127.0.0.1:7050 -c ch1 -f ch1.tx\npeer channel create -o 127.0.0.1:7050 -c ch2 -f ch2.tx  Above assumes orderer is reachable on  127.0.0.1:7050 . The orderer now\nis tracking channels ch1 and ch2 for the default configuration.  peer channel join -b ch1.block\npeer channel join -b ch2.block  The peer has now joined channels cha1 and ch2.", 
            "title": "Create channels ch1 and ch2"
        }, 
        {
            "location": "/peer-chaincode-devmode/#start-the-chaincode", 
            "text": "cd examples/chaincode/go/chaincode_example02\ngo build\nCORE_CHAINCODE_LOGLEVEL=debug CORE_PEER_ADDRESS=127.0.0.1:7052 CORE_CHAINCODE_ID_NAME=mycc:0 ./chaincode_example02  The chaincode is started with peer and chaincode logs indicating\nsuccessful registration with the peer. Note that at this stage the\nchaincode is not associated with any channel. This is done in subsequent\nsteps using the  instantiate  command.", 
            "title": "Start the chaincode"
        }, 
        {
            "location": "/peer-chaincode-devmode/#use-the-chaincode", 
            "text": "Even though you are in  --peer-chaincodedev  mode, you still have to\ninstall the chaincode so the life-cycle system chaincode can go through\nits checks normally. This requirement may be removed in future when in --peer-chaincodedev  mode.  peer chaincode install -n mycc -v 0 -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02  Once installed, the chaincode is ready to be instantiated.  peer chaincode instantiate -n mycc -v 0 -c '{\"Args\":[\"init\",\"a\",\"100\",\"b\",\"200\"]}' -o 127.0.0.1:7050 -C ch1\n\npeer chaincode instantiate -n mycc -v 0 -c '{\"Args\":[\"init\",\"a\",\"100\",\"b\",\"200\"]}' -o 127.0.0.1:7050 -C ch2  The above instantiates the chaincode with the two channels. With default\nsettings it might take a few seconds for the transactions to be\ncommitted.  peer chaincode invoke -n mycc -c '{\"Args\":[\"invoke\",\"a\",\"b\",\"10\"]}' -o 127.0.0.1:7050 -C ch1\npeer chaincode invoke -n mycc -c '{\"Args\":[\"invoke\",\"a\",\"b\",\"10\"]}' -o 127.0.0.1:7050 -C ch2  The above invoke the chaincode over the two channels.  Finally, query the chaincode on the two channels.  peer chaincode query -n mycc -c '{\"Args\":[\"query\",\"a\"]}' -o 127.0.0.1:7050 -C ch1\npeer chaincode query -n mycc -c '{\"Args\":[\"query\",\"a\"]}' -o 127.0.0.1:7050 -C ch2", 
            "title": "Use the chaincode"
        }, 
        {
            "location": "/tbd/", 
            "text": "PLACEHOLDER", 
            "title": "Network Tasks"
        }, 
        {
            "location": "/tbd/#placeholder", 
            "text": "", 
            "title": "PLACEHOLDER"
        }, 
        {
            "location": "/tbd/", 
            "text": "PLACEHOLDER", 
            "title": "Consortium Tasks"
        }, 
        {
            "location": "/tbd/#placeholder", 
            "text": "", 
            "title": "PLACEHOLDER"
        }, 
        {
            "location": "/tbd/", 
            "text": "PLACEHOLDER", 
            "title": "Organization Tasks"
        }, 
        {
            "location": "/tbd/#placeholder", 
            "text": "", 
            "title": "PLACEHOLDER"
        }, 
        {
            "location": "/endorsement-policies/", 
            "text": "Endorsement policies\n\n\nEndorsement policies are used to instruct a peer on how to decide\nwhether a transaction is properly endorsed. When a peer receives a\ntransaction, it invokes the VSCC (Validation System Chaincode)\nassociated with the transaction\\'s Chaincode as part of the transaction\nvalidation flow to determine the validity of the transaction. Recall\nthat a transaction contains one or more endorsement from as many\nendorsing peers. VSCC is tasked to make the following determinations:\n\n\n\n\n\n\nall endorsements are valid (i.e. they are valid signatures from\n    valid certificates over the expected message)\n\n\nthere is an appropriate number of endorsements\n\n\nendorsements come from the expected source(s)\n\n\n\n\n\n\nEndorsement policies are a way of specifying the second and third\npoints.\n\n\nEndorsement policy syntax in the CLI\n\n\nIn the CLI, a simple language is used to express policies in terms of\nboolean expressions over principals.\n\n\nA principal is described in terms of the MSP that is tasked to validate\nthe identity of the signer and of the role that the signer has within\nthat MSP. Currently, two roles are supported: \nmember\n and \nadmin\n.\nPrincipals are described as \nMSP\n.\nROLE\n, where \nMSP\n is the MSP ID that\nis required, and \nROLE\n is either one of the two strings \nmember\n and\n\nadmin\n. Examples of valid principals are \n'Org0.admin'\n (any\nadministrator of the \nOrg0\n MSP) or \n'Org1.member'\n (any member of the\n\nOrg1\n MSP).\n\n\nThe syntax of the language is:\n\n\nEXPR(E[, E...])\n\n\nwhere \nEXPR\n is either \nAND\n or \nOR\n, representing the two boolean\nexpressions and \nE\n is either a principal (with the syntax described\nabove) or another nested call to \nEXPR\n.\n\n\nFor example:\n\n\n:   -   \nAND('Org1.member', 'Org2.member', 'Org3.member')\n requests 1\n        signature from each of the three principals\n    -   \nOR('Org1.member', 'Org2.member')\n requests 1 signature from\n        either one of the two principals\n    -   \nOR('Org1.member', AND('Org2.member', 'Org3.member'))\n requests\n        either one signature from a member of the \nOrg1\n MSP or 1\n        signature from a member of the \nOrg2\n MSP and 1 signature from a\n        member of the \nOrg3\n MSP.\n\n\nSpecifying endorsement policies for a chaincode\n\n\nUsing this language, a chaincode deployer can request that the\nendorsements for a chaincode be validated against the specified policy.\nNOTE - the default policy requires one signature from a member of the\n\nDEFAULT\n MSP). This is used if a policy is not specified in the CLI\nwhen instantiating chaincode.\n\n\nThe policy can be specified at instantiate time using the \n-P\n switch,\nfollowed by the policy.\n\n\nFor example:\n\n\npeer chaincode instantiate -C \nchannelid\n -n mycc -P \"AND('Org1.member', 'Org2.member')\"\n\n\n\nThis command deploys chaincode \nmycc\n with the policy\n\nAND('Org1.member', 'Org2.member')\n which would require that a member of\nboth Org1 and Org2 sign the transaction.", 
            "title": "Endorsement Policy Tasks"
        }, 
        {
            "location": "/endorsement-policies/#endorsement-policies", 
            "text": "Endorsement policies are used to instruct a peer on how to decide\nwhether a transaction is properly endorsed. When a peer receives a\ntransaction, it invokes the VSCC (Validation System Chaincode)\nassociated with the transaction\\'s Chaincode as part of the transaction\nvalidation flow to determine the validity of the transaction. Recall\nthat a transaction contains one or more endorsement from as many\nendorsing peers. VSCC is tasked to make the following determinations:    all endorsements are valid (i.e. they are valid signatures from\n    valid certificates over the expected message)  there is an appropriate number of endorsements  endorsements come from the expected source(s)    Endorsement policies are a way of specifying the second and third\npoints.", 
            "title": "Endorsement policies"
        }, 
        {
            "location": "/endorsement-policies/#endorsement-policy-syntax-in-the-cli", 
            "text": "In the CLI, a simple language is used to express policies in terms of\nboolean expressions over principals.  A principal is described in terms of the MSP that is tasked to validate\nthe identity of the signer and of the role that the signer has within\nthat MSP. Currently, two roles are supported:  member  and  admin .\nPrincipals are described as  MSP . ROLE , where  MSP  is the MSP ID that\nis required, and  ROLE  is either one of the two strings  member  and admin . Examples of valid principals are  'Org0.admin'  (any\nadministrator of the  Org0  MSP) or  'Org1.member'  (any member of the Org1  MSP).  The syntax of the language is:  EXPR(E[, E...])  where  EXPR  is either  AND  or  OR , representing the two boolean\nexpressions and  E  is either a principal (with the syntax described\nabove) or another nested call to  EXPR .  For example:  :   -    AND('Org1.member', 'Org2.member', 'Org3.member')  requests 1\n        signature from each of the three principals\n    -    OR('Org1.member', 'Org2.member')  requests 1 signature from\n        either one of the two principals\n    -    OR('Org1.member', AND('Org2.member', 'Org3.member'))  requests\n        either one signature from a member of the  Org1  MSP or 1\n        signature from a member of the  Org2  MSP and 1 signature from a\n        member of the  Org3  MSP.", 
            "title": "Endorsement policy syntax in the CLI"
        }, 
        {
            "location": "/endorsement-policies/#specifying-endorsement-policies-for-a-chaincode", 
            "text": "Using this language, a chaincode deployer can request that the\nendorsements for a chaincode be validated against the specified policy.\nNOTE - the default policy requires one signature from a member of the DEFAULT  MSP). This is used if a policy is not specified in the CLI\nwhen instantiating chaincode.  The policy can be specified at instantiate time using the  -P  switch,\nfollowed by the policy.  For example:  peer chaincode instantiate -C  channelid  -n mycc -P \"AND('Org1.member', 'Org2.member')\"  This command deploys chaincode  mycc  with the policy AND('Org1.member', 'Org2.member')  which would require that a member of\nboth Org1 and Org2 sign the transaction.", 
            "title": "Specifying endorsement policies for a chaincode"
        }, 
        {
            "location": "/tbd/", 
            "text": "PLACEHOLDER", 
            "title": "Orderer Tasks"
        }, 
        {
            "location": "/tbd/#placeholder", 
            "text": "", 
            "title": "PLACEHOLDER"
        }, 
        {
            "location": "/msp/", 
            "text": "Membership Service Providers (MSP)\n\n\nThe document serves to provide details on the setup and best practices\nfor MSPs.\n\n\nMembership Service Provider (MSP) is a component that aims to offer an\nabstraction of a membership operation architecture.\n\n\nIn particular, MSP abstracts away all cryptographic mechanisms and\nprotocols behind issuing and validating certificates, and user\nauthentication. An MSP may define their own notion of identity, and the\nrules by which those identities are governed (identity validation) and\nauthenticated (signature generation and verification).\n\n\nA Hyperledger Fabric blockchain network can be governed by one or more\nMSPs. This provides modularity of membership operations, and\ninteroperability across different membership standards and\narchitectures.\n\n\nIn the rest of this document we elaborate on the setup of the MSP\nimplementation supported by Hyperledger Fabric, and discuss best\npractices concerning its use.\n\n\nMSP Configuration\n\n\nTo setup an instance of the MSP, its configuration needs to be specified\nlocally at each peer and orderer (to enable peer, and orderer signing),\nand on the channels to enable peer, orderer, client identity validation,\nand respective signature verification (authentication) by and for all\nchannel members.\n\n\nFirstly, for each MSP a name needs to be specified in order to reference\nthat MSP in the network (e.g. \nmsp1\n, \norg2\n, and \norg3.divA\n). This is\nthe name under which membership rules of an MSP representing a\nconsortium, organization or organization division is to be referenced in\na channel. This is also referred to as the \nMSP Identifier\n or \nMSP ID\n.\nMSP Identifiers are required to be unique per MSP instance. For example,\nshall two MSP instances with the same identifier be detected at the\nsystem channel genesis, orderer setup will fail.\n\n\nIn the case of default implementation of MSP, a set of parameters need\nto be specified to allow for identity (certificate) validation and\nsignature verification. These parameters are deduced by\n\nRFC5280\n, and include:\n\n\n\n\nA list of self-signed (X.509) certificates to constitute the \nroot\n    of trust\n\n\nA list of X.509 certificates to represent intermediate CAs this\n    provider considers for certificate validation; these certificates\n    ought to be certified by exactly one of the certificates in the root\n    of trust; intermediate CAs are optional parameters\n\n\nA list of X.509 certificates with a verifiable certificate path to\n    exactly one of the certificates of the root of trust to represent\n    the administrators of this MSP; owners of these certificates are\n    authorized to request changes to this MSP configuration (e.g. root\n    CAs, intermediate CAs)\n\n\nA list of Organizational Units that valid members of this MSP should\n    include in their X.509 certificate; this is an optional\n    configuration parameter, used when, e.g., multiple organisations\n    leverage the same root of trust, and intermediate CAs, and have\n    reserved an OU field for their members\n\n\nA list of certificate revocation lists (CRLs) each corresponding to\n    exactly one of the listed (intermediate or root) MSP Certificate\n    Authorities; this is an optional parameter\n\n\nA list of self-signed (X.509) certificates to constitute the \nTLS\n    root of trust\n for TLS certificate.\n\n\nA list of X.509 certificates to represent intermediate TLS CAs this\n    provider considers; these certificates ought to be certified by\n    exactly one of the certificates in the TLS root of trust;\n    intermediate CAs are optional parameters.\n\n\n\n\nValid\n identities for this MSP instance are required to satisfy the\nfollowing conditions:\n\n\n\n\nThey are in the form of X.509 certificates with a verifiable\n    certificate path to exactly one of the root of trust certificates;\n\n\nThey are not included in any CRL;\n\n\nAnd they \nlist\n one or more of the Organizational Units of the MSP\n    configuration in the \nOU\n field of their X.509 certificate\n    structure.\n\n\n\n\nFor more information on the validity of identities in the current MSP\nimplementation, we refer the reader to\n[msp-identity-validity-rules]{role=\"doc\"}.\n\n\nIn addition to verification related parameters, for the MSP to enable\nthe node on which it is instantiated to sign or authenticate, one needs\nto specify:\n\n\n\n\nThe signing key used for signing by the node (currently only ECDSA\n    keys are supported), and\n\n\nThe node\\'s X.509 certificate, that is a valid identity under the\n    verification parameters of this MSP.\n\n\n\n\nIt is important to note that MSP identities never expire; they can only\nbe revoked by adding them to the appropriate CRLs. Additionally, there\nis currently no support for enforcing revocation of TLS certificates.\n\n\nHow to generate MSP certificates and their signing keys?\n\n\nTo generate X.509 certificates to feed its MSP configuration, the\napplication can use \nOpenssl\n. We emphasise\nthat in Hyperledger Fabric there is no support for certificates\nincluding RSA keys.\n\n\nAlternatively one can use \ncryptogen\n tool, whose operation is explained\nin [getting_started]{role=\"doc\"}.\n\n\nHyperledger Fabric\nCA\n can also be\nused to generate the keys and certificates needed to configure an MSP.\n\n\nMSP setup on the peer \n orderer side\n\n\nTo set up a local MSP (for either a peer or an orderer), the\nadministrator should create a folder (e.g. \n$MY_PATH/mspconfig\n) that\ncontains six subfolders and a file:\n\n\n\n\na folder \nadmincerts\n to include PEM files each corresponding to an\n    administrator certificate\n\n\na folder \ncacerts\n to include PEM files each corresponding to a root\n    CA\\'s certificate\n\n\n(optional) a folder \nintermediatecerts\n to include PEM files each\n    corresponding to an intermediate CA\\'s certificate\n\n\n(optional) a file \nconfig.yaml\n to include information on the\n    considered OUs; the latter are defined as pairs of\n    \nCertificate, OrganizationalUnitIdentifier\n entries of a yaml\n    array called \nOrganizationalUnitIdentifiers\n, where \nCertificate\n\n    represents the relative path to the certificate of the certificate\n    authority (root or intermediate) that should be considered for\n    certifying members of this organizational unit (e.g.\n    ./cacerts/cacert.pem), and \nOrganizationalUnitIdentifier\n represents\n    the actual string as expected to appear in X.509 certificate\n    OU-field (e.g. \\\"COP\\\")\n\n\n(optional) a folder \ncrls\n to include the considered CRLs\n\n\na folder \nkeystore\n to include a PEM file with the node\\'s signing\n    key; we emphasise that currently RSA keys are not supported\n\n\na folder \nsigncerts\n to include a PEM file with the node\\'s X.509\n    certificate\n\n\n(optional) a folder \ntlscacerts\n to include PEM files each\n    corresponding to a TLS root CA\\'s certificate\n\n\n(optional) a folder \ntlsintermediatecerts\n to include PEM files each\n    corresponding to an intermediate TLS CA\\'s certificate\n\n\n\n\nIn the configuration file of the node (core.yaml file for the peer, and\norderer.yaml for the orderer), one needs to specify the path to the\nmspconfig folder, and the MSP Identifier of the node\\'s MSP. The path to\nthe mspconfig folder is expected to be relative to FABRIC_CFG_PATH and\nis provided as the value of parameter \nmspConfigPath\n for the peer, and\n\nLocalMSPDir\n for the orderer. The identifier of the node\\'s MSP is\nprovided as a value of parameter \nlocalMspId\n for the peer and\n\nLocalMSPID\n for the orderer. These variables can be overridden via the\nenvironment using the CORE prefix for peer (e.g. CORE_PEER_LOCALMSPID)\nand the ORDERER prefix for the orderer (e.g.\nORDERER_GENERAL_LOCALMSPID). Notice that for the orderer setup, one\nneeds to generate, and provide to the orderer the genesis block of the\nsystem channel. The MSP configuration needs of this block are detailed\nin the next section.\n\n\nReconfiguration\n of a \\\"local\\\" MSP is only possible manually, and\nrequires that the peer or orderer process is restarted. In subsequent\nreleases we aim to offer online/dynamic reconfiguration (i.e. without\nrequiring to stop the node by using a node managed system chaincode).\n\n\nChannel MSP setup\n\n\nAt the genesis of the system, verification parameters of all the MSPs\nthat appear in the network need to be specified, and included in the\nsystem channel\\'s genesis block. Recall that MSP verification parameters\nconsist of the MSP identifier, the root of trust certificates,\nintermediate CA and admin certificates, as well as OU specifications and\nCRLs. The system genesis block is provided to the orderers at their\nsetup phase, and allows them to authenticate channel creation requests.\nOrderers would reject the system genesis block, if the latter includes\ntwo MSPs with the same identifier, and consequently the bootstrapping of\nthe network would fail.\n\n\nFor application channels, the verification components of only the MSPs\nthat govern a channel need to reside in the channel\\'s genesis block. We\nemphasise that it is \nthe responsibility of the application\n to ensure\nthat correct MSP configuration information is included in the genesis\nblocks (or the most recent configuration block) of a channel prior to\ninstructing one or more of their peers to join the channel.\n\n\nWhen bootstrapping a channel with the help of the configtxgen tool, one\ncan configure the channel MSPs by including the verification parameters\nof MSP in the mspconfig folder, and setting that path in the relevant\nsection in \nconfigtx.yaml\n.\n\n\nReconfiguration\n of an MSP on the channel, including announcements of\nthe certificate revocation lists associated to the CAs of that MSP is\nachieved through the creation of a \nconfig_update\n object by the owner\nof one of the administrator certificates of the MSP. The client\napplication managed by the admin would then announce this update to the\nchannels in which this MSP appears.\n\n\nBest Practices\n\n\nIn this section we elaborate on best practices for MSP configuration in\ncommonly met scenarios.\n\n\n1) Mapping between organizations/corporations and MSPs\n\n\nWe recommend that there is a one-to-one mapping between organizations\nand MSPs. If a different mapping type of mapping is chosen, the\nfollowing needs to be to considered:\n\n\n\n\nOne organization employing various MSPs.\n This corresponds to the\n    case of an organization including a variety of divisions each\n    represented by its MSP, either for management independence reasons,\n    or for privacy reasons. In this case a peer can only be owned by a\n    single MSP, and will not recognize peers with identities from other\n    MSPs as peers of the same organization. The implication of this is\n    that peers may share through gossip organization-scoped data with a\n    set of peers that are members of the same subdivision, and NOT with\n    the full set of providers constituting the actual organization.\n\n\nMultiple organizations using a single MSP.\n This corresponds to a\n    case of a consortium of organisations that are governed by similar\n    membership architecture. One needs to know here that peers would\n    propagate organization-scoped messages to the peers that have an\n    identity under the same MSP regardless of whether they belong to the\n    same actual organization. This is a limitation of the granularity of\n    MSP definition, and/or of the peer's configuration.\n\n\n\n\n2) One organization has different divisions (say organizational\nunits), to\n \nwhich it wants to grant access to different channels.\n\n\nTwo ways to handle this:\n\n\n\n\nDefine one MSP to accommodate membership for all organization's\n    members\n. Configuration of that MSP would consist of a list of root\n    CAs, intermediate CAs and admin certificates; and membership\n    identities would include the organizational unit (\nOU\n) a member\n    belongs to. Policies can then be defined to capture members of a\n    specific \nOU\n, and these policies may constitute the read/write\n    policies of a channel or endorsement policies of a chaincode. A\n    limitation of this approach is that gossip peers would consider\n    peers with membership identities under their local MSP as members of\n    the same organization, and would consequently gossip with them\n    organisation-scoped data (e.g. their status).\n\n\nDefining one MSP to represent each division\n. This would involve\n    specifying for each division, a set of certificates for root CAs,\n    intermediate CAs, and admin Certs, such that there is no overlapping\n    certification path across MSPs. This would mean that, for example, a\n    different intermediate CA per subdivision is employed. Here the\n    disadvantage is the management of more than one MSPs instead of one,\n    but this circumvents the issue present in the previous approach. One\n    could also define one MSP for each division by leveraging an OU\n    extension of the MSP configuration.\n\n\n\n\n3) Separating clients from peers of the same organization.\n\n\nIn many cases it is required that the \"type\" of an identity is\nretrievable from the identity itself (e.g. it may be needed that\nendorsements are guaranteed to have derived by peers, and not clients or\nnodes acting solely as orderers).\n\n\nThere is limited support for such requirements.\n\n\nOne way to allow for this separation is to to create a separate\nintermediate CA for each node type - one for clients and one for\npeers/orderers; and configure two different MSPs - one for clients and\none for peers/orderers. Channels this organization should be accessing\nwould need to include both MSPs, while endorsement policies will\nleverage only the MSP that refers to the peers. This would ultimately\nresult in the organization being mapped to two MSP instances, and would\nhave certain consequences on the way peers and clients interact.\n\n\nGossip would not be drastically impacted as all peers of the same\norganization would still belong to one MSP. Peers can restrict the\nexecution of certain system chaincodes to local MSP based policies. For\nexample, peers would only execute \"joinChannel\" request if the request\nis signed by the admin of their local MSP who can only be a client\n(end-user should be sitting at the origin of that request). We can go\naround this inconsistency if we accept that the only clients to be\nmembers of a peer/orderer MSP would be the administrators of that MSP.\n\n\nAnother point to be considered with this approach is that peers\nauthorize event registration requests based on membership of request\noriginator within their local MSP. Clearly, since the originator of the\nrequest is a client, the request originator is always doomed to belong\nto a different MSP than the requested peer and the peer would reject the\nrequest.\n\n\n4) Admin and CA certificates.\n\n\nIt is important to set MSP admin certificates to be different than any\nof the certificates considered by the MSP for \nroot of trust\n, or\nintermediate CAs. This is a common (security) practice to separate the\nduties of management of membership components from the issuing of new\ncertificates, and/or validation of existing ones.\n\n\n5) Blacklisting an intermediate CA.\n\n\nAs mentioned in previous sections, reconfiguration of an MSP is achieved\nby reconfiguration mechanisms (manual reconfiguration for the local MSP\ninstances, and via properly constructed \nconfig_update\n messages for MSP\ninstances of a channel). Clearly, there are two ways to ensure an\nintermediate CA considered in an MSP is no longer considered for that\nMSP\\'s identity validation:\n\n\n\n\nReconfigure the MSP to no longer include the certificate of that\n    intermediate CA in the list of trusted intermediate CA certs. For\n    the locally configured MSP, this would mean that the certificate of\n    this CA is removed from the \nintermediatecerts\n folder.\n\n\nReconfigure the MSP to include a CRL produced by the root of trust\n    which denounces the mentioned intermediate CA\\'s certificate.\n\n\n\n\nIn the current MSP implementation we only support method (1) as it is\nsimpler and does not require blacklisting the no longer considered\nintermediate CA.\n\n\n6) CAs and TLS CAs\n\n\nMSP identities\\' root CAs and MSP TLS certificates\\' root CAs (and\nrelative intermediate CAs) need to be declared in different folders.\nThis is to avoid confusion between different classes of certificates. It\nis not forbidden to reuse the same CAs for both MSP identities and TLS\ncertificates but best practices suggest to avoid this in production.", 
            "title": "Managing Identity"
        }, 
        {
            "location": "/msp/#membership-service-providers-msp", 
            "text": "The document serves to provide details on the setup and best practices\nfor MSPs.  Membership Service Provider (MSP) is a component that aims to offer an\nabstraction of a membership operation architecture.  In particular, MSP abstracts away all cryptographic mechanisms and\nprotocols behind issuing and validating certificates, and user\nauthentication. An MSP may define their own notion of identity, and the\nrules by which those identities are governed (identity validation) and\nauthenticated (signature generation and verification).  A Hyperledger Fabric blockchain network can be governed by one or more\nMSPs. This provides modularity of membership operations, and\ninteroperability across different membership standards and\narchitectures.  In the rest of this document we elaborate on the setup of the MSP\nimplementation supported by Hyperledger Fabric, and discuss best\npractices concerning its use.", 
            "title": "Membership Service Providers (MSP)"
        }, 
        {
            "location": "/msp/#msp-configuration", 
            "text": "To setup an instance of the MSP, its configuration needs to be specified\nlocally at each peer and orderer (to enable peer, and orderer signing),\nand on the channels to enable peer, orderer, client identity validation,\nand respective signature verification (authentication) by and for all\nchannel members.  Firstly, for each MSP a name needs to be specified in order to reference\nthat MSP in the network (e.g.  msp1 ,  org2 , and  org3.divA ). This is\nthe name under which membership rules of an MSP representing a\nconsortium, organization or organization division is to be referenced in\na channel. This is also referred to as the  MSP Identifier  or  MSP ID .\nMSP Identifiers are required to be unique per MSP instance. For example,\nshall two MSP instances with the same identifier be detected at the\nsystem channel genesis, orderer setup will fail.  In the case of default implementation of MSP, a set of parameters need\nto be specified to allow for identity (certificate) validation and\nsignature verification. These parameters are deduced by RFC5280 , and include:   A list of self-signed (X.509) certificates to constitute the  root\n    of trust  A list of X.509 certificates to represent intermediate CAs this\n    provider considers for certificate validation; these certificates\n    ought to be certified by exactly one of the certificates in the root\n    of trust; intermediate CAs are optional parameters  A list of X.509 certificates with a verifiable certificate path to\n    exactly one of the certificates of the root of trust to represent\n    the administrators of this MSP; owners of these certificates are\n    authorized to request changes to this MSP configuration (e.g. root\n    CAs, intermediate CAs)  A list of Organizational Units that valid members of this MSP should\n    include in their X.509 certificate; this is an optional\n    configuration parameter, used when, e.g., multiple organisations\n    leverage the same root of trust, and intermediate CAs, and have\n    reserved an OU field for their members  A list of certificate revocation lists (CRLs) each corresponding to\n    exactly one of the listed (intermediate or root) MSP Certificate\n    Authorities; this is an optional parameter  A list of self-signed (X.509) certificates to constitute the  TLS\n    root of trust  for TLS certificate.  A list of X.509 certificates to represent intermediate TLS CAs this\n    provider considers; these certificates ought to be certified by\n    exactly one of the certificates in the TLS root of trust;\n    intermediate CAs are optional parameters.   Valid  identities for this MSP instance are required to satisfy the\nfollowing conditions:   They are in the form of X.509 certificates with a verifiable\n    certificate path to exactly one of the root of trust certificates;  They are not included in any CRL;  And they  list  one or more of the Organizational Units of the MSP\n    configuration in the  OU  field of their X.509 certificate\n    structure.   For more information on the validity of identities in the current MSP\nimplementation, we refer the reader to\n[msp-identity-validity-rules]{role=\"doc\"}.  In addition to verification related parameters, for the MSP to enable\nthe node on which it is instantiated to sign or authenticate, one needs\nto specify:   The signing key used for signing by the node (currently only ECDSA\n    keys are supported), and  The node\\'s X.509 certificate, that is a valid identity under the\n    verification parameters of this MSP.   It is important to note that MSP identities never expire; they can only\nbe revoked by adding them to the appropriate CRLs. Additionally, there\nis currently no support for enforcing revocation of TLS certificates.", 
            "title": "MSP Configuration"
        }, 
        {
            "location": "/msp/#how-to-generate-msp-certificates-and-their-signing-keys", 
            "text": "To generate X.509 certificates to feed its MSP configuration, the\napplication can use  Openssl . We emphasise\nthat in Hyperledger Fabric there is no support for certificates\nincluding RSA keys.  Alternatively one can use  cryptogen  tool, whose operation is explained\nin [getting_started]{role=\"doc\"}.  Hyperledger Fabric\nCA  can also be\nused to generate the keys and certificates needed to configure an MSP.", 
            "title": "How to generate MSP certificates and their signing keys?"
        }, 
        {
            "location": "/msp/#msp-setup-on-the-peer-orderer-side", 
            "text": "To set up a local MSP (for either a peer or an orderer), the\nadministrator should create a folder (e.g.  $MY_PATH/mspconfig ) that\ncontains six subfolders and a file:   a folder  admincerts  to include PEM files each corresponding to an\n    administrator certificate  a folder  cacerts  to include PEM files each corresponding to a root\n    CA\\'s certificate  (optional) a folder  intermediatecerts  to include PEM files each\n    corresponding to an intermediate CA\\'s certificate  (optional) a file  config.yaml  to include information on the\n    considered OUs; the latter are defined as pairs of\n     Certificate, OrganizationalUnitIdentifier  entries of a yaml\n    array called  OrganizationalUnitIdentifiers , where  Certificate \n    represents the relative path to the certificate of the certificate\n    authority (root or intermediate) that should be considered for\n    certifying members of this organizational unit (e.g.\n    ./cacerts/cacert.pem), and  OrganizationalUnitIdentifier  represents\n    the actual string as expected to appear in X.509 certificate\n    OU-field (e.g. \\\"COP\\\")  (optional) a folder  crls  to include the considered CRLs  a folder  keystore  to include a PEM file with the node\\'s signing\n    key; we emphasise that currently RSA keys are not supported  a folder  signcerts  to include a PEM file with the node\\'s X.509\n    certificate  (optional) a folder  tlscacerts  to include PEM files each\n    corresponding to a TLS root CA\\'s certificate  (optional) a folder  tlsintermediatecerts  to include PEM files each\n    corresponding to an intermediate TLS CA\\'s certificate   In the configuration file of the node (core.yaml file for the peer, and\norderer.yaml for the orderer), one needs to specify the path to the\nmspconfig folder, and the MSP Identifier of the node\\'s MSP. The path to\nthe mspconfig folder is expected to be relative to FABRIC_CFG_PATH and\nis provided as the value of parameter  mspConfigPath  for the peer, and LocalMSPDir  for the orderer. The identifier of the node\\'s MSP is\nprovided as a value of parameter  localMspId  for the peer and LocalMSPID  for the orderer. These variables can be overridden via the\nenvironment using the CORE prefix for peer (e.g. CORE_PEER_LOCALMSPID)\nand the ORDERER prefix for the orderer (e.g.\nORDERER_GENERAL_LOCALMSPID). Notice that for the orderer setup, one\nneeds to generate, and provide to the orderer the genesis block of the\nsystem channel. The MSP configuration needs of this block are detailed\nin the next section.  Reconfiguration  of a \\\"local\\\" MSP is only possible manually, and\nrequires that the peer or orderer process is restarted. In subsequent\nreleases we aim to offer online/dynamic reconfiguration (i.e. without\nrequiring to stop the node by using a node managed system chaincode).", 
            "title": "MSP setup on the peer &amp; orderer side"
        }, 
        {
            "location": "/msp/#channel-msp-setup", 
            "text": "At the genesis of the system, verification parameters of all the MSPs\nthat appear in the network need to be specified, and included in the\nsystem channel\\'s genesis block. Recall that MSP verification parameters\nconsist of the MSP identifier, the root of trust certificates,\nintermediate CA and admin certificates, as well as OU specifications and\nCRLs. The system genesis block is provided to the orderers at their\nsetup phase, and allows them to authenticate channel creation requests.\nOrderers would reject the system genesis block, if the latter includes\ntwo MSPs with the same identifier, and consequently the bootstrapping of\nthe network would fail.  For application channels, the verification components of only the MSPs\nthat govern a channel need to reside in the channel\\'s genesis block. We\nemphasise that it is  the responsibility of the application  to ensure\nthat correct MSP configuration information is included in the genesis\nblocks (or the most recent configuration block) of a channel prior to\ninstructing one or more of their peers to join the channel.  When bootstrapping a channel with the help of the configtxgen tool, one\ncan configure the channel MSPs by including the verification parameters\nof MSP in the mspconfig folder, and setting that path in the relevant\nsection in  configtx.yaml .  Reconfiguration  of an MSP on the channel, including announcements of\nthe certificate revocation lists associated to the CAs of that MSP is\nachieved through the creation of a  config_update  object by the owner\nof one of the administrator certificates of the MSP. The client\napplication managed by the admin would then announce this update to the\nchannels in which this MSP appears.", 
            "title": "Channel MSP setup"
        }, 
        {
            "location": "/msp/#best-practices", 
            "text": "In this section we elaborate on best practices for MSP configuration in\ncommonly met scenarios.  1) Mapping between organizations/corporations and MSPs  We recommend that there is a one-to-one mapping between organizations\nand MSPs. If a different mapping type of mapping is chosen, the\nfollowing needs to be to considered:   One organization employing various MSPs.  This corresponds to the\n    case of an organization including a variety of divisions each\n    represented by its MSP, either for management independence reasons,\n    or for privacy reasons. In this case a peer can only be owned by a\n    single MSP, and will not recognize peers with identities from other\n    MSPs as peers of the same organization. The implication of this is\n    that peers may share through gossip organization-scoped data with a\n    set of peers that are members of the same subdivision, and NOT with\n    the full set of providers constituting the actual organization.  Multiple organizations using a single MSP.  This corresponds to a\n    case of a consortium of organisations that are governed by similar\n    membership architecture. One needs to know here that peers would\n    propagate organization-scoped messages to the peers that have an\n    identity under the same MSP regardless of whether they belong to the\n    same actual organization. This is a limitation of the granularity of\n    MSP definition, and/or of the peer's configuration.   2) One organization has different divisions (say organizational\nunits), to   which it wants to grant access to different channels.  Two ways to handle this:   Define one MSP to accommodate membership for all organization's\n    members . Configuration of that MSP would consist of a list of root\n    CAs, intermediate CAs and admin certificates; and membership\n    identities would include the organizational unit ( OU ) a member\n    belongs to. Policies can then be defined to capture members of a\n    specific  OU , and these policies may constitute the read/write\n    policies of a channel or endorsement policies of a chaincode. A\n    limitation of this approach is that gossip peers would consider\n    peers with membership identities under their local MSP as members of\n    the same organization, and would consequently gossip with them\n    organisation-scoped data (e.g. their status).  Defining one MSP to represent each division . This would involve\n    specifying for each division, a set of certificates for root CAs,\n    intermediate CAs, and admin Certs, such that there is no overlapping\n    certification path across MSPs. This would mean that, for example, a\n    different intermediate CA per subdivision is employed. Here the\n    disadvantage is the management of more than one MSPs instead of one,\n    but this circumvents the issue present in the previous approach. One\n    could also define one MSP for each division by leveraging an OU\n    extension of the MSP configuration.   3) Separating clients from peers of the same organization.  In many cases it is required that the \"type\" of an identity is\nretrievable from the identity itself (e.g. it may be needed that\nendorsements are guaranteed to have derived by peers, and not clients or\nnodes acting solely as orderers).  There is limited support for such requirements.  One way to allow for this separation is to to create a separate\nintermediate CA for each node type - one for clients and one for\npeers/orderers; and configure two different MSPs - one for clients and\none for peers/orderers. Channels this organization should be accessing\nwould need to include both MSPs, while endorsement policies will\nleverage only the MSP that refers to the peers. This would ultimately\nresult in the organization being mapped to two MSP instances, and would\nhave certain consequences on the way peers and clients interact.  Gossip would not be drastically impacted as all peers of the same\norganization would still belong to one MSP. Peers can restrict the\nexecution of certain system chaincodes to local MSP based policies. For\nexample, peers would only execute \"joinChannel\" request if the request\nis signed by the admin of their local MSP who can only be a client\n(end-user should be sitting at the origin of that request). We can go\naround this inconsistency if we accept that the only clients to be\nmembers of a peer/orderer MSP would be the administrators of that MSP.  Another point to be considered with this approach is that peers\nauthorize event registration requests based on membership of request\noriginator within their local MSP. Clearly, since the originator of the\nrequest is a client, the request originator is always doomed to belong\nto a different MSP than the requested peer and the peer would reject the\nrequest.  4) Admin and CA certificates.  It is important to set MSP admin certificates to be different than any\nof the certificates considered by the MSP for  root of trust , or\nintermediate CAs. This is a common (security) practice to separate the\nduties of management of membership components from the issuing of new\ncertificates, and/or validation of existing ones.  5) Blacklisting an intermediate CA.  As mentioned in previous sections, reconfiguration of an MSP is achieved\nby reconfiguration mechanisms (manual reconfiguration for the local MSP\ninstances, and via properly constructed  config_update  messages for MSP\ninstances of a channel). Clearly, there are two ways to ensure an\nintermediate CA considered in an MSP is no longer considered for that\nMSP\\'s identity validation:   Reconfigure the MSP to no longer include the certificate of that\n    intermediate CA in the list of trusted intermediate CA certs. For\n    the locally configured MSP, this would mean that the certificate of\n    this CA is removed from the  intermediatecerts  folder.  Reconfigure the MSP to include a CRL produced by the root of trust\n    which denounces the mentioned intermediate CA\\'s certificate.   In the current MSP implementation we only support method (1) as it is\nsimpler and does not require blacklisting the no longer considered\nintermediate CA.  6) CAs and TLS CAs  MSP identities\\' root CAs and MSP TLS certificates\\' root CAs (and\nrelative intermediate CAs) need to be declared in different folders.\nThis is to avoid confusion between different classes of certificates. It\nis not forbidden to reuse the same CAs for both MSP identities and TLS\ncertificates but best practices suggest to avoid this in production.", 
            "title": "Best Practices"
        }, 
        {
            "location": "/configtx/", 
            "text": "Channel Configuration (configtx)\n\n\nShared configuration for a Hyperledger Fabric blockchain network is\nstored in a collection configuration transactions, one per channel. Each\nconfiguration transaction is usually referred to by the shorter name\n\nconfigtx\n.\n\n\nChannel configuration has the following important properties:\n\n\n\n\nVersioned\n: All elements of the configuration have an associated\n    version which is advanced with every modification. Further, every\n    committed configuration receives a sequence number.\n\n\nPermissioned\n: Each element of the configuration has an\n    associated policy which governs whether or not modification to that\n    element is permitted. Anyone with a copy of the previous configtx\n    (and no additional info) may verify the validity of a new config\n    based on these policies.\n\n\nHierarchical\n: A root configuration group contains sub-groups,\n    and each group of the hierarchy has associated values and policies.\n    These policies can take advantage of the hierarchy to derive\n    policies at one level from policies of lower levels.\n\n\n\n\nAnatomy of a configuration\n\n\nConfiguration is stored as a transaction of type \nHeaderType_CONFIG\n in\na block with no other transactions. These blocks are referred to as\n\nConfiguration Blocks\n, the first of which is referred to as the\n\nGenesis Block\n.\n\n\nThe proto structures for configuration are stored in\n\nfabric/protos/common/configtx.proto\n. The Envelope of type\n\nHeaderType_CONFIG\n encodes a \nConfigEnvelope\n message as the \nPayload\n\n\ndata\n field. The proto for \nConfigEnvelope\n is defined as follows:\n\n\nmessage ConfigEnvelope {\n    Config config = 1;\n    Envelope last_update = 2;\n}\n\n\n\nThe \nlast_update\n field is defined below in the \nUpdates to\nconfiguration\n section, but is only necessary when validating the\nconfiguration, not reading it. Instead, the currently committed\nconfiguration is stored in the \nconfig\n field, containing a \nConfig\n\nmessage.\n\n\nmessage Config {\n    uint64 sequence = 1;\n    ConfigGroup channel_group = 2;\n}\n\n\n\nThe \nsequence\n number is incremented by one for each committed\nconfiguration. The \nchannel_group\n field is the root group which\ncontains the configuration. The \nConfigGroup\n structure is recursively\ndefined, and builds a tree of groups, each of which contains values and\npolicies. It is defined as follows:\n\n\nmessage ConfigGroup {\n    uint64 version = 1;\n    map\nstring,ConfigGroup\n groups = 2;\n    map\nstring,ConfigValue\n values = 3;\n    map\nstring,ConfigPolicy\n policies = 4;\n    string mod_policy = 5;\n}\n\n\n\nBecause \nConfigGroup\n is a recursive structure, it has hierarchical\narrangement. The following example is expressed for clarity in golang\nnotation.\n\n\n// Assume the following groups are defined\nvar root, child1, child2, grandChild1, grandChild2, grandChild3 *ConfigGroup\n\n// Set the following values\nroot.Groups[\"child1\"] = child1\nroot.Groups[\"child2\"] = child2\nchild1.Groups[\"grandChild1\"] = grandChild1\nchild2.Groups[\"grandChild2\"] = grandChild2\nchild2.Groups[\"grandChild3\"] = grandChild3\n\n// The resulting config structure of groups looks like:\n// root:\n//     child1:\n//         grandChild1\n//     child2:\n//         grandChild2\n//         grandChild3\n\n\n\nEach group defines a level in the config hierarchy, and each group has\nan associated set of values (indexed by string key) and policies (also\nindexed by string key).\n\n\nValues are defined by:\n\n\nmessage ConfigValue {\n    uint64 version = 1;\n    bytes value = 2;\n    string mod_policy = 3;\n}\n\n\n\nPolicies are defined by:\n\n\nmessage ConfigPolicy {\n    uint64 version = 1;\n    Policy policy = 2;\n    string mod_policy = 3;\n}\n\n\n\nNote that Values, Policies, and Groups all have a \nversion\n and a\n\nmod_policy\n. The \nversion\n of an element is incremented each time that\nelement is modified. The \nmod_policy\n is used to govern the required\nsignatures to modify that element. For Groups, modification is adding or\nremoving elements to the Values, Policies, or Groups maps (or changing\nthe \nmod_policy\n). For Values and Policies, modification is changing the\nValue and Policy fields respectively (or changing the \nmod_policy\n).\nEach element\\'s \nmod_policy\n is evaluated in the context of the current\nlevel of the config. Consider the following example mod policies defined\nat \nChannel.Groups[\"Application\"]\n (Here, we use the golang map\nreference syntax, so \nChannel.Groups[\"Application\"].Policies[\"policy1\"]\n\nrefers to the base \nChannel\n group\\'s \nApplication\n group\\'s \nPolicies\n\nmap\\'s \npolicy1\n policy.)\n\n\n\n\npolicy1\n maps to\n    \nChannel.Groups[\"Application\"].Policies[\"policy1\"]\n\n\nOrg1/policy2\n maps to\n    \nChannel.Groups[\"Application\"].Groups[\"Org1\"].Policies[\"policy2\"]\n\n\n/Channel/policy3\n maps to \nChannel.Policies[\"policy3\"]\n\n\n\n\nNote that if a \nmod_policy\n references a policy which does not exist,\nthe item cannot be modified.\n\n\nConfiguration updates\n\n\nConfiguration updates are submitted as an \nEnvelope\n message of type\n\nHeaderType_CONFIG_UPDATE\n. The \nPayload\n \ndata\n of the transaction is a\nmarshaled \nConfigUpdateEnvelope\n. The \nConfigUpdateEnvelope\n is defined\nas follows:\n\n\nmessage ConfigUpdateEnvelope {\n    bytes config_update = 1;\n    repeated ConfigSignature signatures = 2;\n}\n\n\n\nThe \nsignatures\n field contains the set of signatures which authorizes\nthe config update. Its message definition is:\n\n\nmessage ConfigSignature {\n    bytes signature_header = 1;\n    bytes signature = 2;\n}\n\n\n\nThe \nsignature_header\n is as defined for standard transactions, while\nthe signature is over the concatenation of the \nsignature_header\n bytes\nand the \nconfig_update\n bytes from the \nConfigUpdateEnvelope\n message.\n\n\nThe \nConfigUpdateEnvelope\n \nconfig_update\n bytes are a marshaled\n\nConfigUpdate\n message which is defined as follows:\n\n\nmessage ConfigUpdate {\n    string channel_id = 1;\n    ConfigGroup read_set = 2;\n    ConfigGroup write_set = 3;\n}\n\n\n\nThe \nchannel_id\n is the channel ID the update is bound for, this is\nnecessary to scope the signatures which support this reconfiguration.\n\n\nThe \nread_set\n specifies a subset of the existing configuration,\nspecified sparsely where only the \nversion\n field is set and no other\nfields must be populated. The particular \nConfigValue\n \nvalue\n or\n\nConfigPolicy\n \npolicy\n fields should never be set in the \nread_set\n.\nThe \nConfigGroup\n may have a subset of its map fields populated, so as\nto reference an element deeper in the config tree. For instance, to\ninclude the \nApplication\n group in the \nread_set\n, its parent (the\n\nChannel\n group) must also be included in the read set, but, the\n\nChannel\n group does not need to populate all of the keys, such as the\n\nOrderer\n \ngroup\n key, or any of the \nvalues\n or \npolicies\n keys.\n\n\nThe \nwrite_set\n specifies the pieces of configuration which are\nmodified. Because of the hierarchical nature of the configuration, a\nwrite to an element deep in the hierarchy must contain the higher level\nelements in its \nwrite_set\n as well. However, for any element in the\n\nwrite_set\n which is also specified in the \nread_set\n at the same\nversion, the element should be specified sparsely, just as in the\n\nread_set\n.\n\n\nFor example, given the configuration:\n\n\nChannel: (version 0)\n    Orderer (version 0)\n    Appplication (version 3)\n       Org1 (version 2)\n\n\n\nTo submit a configuration update which modifies \nOrg1\n, the \nread_set\n\nwould be:\n\n\nChannel: (version 0)\n    Application: (version 3)\n\n\n\nand the \nwrite_set\n would be\n\n\nChannel: (version 0)\n    Application: (version 3)\n        Org1 (version 3)\n\n\n\nWhen the \nCONFIG_UPDATE\n is received, the orderer computes the resulting\n\nCONFIG\n by doing the following:\n\n\n\n\nVerifies the \nchannel_id\n and \nread_set\n. All elements in the\n    \nread_set\n must exist at the given versions.\n\n\nComputes the update set by collecting all elements in the\n    \nwrite_set\n which do not appear at the same version in the\n    \nread_set\n.\n\n\nVerifies that each element in the update set increments the version\n    number of the element update by exactly 1.\n\n\nVerifies that the signature set attached to the\n    \nConfigUpdateEnvelope\n satisfies the \nmod_policy\n for each element\n    in the update set.\n\n\nComputes a new complete version of the config by applying the update\n    set to the current config.\n\n\nWrites the new config into a \nConfigEnvelope\n which includes the\n    \nCONFIG_UPDATE\n as the \nlast_update\n field and the new config\n    encoded in the \nconfig\n field, along with the incremented \nsequence\n\n    value.\n\n\nWrites the new \nConfigEnvelope\n into a \nEnvelope\n of type \nCONFIG\n,\n    and ultimately writes this as the sole transaction in a new\n    configuration block.\n\n\n\n\nWhen the peer (or any other receiver for \nDeliver\n) receives this\nconfiguration block, it should verify that the config was appropriately\nvalidated by applying the \nlast_update\n message to the current config\nand verifying that the orderer-computed \nconfig\n field contains the\ncorrect new configuration.\n\n\nPermitted configuration groups and values\n\n\nAny valid configuration is a subset of the following configuration. Here\nwe use the notation \npeer.\nMSG\n to define a \nConfigValue\n whose \nvalue\n\nfield is a marshaled proto message of name \nMSG\n defined in\n\nfabric/protos/peer/configuration.proto\n. The notations \ncommon.\nMSG\n,\n\nmsp.\nMSG\n, and \norderer.\nMSG\n correspond similarly, but with their\nmessages defined in \nfabric/protos/common/configuration.proto\n,\n\nfabric/protos/msp/mspconfig.proto\n, and\n\nfabric/protos/orderer/configuration.proto\n respectively.\n\n\nNote, that the keys \n{{org_name}}\n and \n{{consortium_name}}\n represent\narbitrary names, and indicate an element which may be repeated with\ndifferent names.\n\n\nConfigGroup{\n    Groups: map\nstring, *ConfigGroup\n {\n        \"Application\":\nConfigGroup{\n            Groups:map\nString, *ConfigGroup\n {\n                {{org_name}}:\nConfigGroup{\n                    Values:map\nstring, *ConfigValue\n{\n                        \"MSP\":msp.MSPConfig,\n                        \"AnchorPeers\":peer.AnchorPeers,\n                    },\n                },\n            },\n        },\n        \"Orderer\":\nConfigGroup{\n            Groups:map\nString, *ConfigGroup\n {\n                {{org_name}}:\nConfigGroup{\n                    Values:map\nstring, *ConfigValue\n{\n                        \"MSP\":msp.MSPConfig,\n                    },\n                },\n            },\n\n            Values:map\nstring, *ConfigValue\n {\n                \"ConsensusType\":orderer.ConsensusType,\n                \"BatchSize\":orderer.BatchSize,\n                \"BatchTimeout\":orderer.BatchTimeout,\n                \"KafkaBrokers\":orderer.KafkaBrokers,\n            },\n        },\n        \"Consortiums\":\nConfigGroup{\n            Groups:map\nString, *ConfigGroup\n {\n                {{consortium_name}}:\nConfigGroup{\n                    Groups:map\nstring, *ConfigGroup\n {\n                        {{org_name}}:\nConfigGroup{\n                            Values:map\nstring, *ConfigValue\n{\n                                \"MSP\":msp.MSPConfig,\n                            },\n                        },\n                    },\n                    Values:map\nstring, *ConfigValue\n {\n                        \"ChannelCreationPolicy\":common.Policy,\n                    }\n                },\n            },\n        },\n    },\n\n    Values: map\nstring, *ConfigValue\n {\n        \"HashingAlgorithm\":common.HashingAlgorithm,\n        \"BlockHashingDataStructure\":common.BlockDataHashingStructure,\n        \"Consortium\":common.Consortium,\n        \"OrdererAddresses\":common.OrdererAddresses,\n    },\n}\n\n\n\nOrderer system channel configuration\n\n\nThe ordering system channel needs to define ordering parameters, and\nconsortiums for creating channels. There must be exactly one ordering\nsystem channel for an ordering service, and it is the first channel to\nbe created (or more accurately bootstrapped). It is recommended never to\ndefine an Application section inside of the ordering system channel\ngenesis configuration, but may be done for testing. Note that any member\nwith read access to the ordering system channel may see all channel\ncreations, so this channel\\'s access should be restricted.\n\n\nThe ordering parameters are defined as the following subset of config:\n\n\nConfigGroup{\n    Groups: map\nstring, *ConfigGroup\n {\n        \"Orderer\":\nConfigGroup{\n            Groups:map\nString, *ConfigGroup\n {\n                {{org_name}}:\nConfigGroup{\n                    Values:map\nstring, *ConfigValue\n{\n                        \"MSP\":msp.MSPConfig,\n                    },\n                },\n            },\n\n            Values:map\nstring, *ConfigValue\n {\n                \"ConsensusType\":orderer.ConsensusType,\n                \"BatchSize\":orderer.BatchSize,\n                \"BatchTimeout\":orderer.BatchTimeout,\n                \"KafkaBrokers\":orderer.KafkaBrokers,\n            },\n        },\n    },\n\n\n\nEach organization participating in ordering has a group element under\nthe \nOrderer\n group. This group defines a single parameter \nMSP\n which\ncontains the cryptographic identity information for that organization.\nThe \nValues\n of the \nOrderer\n group determine how the ordering nodes\nfunction. They exist per channel, so \norderer.BatchTimeout\n for instance\nmay be specified differently on one channel than another.\n\n\nAt startup, the orderer is faced with a filesystem which contains\ninformation for many channels. The orderer identifies the system channel\nby identifying the channel with the consortiums group defined. The\nconsortiums group has the following structure.\n\n\nConfigGroup{\n    Groups: map\nstring, *ConfigGroup\n {\n        \"Consortiums\":\nConfigGroup{\n            Groups:map\nString, *ConfigGroup\n {\n                {{consortium_name}}:\nConfigGroup{\n                    Groups:map\nstring, *ConfigGroup\n {\n                        {{org_name}}:\nConfigGroup{\n                            Values:map\nstring, *ConfigValue\n{\n                                \"MSP\":msp.MSPConfig,\n                            },\n                        },\n                    },\n                    Values:map\nstring, *ConfigValue\n {\n                        \"ChannelCreationPolicy\":common.Policy,\n                    }\n                },\n            },\n        },\n    },\n},\n\n\n\nNote that each consortium defines a set of members, just like the\norganizational members for the ordering orgs. Each consortium also\ndefines a \nChannelCreationPolicy\n. This is a policy which is applied to\nauthorize channel creation requests. Typically, this value will be set\nto an \nImplicitMetaPolicy\n requiring that the new members of the channel\nsign to authorize the channel creation. More details about channel\ncreation follow later in this document.\n\n\nApplication channel configuration\n\n\nApplication configuration is for channels which are designed for\napplication type transactions. It is defined as follows:\n\n\nConfigGroup{\n    Groups: map\nstring, *ConfigGroup\n {\n        \"Application\":\nConfigGroup{\n            Groups:map\nString, *ConfigGroup\n {\n                {{org_name}}:\nConfigGroup{\n                    Values:map\nstring, *ConfigValue\n{\n                        \"MSP\":msp.MSPConfig,\n                        \"AnchorPeers\":peer.AnchorPeers,\n                    },\n                },\n            },\n        },\n    },\n}\n\n\n\nJust like with the \nOrderer\n section, each organization is encoded as a\ngroup. However, instead of only encoding the \nMSP\n identity information,\neach org additionally encodes a list of \nAnchorPeers\n. This list allows\nthe peers of different organizations to contact each other for peer\ngossip networking.\n\n\nThe application channel encodes a copy of the orderer orgs and consensus\noptions to allow for deterministic updating of these parameters, so the\nsame \nOrderer\n section from the orderer system channel configuration is\nincluded. However from an application perspective this may be largely\nignored.\n\n\nChannel creation\n\n\nWhen the orderer receives a \nCONFIG_UPDATE\n for a channel which does not\nexist, the orderer assumes that this must be a channel creation request\nand performs the following.\n\n\n\n\nThe orderer identifies the consortium which the channel creation\n    request is to be performed for. It does this by looking at the\n    \nConsortium\n value of the top level group.\n\n\nThe orderer verifies that the organizations included in the\n    \nApplication\n group are a subset of the organizations included in\n    the corresponding consortium and that the \nApplicationGroup\n is set\n    to \nversion\n \n1\n.\n\n\nThe orderer verifies that if the consortium has members, that the\n    new channel also has application members (creation consortiums and\n    channels with no members is useful for testing only).\n\n\nThe orderer creates a template configuration by taking the \nOrderer\n\n    group from the ordering system channel, and creating an\n    \nApplication\n group with the newly specified members and specifying\n    its \nmod_policy\n to be the \nChannelCreationPolicy\n as specified in\n    the consortium config. Note that the policy is evaluated in the\n    context of the new configuration, so a policy requiring \nALL\n\n    members, would require signatures from all the new channel members,\n    not all the members of the consortium.\n\n\nThe orderer then applies the \nCONFIG_UPDATE\n as an update to this\n    template configuration. Because the \nCONFIG_UPDATE\n applies\n    modifications to the \nApplication\n group (its \nversion\n is \n1\n), the\n    config code validates these updates against the\n    \nChannelCreationPolicy\n. If the channel creation contains any other\n    modifications, such as to an individual org\\'s anchor peers, the\n    corresponding mod policy for the element will be invoked.\n\n\nThe new \nCONFIG\n transaction with the new channel config is wrapped\n    and sent for ordering on the ordering system channel. After\n    ordering, the channel is created.", 
            "title": "Channel Configuration"
        }, 
        {
            "location": "/configtx/#channel-configuration-configtx", 
            "text": "Shared configuration for a Hyperledger Fabric blockchain network is\nstored in a collection configuration transactions, one per channel. Each\nconfiguration transaction is usually referred to by the shorter name configtx .  Channel configuration has the following important properties:   Versioned : All elements of the configuration have an associated\n    version which is advanced with every modification. Further, every\n    committed configuration receives a sequence number.  Permissioned : Each element of the configuration has an\n    associated policy which governs whether or not modification to that\n    element is permitted. Anyone with a copy of the previous configtx\n    (and no additional info) may verify the validity of a new config\n    based on these policies.  Hierarchical : A root configuration group contains sub-groups,\n    and each group of the hierarchy has associated values and policies.\n    These policies can take advantage of the hierarchy to derive\n    policies at one level from policies of lower levels.", 
            "title": "Channel Configuration (configtx)"
        }, 
        {
            "location": "/configtx/#anatomy-of-a-configuration", 
            "text": "Configuration is stored as a transaction of type  HeaderType_CONFIG  in\na block with no other transactions. These blocks are referred to as Configuration Blocks , the first of which is referred to as the Genesis Block .  The proto structures for configuration are stored in fabric/protos/common/configtx.proto . The Envelope of type HeaderType_CONFIG  encodes a  ConfigEnvelope  message as the  Payload  data  field. The proto for  ConfigEnvelope  is defined as follows:  message ConfigEnvelope {\n    Config config = 1;\n    Envelope last_update = 2;\n}  The  last_update  field is defined below in the  Updates to\nconfiguration  section, but is only necessary when validating the\nconfiguration, not reading it. Instead, the currently committed\nconfiguration is stored in the  config  field, containing a  Config \nmessage.  message Config {\n    uint64 sequence = 1;\n    ConfigGroup channel_group = 2;\n}  The  sequence  number is incremented by one for each committed\nconfiguration. The  channel_group  field is the root group which\ncontains the configuration. The  ConfigGroup  structure is recursively\ndefined, and builds a tree of groups, each of which contains values and\npolicies. It is defined as follows:  message ConfigGroup {\n    uint64 version = 1;\n    map string,ConfigGroup  groups = 2;\n    map string,ConfigValue  values = 3;\n    map string,ConfigPolicy  policies = 4;\n    string mod_policy = 5;\n}  Because  ConfigGroup  is a recursive structure, it has hierarchical\narrangement. The following example is expressed for clarity in golang\nnotation.  // Assume the following groups are defined\nvar root, child1, child2, grandChild1, grandChild2, grandChild3 *ConfigGroup\n\n// Set the following values\nroot.Groups[\"child1\"] = child1\nroot.Groups[\"child2\"] = child2\nchild1.Groups[\"grandChild1\"] = grandChild1\nchild2.Groups[\"grandChild2\"] = grandChild2\nchild2.Groups[\"grandChild3\"] = grandChild3\n\n// The resulting config structure of groups looks like:\n// root:\n//     child1:\n//         grandChild1\n//     child2:\n//         grandChild2\n//         grandChild3  Each group defines a level in the config hierarchy, and each group has\nan associated set of values (indexed by string key) and policies (also\nindexed by string key).  Values are defined by:  message ConfigValue {\n    uint64 version = 1;\n    bytes value = 2;\n    string mod_policy = 3;\n}  Policies are defined by:  message ConfigPolicy {\n    uint64 version = 1;\n    Policy policy = 2;\n    string mod_policy = 3;\n}  Note that Values, Policies, and Groups all have a  version  and a mod_policy . The  version  of an element is incremented each time that\nelement is modified. The  mod_policy  is used to govern the required\nsignatures to modify that element. For Groups, modification is adding or\nremoving elements to the Values, Policies, or Groups maps (or changing\nthe  mod_policy ). For Values and Policies, modification is changing the\nValue and Policy fields respectively (or changing the  mod_policy ).\nEach element\\'s  mod_policy  is evaluated in the context of the current\nlevel of the config. Consider the following example mod policies defined\nat  Channel.Groups[\"Application\"]  (Here, we use the golang map\nreference syntax, so  Channel.Groups[\"Application\"].Policies[\"policy1\"] \nrefers to the base  Channel  group\\'s  Application  group\\'s  Policies \nmap\\'s  policy1  policy.)   policy1  maps to\n     Channel.Groups[\"Application\"].Policies[\"policy1\"]  Org1/policy2  maps to\n     Channel.Groups[\"Application\"].Groups[\"Org1\"].Policies[\"policy2\"]  /Channel/policy3  maps to  Channel.Policies[\"policy3\"]   Note that if a  mod_policy  references a policy which does not exist,\nthe item cannot be modified.", 
            "title": "Anatomy of a configuration"
        }, 
        {
            "location": "/configtx/#configuration-updates", 
            "text": "Configuration updates are submitted as an  Envelope  message of type HeaderType_CONFIG_UPDATE . The  Payload   data  of the transaction is a\nmarshaled  ConfigUpdateEnvelope . The  ConfigUpdateEnvelope  is defined\nas follows:  message ConfigUpdateEnvelope {\n    bytes config_update = 1;\n    repeated ConfigSignature signatures = 2;\n}  The  signatures  field contains the set of signatures which authorizes\nthe config update. Its message definition is:  message ConfigSignature {\n    bytes signature_header = 1;\n    bytes signature = 2;\n}  The  signature_header  is as defined for standard transactions, while\nthe signature is over the concatenation of the  signature_header  bytes\nand the  config_update  bytes from the  ConfigUpdateEnvelope  message.  The  ConfigUpdateEnvelope   config_update  bytes are a marshaled ConfigUpdate  message which is defined as follows:  message ConfigUpdate {\n    string channel_id = 1;\n    ConfigGroup read_set = 2;\n    ConfigGroup write_set = 3;\n}  The  channel_id  is the channel ID the update is bound for, this is\nnecessary to scope the signatures which support this reconfiguration.  The  read_set  specifies a subset of the existing configuration,\nspecified sparsely where only the  version  field is set and no other\nfields must be populated. The particular  ConfigValue   value  or ConfigPolicy   policy  fields should never be set in the  read_set .\nThe  ConfigGroup  may have a subset of its map fields populated, so as\nto reference an element deeper in the config tree. For instance, to\ninclude the  Application  group in the  read_set , its parent (the Channel  group) must also be included in the read set, but, the Channel  group does not need to populate all of the keys, such as the Orderer   group  key, or any of the  values  or  policies  keys.  The  write_set  specifies the pieces of configuration which are\nmodified. Because of the hierarchical nature of the configuration, a\nwrite to an element deep in the hierarchy must contain the higher level\nelements in its  write_set  as well. However, for any element in the write_set  which is also specified in the  read_set  at the same\nversion, the element should be specified sparsely, just as in the read_set .  For example, given the configuration:  Channel: (version 0)\n    Orderer (version 0)\n    Appplication (version 3)\n       Org1 (version 2)  To submit a configuration update which modifies  Org1 , the  read_set \nwould be:  Channel: (version 0)\n    Application: (version 3)  and the  write_set  would be  Channel: (version 0)\n    Application: (version 3)\n        Org1 (version 3)  When the  CONFIG_UPDATE  is received, the orderer computes the resulting CONFIG  by doing the following:   Verifies the  channel_id  and  read_set . All elements in the\n     read_set  must exist at the given versions.  Computes the update set by collecting all elements in the\n     write_set  which do not appear at the same version in the\n     read_set .  Verifies that each element in the update set increments the version\n    number of the element update by exactly 1.  Verifies that the signature set attached to the\n     ConfigUpdateEnvelope  satisfies the  mod_policy  for each element\n    in the update set.  Computes a new complete version of the config by applying the update\n    set to the current config.  Writes the new config into a  ConfigEnvelope  which includes the\n     CONFIG_UPDATE  as the  last_update  field and the new config\n    encoded in the  config  field, along with the incremented  sequence \n    value.  Writes the new  ConfigEnvelope  into a  Envelope  of type  CONFIG ,\n    and ultimately writes this as the sole transaction in a new\n    configuration block.   When the peer (or any other receiver for  Deliver ) receives this\nconfiguration block, it should verify that the config was appropriately\nvalidated by applying the  last_update  message to the current config\nand verifying that the orderer-computed  config  field contains the\ncorrect new configuration.", 
            "title": "Configuration updates"
        }, 
        {
            "location": "/configtx/#permitted-configuration-groups-and-values", 
            "text": "Any valid configuration is a subset of the following configuration. Here\nwe use the notation  peer. MSG  to define a  ConfigValue  whose  value \nfield is a marshaled proto message of name  MSG  defined in fabric/protos/peer/configuration.proto . The notations  common. MSG , msp. MSG , and  orderer. MSG  correspond similarly, but with their\nmessages defined in  fabric/protos/common/configuration.proto , fabric/protos/msp/mspconfig.proto , and fabric/protos/orderer/configuration.proto  respectively.  Note, that the keys  {{org_name}}  and  {{consortium_name}}  represent\narbitrary names, and indicate an element which may be repeated with\ndifferent names.  ConfigGroup{\n    Groups: map string, *ConfigGroup  {\n        \"Application\": ConfigGroup{\n            Groups:map String, *ConfigGroup  {\n                {{org_name}}: ConfigGroup{\n                    Values:map string, *ConfigValue {\n                        \"MSP\":msp.MSPConfig,\n                        \"AnchorPeers\":peer.AnchorPeers,\n                    },\n                },\n            },\n        },\n        \"Orderer\": ConfigGroup{\n            Groups:map String, *ConfigGroup  {\n                {{org_name}}: ConfigGroup{\n                    Values:map string, *ConfigValue {\n                        \"MSP\":msp.MSPConfig,\n                    },\n                },\n            },\n\n            Values:map string, *ConfigValue  {\n                \"ConsensusType\":orderer.ConsensusType,\n                \"BatchSize\":orderer.BatchSize,\n                \"BatchTimeout\":orderer.BatchTimeout,\n                \"KafkaBrokers\":orderer.KafkaBrokers,\n            },\n        },\n        \"Consortiums\": ConfigGroup{\n            Groups:map String, *ConfigGroup  {\n                {{consortium_name}}: ConfigGroup{\n                    Groups:map string, *ConfigGroup  {\n                        {{org_name}}: ConfigGroup{\n                            Values:map string, *ConfigValue {\n                                \"MSP\":msp.MSPConfig,\n                            },\n                        },\n                    },\n                    Values:map string, *ConfigValue  {\n                        \"ChannelCreationPolicy\":common.Policy,\n                    }\n                },\n            },\n        },\n    },\n\n    Values: map string, *ConfigValue  {\n        \"HashingAlgorithm\":common.HashingAlgorithm,\n        \"BlockHashingDataStructure\":common.BlockDataHashingStructure,\n        \"Consortium\":common.Consortium,\n        \"OrdererAddresses\":common.OrdererAddresses,\n    },\n}", 
            "title": "Permitted configuration groups and values"
        }, 
        {
            "location": "/configtx/#orderer-system-channel-configuration", 
            "text": "The ordering system channel needs to define ordering parameters, and\nconsortiums for creating channels. There must be exactly one ordering\nsystem channel for an ordering service, and it is the first channel to\nbe created (or more accurately bootstrapped). It is recommended never to\ndefine an Application section inside of the ordering system channel\ngenesis configuration, but may be done for testing. Note that any member\nwith read access to the ordering system channel may see all channel\ncreations, so this channel\\'s access should be restricted.  The ordering parameters are defined as the following subset of config:  ConfigGroup{\n    Groups: map string, *ConfigGroup  {\n        \"Orderer\": ConfigGroup{\n            Groups:map String, *ConfigGroup  {\n                {{org_name}}: ConfigGroup{\n                    Values:map string, *ConfigValue {\n                        \"MSP\":msp.MSPConfig,\n                    },\n                },\n            },\n\n            Values:map string, *ConfigValue  {\n                \"ConsensusType\":orderer.ConsensusType,\n                \"BatchSize\":orderer.BatchSize,\n                \"BatchTimeout\":orderer.BatchTimeout,\n                \"KafkaBrokers\":orderer.KafkaBrokers,\n            },\n        },\n    },  Each organization participating in ordering has a group element under\nthe  Orderer  group. This group defines a single parameter  MSP  which\ncontains the cryptographic identity information for that organization.\nThe  Values  of the  Orderer  group determine how the ordering nodes\nfunction. They exist per channel, so  orderer.BatchTimeout  for instance\nmay be specified differently on one channel than another.  At startup, the orderer is faced with a filesystem which contains\ninformation for many channels. The orderer identifies the system channel\nby identifying the channel with the consortiums group defined. The\nconsortiums group has the following structure.  ConfigGroup{\n    Groups: map string, *ConfigGroup  {\n        \"Consortiums\": ConfigGroup{\n            Groups:map String, *ConfigGroup  {\n                {{consortium_name}}: ConfigGroup{\n                    Groups:map string, *ConfigGroup  {\n                        {{org_name}}: ConfigGroup{\n                            Values:map string, *ConfigValue {\n                                \"MSP\":msp.MSPConfig,\n                            },\n                        },\n                    },\n                    Values:map string, *ConfigValue  {\n                        \"ChannelCreationPolicy\":common.Policy,\n                    }\n                },\n            },\n        },\n    },\n},  Note that each consortium defines a set of members, just like the\norganizational members for the ordering orgs. Each consortium also\ndefines a  ChannelCreationPolicy . This is a policy which is applied to\nauthorize channel creation requests. Typically, this value will be set\nto an  ImplicitMetaPolicy  requiring that the new members of the channel\nsign to authorize the channel creation. More details about channel\ncreation follow later in this document.", 
            "title": "Orderer system channel configuration"
        }, 
        {
            "location": "/configtx/#application-channel-configuration", 
            "text": "Application configuration is for channels which are designed for\napplication type transactions. It is defined as follows:  ConfigGroup{\n    Groups: map string, *ConfigGroup  {\n        \"Application\": ConfigGroup{\n            Groups:map String, *ConfigGroup  {\n                {{org_name}}: ConfigGroup{\n                    Values:map string, *ConfigValue {\n                        \"MSP\":msp.MSPConfig,\n                        \"AnchorPeers\":peer.AnchorPeers,\n                    },\n                },\n            },\n        },\n    },\n}  Just like with the  Orderer  section, each organization is encoded as a\ngroup. However, instead of only encoding the  MSP  identity information,\neach org additionally encodes a list of  AnchorPeers . This list allows\nthe peers of different organizations to contact each other for peer\ngossip networking.  The application channel encodes a copy of the orderer orgs and consensus\noptions to allow for deterministic updating of these parameters, so the\nsame  Orderer  section from the orderer system channel configuration is\nincluded. However from an application perspective this may be largely\nignored.", 
            "title": "Application channel configuration"
        }, 
        {
            "location": "/configtx/#channel-creation", 
            "text": "When the orderer receives a  CONFIG_UPDATE  for a channel which does not\nexist, the orderer assumes that this must be a channel creation request\nand performs the following.   The orderer identifies the consortium which the channel creation\n    request is to be performed for. It does this by looking at the\n     Consortium  value of the top level group.  The orderer verifies that the organizations included in the\n     Application  group are a subset of the organizations included in\n    the corresponding consortium and that the  ApplicationGroup  is set\n    to  version   1 .  The orderer verifies that if the consortium has members, that the\n    new channel also has application members (creation consortiums and\n    channels with no members is useful for testing only).  The orderer creates a template configuration by taking the  Orderer \n    group from the ordering system channel, and creating an\n     Application  group with the newly specified members and specifying\n    its  mod_policy  to be the  ChannelCreationPolicy  as specified in\n    the consortium config. Note that the policy is evaluated in the\n    context of the new configuration, so a policy requiring  ALL \n    members, would require signatures from all the new channel members,\n    not all the members of the consortium.  The orderer then applies the  CONFIG_UPDATE  as an update to this\n    template configuration. Because the  CONFIG_UPDATE  applies\n    modifications to the  Application  group (its  version  is  1 ), the\n    config code validates these updates against the\n     ChannelCreationPolicy . If the channel creation contains any other\n    modifications, such as to an individual org\\'s anchor peers, the\n    corresponding mod policy for the element will be invoked.  The new  CONFIG  transaction with the new channel config is wrapped\n    and sent for ordering on the ordering system channel. After\n    ordering, the channel is created.", 
            "title": "Channel creation"
        }, 
        {
            "location": "/configtxgen/", 
            "text": "Channel Configuration (configtxgen)\n\n\nThis document describe the usage for the \nconfigtxgen\n utility for\nmanipulating Hyperledger Fabric channel configuration.\n\n\nFor now, the tool is primarily focused on generating the genesis block\nfor bootstrapping the orderer, but it is intended to be enhanced in the\nfuture for generating new channel configurations as well as\nreconfiguring existing channels.\n\n\nConfiguration Profiles\n\n\nThe configuration parameters supplied to the \nconfigtxgen\n tool are\nprimarily provided by the \nconfigtx.yaml\n file. This file is located at\n\nfabric/sampleconfig/configtx.yaml\n in the fabric.git repository.\n\n\nThis configuration file is split primarily into three pieces.\n\n\n\n\nThe \nProfiles\n section. By default, this section includes some\n    sample configurations which can be used for development or testing\n    scenarios, and refer to crypto material present in the fabric.git\n    tree. These profiles can make a good starting point for construction\n    a real deployment profile. The \nconfigtxgen\n tool allows you to\n    specify the profile it is operating under by passing the \n-profile\n\n    flag. Profiles may explicitly declare all configuration, but usually\n    inherit configuration from the defaults in (3) below.\n\n\nThe \nOrganizations\n section. By default, this section includes a\n    single reference to the sampleconfig MSP definition. For production\n    deployments, the sample organization should be removed, and the MSP\n    definitions of the network members should be referenced and defined\n    instead. Each element in the \nOrganizations\n section should be\n    tagged with an anchor label such as \norgName\n which will allow the\n    definition to be referenced in the \nProfiles\n sections.\n\n\nThe default sections. There are default sections for \nOrderer\n and\n    \nApplication\n configuration, these include attributes like\n    \nBatchTimeout\n and are generally used as the base inherited values\n    for the profiles.\n\n\n\n\nThis configuration file may be edited, or, individual properties may be\noverridden by setting environment variables, such as\n\nCONFIGTX_ORDERER_ORDERERTYPE=kafka\n. Note that the \nProfiles\n element\nand profile name do not need to be specified.\n\n\nBootstrapping the orderer\n\n\nAfter creating a configuration profile as desired, simply invoke\n\n\nconfigtxgen -profile \nprofile_name\n -outputBlock orderer_genesisblock.pb\n\n\n\nThis will produce an \norderer_genesisblock.pb\n file in the current\ndirectory. This genesis block is used to bootstrap the ordering system\nchannel, which the orderers use to authorize and orchestrate creation of\nother channels. By default, the channel ID encoded into the genesis\nblock by \nconfigtxgen\n will be \ntestchainid\n. It is recommended that you\nmodify this identifier to something which will be globally unique.\n\n\nThen, to utilize this genesis block, before starting the orderer, simply\nspecify \nORDERER_GENERAL_GENESISMETHOD=file\n and\n\nORDERER_GENERAL_GENESISFILE=$PWD/orderer_genesisblock.pb\n or modify the\n\norderer.yaml\n file to encode these values.\n\n\nCreating a channel\n\n\nThe tool can also output a channel creation tx by executing\n\n\nconfigtxgen -profile \nprofile_name\n -channelID \nchannel_name\n -outputCreateChannelTx \ntx_filename\n\n\n\n\nThis will output a marshaled \nEnvelope\n message which may be sent to\nbroadcast to create a channel.\n\n\nReviewing a configuration\n\n\nIn addition to creating configuration, the \nconfigtxgen\n tool is also\ncapable of inspecting configuration.\n\n\nIt supports inspecting both configuration blocks, and configuration\ntransactions. You may use the inspect flags \n-inspectBlock\n and\n\n-inspectChannelCreateTx\n respectively with the path to a file to\ninspect to output a human readable (JSON) representation of the\nconfiguration.\n\n\nYou may even wish to combine the inspection with generation. For\nexample:\n\n\n$ build/bin/configtxgen -channelID foo -outputBlock foo_genesisblock.pb -inspectBlock foo_genesisblock.pb\n2017-11-02 17:56:04.489 EDT [common/tools/configtxgen] main -\n INFO 001 Loading configuration\n2017-11-02 17:56:04.564 EDT [common/tools/configtxgen] doOutputBlock -\n INFO 002 Generating genesis block\n2017-11-02 17:56:04.564 EDT [common/tools/configtxgen] doOutputBlock -\n INFO 003 Writing genesis block\n2017-11-02 17:56:04.564 EDT [common/tools/configtxgen] doInspectBlock -\n INFO 004 Inspecting block\n2017-11-02 17:56:04.564 EDT [common/tools/configtxgen] doInspectBlock -\n INFO 005 Parsing genesis block\n{\n  \"data\": {\n    \"data\": [\n      {\n        \"payload\": {\n          \"data\": {\n            \"config\": {\n              \"channel_group\": {\n                \"groups\": {\n                  \"Consortiums\": {\n                    \"groups\": {\n                      \"SampleConsortium\": {\n                        \"mod_policy\": \"/Channel/Orderer/Admins\",\n                        \"values\": {\n                          \"ChannelCreationPolicy\": {\n                            \"mod_policy\": \"/Channel/Orderer/Admins\",\n                            \"value\": {\n                              \"type\": 3,\n                              \"value\": {\n                                \"rule\": \"ANY\",\n                                \"sub_policy\": \"Admins\"\n                              }\n                            },\n                            \"version\": \"0\"\n                          }\n                        },\n                        \"version\": \"0\"\n                      }\n                    },\n                    \"mod_policy\": \"/Channel/Orderer/Admins\",\n                    \"policies\": {\n                      \"Admins\": {\n                        \"mod_policy\": \"/Channel/Orderer/Admins\",\n                        \"policy\": {\n                          \"type\": 1,\n                          \"value\": {\n                            \"rule\": {\n                              \"n_out_of\": {\n                                \"n\": 0\n                              }\n                            },\n                            \"version\": 0\n                          }\n                        },\n                        \"version\": \"0\"\n                      }\n                    },\n                    \"version\": \"0\"\n                  },\n                  \"Orderer\": {\n                    \"mod_policy\": \"Admins\",\n                    \"policies\": {\n                      \"Admins\": {\n                        \"mod_policy\": \"Admins\",\n                        \"policy\": {\n                          \"type\": 3,\n                          \"value\": {\n                            \"rule\": \"MAJORITY\",\n                            \"sub_policy\": \"Admins\"\n                          }\n                        },\n                        \"version\": \"0\"\n                      },\n                      \"BlockValidation\": {\n                        \"mod_policy\": \"Admins\",\n                        \"policy\": {\n                          \"type\": 3,\n                          \"value\": {\n                            \"rule\": \"ANY\",\n                            \"sub_policy\": \"Writers\"\n                          }\n                        },\n                        \"version\": \"0\"\n                      },\n                      \"Readers\": {\n                        \"mod_policy\": \"Admins\",\n                        \"policy\": {\n                          \"type\": 3,\n                          \"value\": {\n                            \"rule\": \"ANY\",\n                            \"sub_policy\": \"Readers\"\n                          }\n                        },\n                        \"version\": \"0\"\n                      },\n                      \"Writers\": {\n                        \"mod_policy\": \"Admins\",\n                        \"policy\": {\n                          \"type\": 3,\n                          \"value\": {\n                            \"rule\": \"ANY\",\n                            \"sub_policy\": \"Writers\"\n                          }\n                        },\n                        \"version\": \"0\"\n                      }\n                    },\n                    \"values\": {\n                      \"BatchSize\": {\n                        \"mod_policy\": \"Admins\",\n                        \"value\": {\n                          \"absolute_max_bytes\": 10485760,\n                          \"max_message_count\": 10,\n                          \"preferred_max_bytes\": 524288\n                        },\n                        \"version\": \"0\"\n                      },\n                      \"BatchTimeout\": {\n                        \"mod_policy\": \"Admins\",\n                        \"value\": {\n                          \"timeout\": \"2s\"\n                        },\n                        \"version\": \"0\"\n                      },\n                      \"ChannelRestrictions\": {\n                        \"mod_policy\": \"Admins\",\n                        \"version\": \"0\"\n                      },\n                      \"ConsensusType\": {\n                        \"mod_policy\": \"Admins\",\n                        \"value\": {\n                          \"type\": \"solo\"\n                        },\n                        \"version\": \"0\"\n                      }\n                    },\n                    \"version\": \"0\"\n                  }\n                },\n                \"mod_policy\": \"Admins\",\n                \"policies\": {\n                  \"Admins\": {\n                    \"mod_policy\": \"Admins\",\n                    \"policy\": {\n                      \"type\": 3,\n                      \"value\": {\n                        \"rule\": \"MAJORITY\",\n                        \"sub_policy\": \"Admins\"\n                      }\n                    },\n                    \"version\": \"0\"\n                  },\n                  \"Readers\": {\n                    \"mod_policy\": \"Admins\",\n                    \"policy\": {\n                      \"type\": 3,\n                      \"value\": {\n                        \"rule\": \"ANY\",\n                        \"sub_policy\": \"Readers\"\n                      }\n                    },\n                    \"version\": \"0\"\n                  },\n                  \"Writers\": {\n                    \"mod_policy\": \"Admins\",\n                    \"policy\": {\n                      \"type\": 3,\n                      \"value\": {\n                        \"rule\": \"ANY\",\n                        \"sub_policy\": \"Writers\"\n                      }\n                    },\n                    \"version\": \"0\"\n                  }\n                },\n                \"values\": {\n                  \"BlockDataHashingStructure\": {\n                    \"mod_policy\": \"Admins\",\n                    \"value\": {\n                      \"width\": 4294967295\n                    },\n                    \"version\": \"0\"\n                  },\n                  \"HashingAlgorithm\": {\n                    \"mod_policy\": \"Admins\",\n                    \"value\": {\n                      \"name\": \"SHA256\"\n                    },\n                    \"version\": \"0\"\n                  },\n                  \"OrdererAddresses\": {\n                    \"mod_policy\": \"/Channel/Orderer/Admins\",\n                    \"value\": {\n                      \"addresses\": [\n                        \"127.0.0.1:7050\"\n                      ]\n                    },\n                    \"version\": \"0\"\n                  }\n                },\n                \"version\": \"0\"\n              },\n              \"sequence\": \"0\",\n              \"type\": 0\n            }\n          },\n          \"header\": {\n            \"channel_header\": {\n              \"channel_id\": \"foo\",\n              \"epoch\": \"0\",\n              \"timestamp\": \"2017-11-02T21:56:04.000Z\",\n              \"tx_id\": \"6acfe1257c23a4f844cc299cbf53acc7bf8fa8bcf8aae8d049193098fe982eab\",\n              \"type\": 1,\n              \"version\": 1\n            },\n            \"signature_header\": {\n              \"nonce\": \"eZOKru6jmeiWykBtSDwnkGjyQt69GwuS\"\n            }\n          }\n        }\n      }\n    ]\n  },\n  \"header\": {\n    \"data_hash\": \"/86I/7NScbH/bHcDcYG0/9qTmVPWVoVVfSN8NKMARKI=\",\n    \"number\": \"0\"\n  },\n  \"metadata\": {\n    \"metadata\": [\n      \"\",\n      \"\",\n      \"\",\n      \"\"\n    ]\n  }\n}", 
            "title": "Generating Channel Configuration"
        }, 
        {
            "location": "/configtxgen/#channel-configuration-configtxgen", 
            "text": "This document describe the usage for the  configtxgen  utility for\nmanipulating Hyperledger Fabric channel configuration.  For now, the tool is primarily focused on generating the genesis block\nfor bootstrapping the orderer, but it is intended to be enhanced in the\nfuture for generating new channel configurations as well as\nreconfiguring existing channels.", 
            "title": "Channel Configuration (configtxgen)"
        }, 
        {
            "location": "/configtxgen/#configuration-profiles", 
            "text": "The configuration parameters supplied to the  configtxgen  tool are\nprimarily provided by the  configtx.yaml  file. This file is located at fabric/sampleconfig/configtx.yaml  in the fabric.git repository.  This configuration file is split primarily into three pieces.   The  Profiles  section. By default, this section includes some\n    sample configurations which can be used for development or testing\n    scenarios, and refer to crypto material present in the fabric.git\n    tree. These profiles can make a good starting point for construction\n    a real deployment profile. The  configtxgen  tool allows you to\n    specify the profile it is operating under by passing the  -profile \n    flag. Profiles may explicitly declare all configuration, but usually\n    inherit configuration from the defaults in (3) below.  The  Organizations  section. By default, this section includes a\n    single reference to the sampleconfig MSP definition. For production\n    deployments, the sample organization should be removed, and the MSP\n    definitions of the network members should be referenced and defined\n    instead. Each element in the  Organizations  section should be\n    tagged with an anchor label such as  orgName  which will allow the\n    definition to be referenced in the  Profiles  sections.  The default sections. There are default sections for  Orderer  and\n     Application  configuration, these include attributes like\n     BatchTimeout  and are generally used as the base inherited values\n    for the profiles.   This configuration file may be edited, or, individual properties may be\noverridden by setting environment variables, such as CONFIGTX_ORDERER_ORDERERTYPE=kafka . Note that the  Profiles  element\nand profile name do not need to be specified.", 
            "title": "Configuration Profiles"
        }, 
        {
            "location": "/configtxgen/#bootstrapping-the-orderer", 
            "text": "After creating a configuration profile as desired, simply invoke  configtxgen -profile  profile_name  -outputBlock orderer_genesisblock.pb  This will produce an  orderer_genesisblock.pb  file in the current\ndirectory. This genesis block is used to bootstrap the ordering system\nchannel, which the orderers use to authorize and orchestrate creation of\nother channels. By default, the channel ID encoded into the genesis\nblock by  configtxgen  will be  testchainid . It is recommended that you\nmodify this identifier to something which will be globally unique.  Then, to utilize this genesis block, before starting the orderer, simply\nspecify  ORDERER_GENERAL_GENESISMETHOD=file  and ORDERER_GENERAL_GENESISFILE=$PWD/orderer_genesisblock.pb  or modify the orderer.yaml  file to encode these values.", 
            "title": "Bootstrapping the orderer"
        }, 
        {
            "location": "/configtxgen/#creating-a-channel", 
            "text": "The tool can also output a channel creation tx by executing  configtxgen -profile  profile_name  -channelID  channel_name  -outputCreateChannelTx  tx_filename   This will output a marshaled  Envelope  message which may be sent to\nbroadcast to create a channel.", 
            "title": "Creating a channel"
        }, 
        {
            "location": "/configtxgen/#reviewing-a-configuration", 
            "text": "In addition to creating configuration, the  configtxgen  tool is also\ncapable of inspecting configuration.  It supports inspecting both configuration blocks, and configuration\ntransactions. You may use the inspect flags  -inspectBlock  and -inspectChannelCreateTx  respectively with the path to a file to\ninspect to output a human readable (JSON) representation of the\nconfiguration.  You may even wish to combine the inspection with generation. For\nexample:  $ build/bin/configtxgen -channelID foo -outputBlock foo_genesisblock.pb -inspectBlock foo_genesisblock.pb\n2017-11-02 17:56:04.489 EDT [common/tools/configtxgen] main -  INFO 001 Loading configuration\n2017-11-02 17:56:04.564 EDT [common/tools/configtxgen] doOutputBlock -  INFO 002 Generating genesis block\n2017-11-02 17:56:04.564 EDT [common/tools/configtxgen] doOutputBlock -  INFO 003 Writing genesis block\n2017-11-02 17:56:04.564 EDT [common/tools/configtxgen] doInspectBlock -  INFO 004 Inspecting block\n2017-11-02 17:56:04.564 EDT [common/tools/configtxgen] doInspectBlock -  INFO 005 Parsing genesis block\n{\n  \"data\": {\n    \"data\": [\n      {\n        \"payload\": {\n          \"data\": {\n            \"config\": {\n              \"channel_group\": {\n                \"groups\": {\n                  \"Consortiums\": {\n                    \"groups\": {\n                      \"SampleConsortium\": {\n                        \"mod_policy\": \"/Channel/Orderer/Admins\",\n                        \"values\": {\n                          \"ChannelCreationPolicy\": {\n                            \"mod_policy\": \"/Channel/Orderer/Admins\",\n                            \"value\": {\n                              \"type\": 3,\n                              \"value\": {\n                                \"rule\": \"ANY\",\n                                \"sub_policy\": \"Admins\"\n                              }\n                            },\n                            \"version\": \"0\"\n                          }\n                        },\n                        \"version\": \"0\"\n                      }\n                    },\n                    \"mod_policy\": \"/Channel/Orderer/Admins\",\n                    \"policies\": {\n                      \"Admins\": {\n                        \"mod_policy\": \"/Channel/Orderer/Admins\",\n                        \"policy\": {\n                          \"type\": 1,\n                          \"value\": {\n                            \"rule\": {\n                              \"n_out_of\": {\n                                \"n\": 0\n                              }\n                            },\n                            \"version\": 0\n                          }\n                        },\n                        \"version\": \"0\"\n                      }\n                    },\n                    \"version\": \"0\"\n                  },\n                  \"Orderer\": {\n                    \"mod_policy\": \"Admins\",\n                    \"policies\": {\n                      \"Admins\": {\n                        \"mod_policy\": \"Admins\",\n                        \"policy\": {\n                          \"type\": 3,\n                          \"value\": {\n                            \"rule\": \"MAJORITY\",\n                            \"sub_policy\": \"Admins\"\n                          }\n                        },\n                        \"version\": \"0\"\n                      },\n                      \"BlockValidation\": {\n                        \"mod_policy\": \"Admins\",\n                        \"policy\": {\n                          \"type\": 3,\n                          \"value\": {\n                            \"rule\": \"ANY\",\n                            \"sub_policy\": \"Writers\"\n                          }\n                        },\n                        \"version\": \"0\"\n                      },\n                      \"Readers\": {\n                        \"mod_policy\": \"Admins\",\n                        \"policy\": {\n                          \"type\": 3,\n                          \"value\": {\n                            \"rule\": \"ANY\",\n                            \"sub_policy\": \"Readers\"\n                          }\n                        },\n                        \"version\": \"0\"\n                      },\n                      \"Writers\": {\n                        \"mod_policy\": \"Admins\",\n                        \"policy\": {\n                          \"type\": 3,\n                          \"value\": {\n                            \"rule\": \"ANY\",\n                            \"sub_policy\": \"Writers\"\n                          }\n                        },\n                        \"version\": \"0\"\n                      }\n                    },\n                    \"values\": {\n                      \"BatchSize\": {\n                        \"mod_policy\": \"Admins\",\n                        \"value\": {\n                          \"absolute_max_bytes\": 10485760,\n                          \"max_message_count\": 10,\n                          \"preferred_max_bytes\": 524288\n                        },\n                        \"version\": \"0\"\n                      },\n                      \"BatchTimeout\": {\n                        \"mod_policy\": \"Admins\",\n                        \"value\": {\n                          \"timeout\": \"2s\"\n                        },\n                        \"version\": \"0\"\n                      },\n                      \"ChannelRestrictions\": {\n                        \"mod_policy\": \"Admins\",\n                        \"version\": \"0\"\n                      },\n                      \"ConsensusType\": {\n                        \"mod_policy\": \"Admins\",\n                        \"value\": {\n                          \"type\": \"solo\"\n                        },\n                        \"version\": \"0\"\n                      }\n                    },\n                    \"version\": \"0\"\n                  }\n                },\n                \"mod_policy\": \"Admins\",\n                \"policies\": {\n                  \"Admins\": {\n                    \"mod_policy\": \"Admins\",\n                    \"policy\": {\n                      \"type\": 3,\n                      \"value\": {\n                        \"rule\": \"MAJORITY\",\n                        \"sub_policy\": \"Admins\"\n                      }\n                    },\n                    \"version\": \"0\"\n                  },\n                  \"Readers\": {\n                    \"mod_policy\": \"Admins\",\n                    \"policy\": {\n                      \"type\": 3,\n                      \"value\": {\n                        \"rule\": \"ANY\",\n                        \"sub_policy\": \"Readers\"\n                      }\n                    },\n                    \"version\": \"0\"\n                  },\n                  \"Writers\": {\n                    \"mod_policy\": \"Admins\",\n                    \"policy\": {\n                      \"type\": 3,\n                      \"value\": {\n                        \"rule\": \"ANY\",\n                        \"sub_policy\": \"Writers\"\n                      }\n                    },\n                    \"version\": \"0\"\n                  }\n                },\n                \"values\": {\n                  \"BlockDataHashingStructure\": {\n                    \"mod_policy\": \"Admins\",\n                    \"value\": {\n                      \"width\": 4294967295\n                    },\n                    \"version\": \"0\"\n                  },\n                  \"HashingAlgorithm\": {\n                    \"mod_policy\": \"Admins\",\n                    \"value\": {\n                      \"name\": \"SHA256\"\n                    },\n                    \"version\": \"0\"\n                  },\n                  \"OrdererAddresses\": {\n                    \"mod_policy\": \"/Channel/Orderer/Admins\",\n                    \"value\": {\n                      \"addresses\": [\n                        \"127.0.0.1:7050\"\n                      ]\n                    },\n                    \"version\": \"0\"\n                  }\n                },\n                \"version\": \"0\"\n              },\n              \"sequence\": \"0\",\n              \"type\": 0\n            }\n          },\n          \"header\": {\n            \"channel_header\": {\n              \"channel_id\": \"foo\",\n              \"epoch\": \"0\",\n              \"timestamp\": \"2017-11-02T21:56:04.000Z\",\n              \"tx_id\": \"6acfe1257c23a4f844cc299cbf53acc7bf8fa8bcf8aae8d049193098fe982eab\",\n              \"type\": 1,\n              \"version\": 1\n            },\n            \"signature_header\": {\n              \"nonce\": \"eZOKru6jmeiWykBtSDwnkGjyQt69GwuS\"\n            }\n          }\n        }\n      }\n    ]\n  },\n  \"header\": {\n    \"data_hash\": \"/86I/7NScbH/bHcDcYG0/9qTmVPWVoVVfSN8NKMARKI=\",\n    \"number\": \"0\"\n  },\n  \"metadata\": {\n    \"metadata\": [\n      \"\",\n      \"\",\n      \"\",\n      \"\"\n    ]\n  }\n}", 
            "title": "Reviewing a configuration"
        }, 
        {
            "location": "/configtxlator/", 
            "text": "Reconfiguring with configtxlator\n\n\nOverview\n\n\nThe \nconfigtxlator\n tool was created to support reconfiguration\nindependent of SDKs. Channel configuration is stored as a transaction in\nconfiguration blocks of a channel and may be manipulated directly, such\nas in the bdd behave tests. However, at the time of this writing, no SDK\nnatively supports manipulating the configuration directly, so the\n\nconfigtxlator\n tool is designed to provide an API which consumers of\nany SDK may interact with to assist with configuration updates.\n\n\nThe tool name is a portmanteau of \nconfigtx\n and \ntranslator\n and is\nintended to convey that the tool simply converts between different\nequivalent data representations. It does not generate configuration. It\ndoes not submit or retrieve configuration. It does not modify\nconfiguration itself, it simply provides some bijective operations\nbetween different views of the configtx format.\n\n\nThe standard usage is expected to be:\n\n\n\n\n\n\nSDK retrieves latest config\n\n\nconfigtxlator\n produces human readable version of config\n\n\nUser or application edits the config\n\n\nconfigtxlator\n is used to compute config update representation of\n    changes to the config\n\n\nSDK submits signs and submits config\n\n\n\n\n\n\nThe \nconfigtxlator\n tool exposes a truly stateless REST API for\ninteracting with configuration elements. These REST components support\nconverting the native configuration format to/from a human readable JSON\nrepresentation, as well as computing configuration updates based on the\ndifference between two configurations.\n\n\nBecause the \nconfigtxlator\n service deliberately does not contain any\ncrypto material, or otherwise secret information, it does not include\nany authorization or access control. The anticipated typical deployment\nwould be to operate as a sandboxed container, locally with the\napplication, so that there is a dedicated \nconfigtxlator\n process for\neach consumer of it.\n\n\nRunning the configtxlator\n\n\nThe \nconfigtxlator\n tool can be downloaded with the other Hyperledger\nFabric platform-specific binaries. Please see\n[download-platform-specific-binaries]{role=\"ref\"} for details.\n\n\nThe tool may be configured to listen on a different port and you may\nalso specify the hostname using the \n--port\n and \n--hostname\n flags. To\nexplore the complete set of commands and flags, run\n\nconfigtxlator --help\n.\n\n\nThe binary will start an http server listening on the designated port\nand is now ready to process request.\n\n\nTo start the \nconfigtxlator\n server:\n\n\n``` {.sourceCode .bash}\nconfigtxlator start\n2017-06-21 18:16:58.248 HKT [configtxlator] startServer -\n INFO 001 Serving HTTP requests on 0.0.0.0:7059\n\n\n\nProto translation\n-----------------\n\nFor extensibility, and because certain fields must be signed over, many\nproto fields are stored as bytes. This makes the natural proto to JSON\ntranslation using the `jsonpb` package ineffective for producing a human\nreadable version of the protobufs. Instead, the `configtxlator` exposes\na REST component to do a more sophisticated translation.\n\nTo convert a proto to its human readable JSON equivalent, simply post\nthe binary proto to the rest target\n`http://$SERVER:$PORT/protolator/decode/\nmessage.Name\n`, where\n`\nmessage.Name\n` is the fully qualified proto name of the message.\n\nFor instance, to decode a configuration block saved as\n`configuration_block.pb`, run the command:\n\n``` {.sourceCode .bash}\ncurl -X POST --data-binary @configuration_block.pb http://127.0.0.1:7059/protolator/decode/common.Block\n\n\n\n\nTo convert the human readable JSON version of the proto message, simply\npost the JSON version to\n\nhttp://$SERVER:$PORT/protolator/encode/\nmessage.Name\n, where\n\nmessage.Name\n is again the fully qualified proto name of the message.\n\n\nFor instance, to re-encode the block saved as\n\nconfiguration_block.json\n, run the command:\n\n\n``` {.sourceCode .bash}\ncurl -X POST --data-binary @configuration_block.json http://127.0.0.1:7059/protolator/encode/common.Block\n\n\n\nAny of the configuration related protos, including `common.Block`,\n`common.Envelope`, `common.ConfigEnvelope`,\n`common.ConfigUpdateEnvelope`, `common.Config`, and\n`common.ConfigUpdate` are valid targets for these URLs. In the future,\nother proto decoding types may be added, such as for endorser\ntransactions.\n\nConfig update computation\n-------------------------\n\nGiven two different configurations, it is possible to compute the config\nupdate which transitions between them. Simply POST the two\n`common.Config` proto encoded configurations as `multipart/formdata`,\nwith the original as field `original` and the updated as field\n`updated`, to\n`http://$SERVER:$PORT/configtxlator/compute/update-from-configs`.\n\nFor example, given the original config as the file `original_config.pb`\nand the updated config as the file `updated_config.pb` for the channel\n`desiredchannel`:\n\n``` {.sourceCode .bash}\ncurl -X POST -F channel=desiredchannel -F original=@original_config.pb -F updated=@updated_config.pb http://127.0.0.1:7059/configtxlator/compute/update-from-configs\n\n\n\n\nBootstraping example\n\n\nFirst start the \nconfigtxlator\n:\n\n\n``` {.sourceCode .bash}\n$ configtxlator start\n2017-05-31 12:57:22.499 EDT [configtxlator] main -\n INFO 001 Serving HTTP requests on port: 7059\n\n\n\nFirst, produce a genesis block for the ordering system channel:\n\n``` {.sourceCode .bash}\n$ configtxgen -outputBlock genesis_block.pb\n2017-05-31 14:15:16.634 EDT [common/configtx/tool] main -\n INFO 001 Loading configuration\n2017-05-31 14:15:16.646 EDT [common/configtx/tool] doOutputBlock -\n INFO 002 Generating genesis block\n2017-05-31 14:15:16.646 EDT [common/configtx/tool] doOutputBlock -\n INFO 003 Writing genesis block\n\n\n\n\nDecode the genesis block into a human editable form:\n\n\n``` {.sourceCode .bash}\ncurl -X POST --data-binary @genesis_block.pb http://127.0.0.1:7059/protolator/decode/common.Block \n genesis_block.json\n\n\n\nEdit the `genesis_block.json` file in your favorite JSON editor, or\nmanipulate it programatically. Here we use the JSON CLI tool `jq`. For\nsimplicity, we are editing the batch size for the channel, because it is\na single numeric field. However, any edits, including policy and MSP\nedits may be made here.\n\nFirst, let\\'s establish an environment variable to hold the string that\ndefines the path to a property in the json:\n\n``` {.sourceCode .bash}\nexport MAXBATCHSIZEPATH=\n.data.data[0].payload.data.config.channel_group.groups.Orderer.values.BatchSize.value.max_message_count\n\n\n\n\n\nNext, let\\'s display the value of that property:\n\n\n``` {.sourceCode .bash}\njq \"$MAXBATCHSIZEPATH\" genesis_block.json\n10\n\n\n\nNow, let\\'s set the new batch size, and display the new value:\n\n\n jq \\\n\\$MAXBATCHSIZEPATH = 20\\\n genesis\\_block.json \\\n\n\n updated\\_genesis\\_block.json jq \\\n\\$MAXBATCHSIZEPATH\\\n\n\n updated\\_genesis\\_block.json 20\n\nThe genesis block is now ready to be re-encoded into the native proto\nform to be used for bootstrapping:\n\n``` {.sourceCode .bash}\ncurl -X POST --data-binary @updated_genesis_block.json http://127.0.0.1:7059/protolator/encode/common.Block \n updated_genesis_block.pb\n\n\n\n\nThe \nupdated_genesis_block.pb\n file may now be used as the genesis block\nfor bootstrapping an ordering system channel.\n\n\nReconfiguration example\n\n\nIn another terminal window, start the orderer using the default options,\nincluding the provisional bootstrapper which will create a \ntestchainid\n\nordering system channel.\n\n\n``` {.sourceCode .bash}\nORDERER_GENERAL_LOGLEVEL=debug orderer\n\n\n\nReconfiguring a channel can be performed in a very similar way to\nmodifying a genesis config.\n\nFirst, fetch the config\\_block proto:\n\n``` {.sourceCode .bash}\n$ peer channel fetch config config_block.pb -o 127.0.0.1:7050 -c testchainid\n2017-05-31 15:11:37.617 EDT [msp] getMspConfig -\n INFO 001 intermediate certs folder not found at [/home/yellickj/go/src/github.com/hyperledger/fabric/sampleconfig/msp/intermediatecerts]. Skipping.: [stat /home/yellickj/go/src/github.com/hyperledger/fabric/sampleconfig/msp/intermediatecerts: no such file or directory]\n2017-05-31 15:11:37.617 EDT [msp] getMspConfig -\n INFO 002 crls folder not found at [/home/yellickj/go/src/github.com/hyperledger/fabric/sampleconfig/msp/intermediatecerts]. Skipping.: [stat /home/yellickj/go/src/github.com/hyperledger/fabric/sampleconfig/msp/crls: no such file or directory]\nReceived block:  1\nReceived block:  1\n2017-05-31 15:11:37.635 EDT [main] main -\n INFO 003 Exiting.....\n\n\n\n\nNext, send the config block to the \nconfigtxlator\n service for decoding:\n\n\n``` {.sourceCode .bash}\ncurl -X POST --data-binary @config_block.pb http://127.0.0.1:7059/protolator/decode/common.Block \n config_block.json\n\n\n\nExtract the config section from the block:\n\n``` {.sourceCode .bash}\njq .data.data[0].payload.data.config config_block.json \n config.json\n\n\n\n\nEdit the config, saving it as a new \nupdated_config.json\n. Here, we set\nthe batch size to 30.\n\n\n``` {.sourceCode .bash}\njq \".channel_group.groups.Orderer.values.BatchSize.value.max_message_count = 30\" config.json  \n updated_config.json\n\n\n\nRe-encode both the original config, and the updated config into proto:\n\n``` {.sourceCode .bash}\ncurl -X POST --data-binary @config.json http://127.0.0.1:7059/protolator/encode/common.Config \n config.pb\n\n\n\n\n``` {.sourceCode .bash}\ncurl -X POST --data-binary @updated_config.json http://127.0.0.1:7059/protolator/encode/common.Config \n updated_config.pb\n\n\n\nNow, with both configs properly encoded, send them to the configtxlator\nservice to compute the config update which transitions between the two.\n\n``` {.sourceCode .bash}\ncurl -X POST -F original=@config.pb -F updated=@updated_config.pb http://127.0.0.1:7059/configtxlator/compute/update-from-configs -F channel=testchainid \n config_update.pb\n\n\n\n\nAt this point, the computed config update is now prepared.\nTraditionally, an SDK would be used to sign and wrap this message.\nHowever, in the interest of using only the peer cli, the configtxlator\ncan also be used for this task.\n\n\nFirst, we decode the ConfigUpdate so that we may work with it as text:\n\n\n``` {.sourceCode .bash}\n$ curl -X POST --data-binary @config_update.pb http://127.0.0.1:7059/protolator/decode/common.ConfigUpdate \n config_update.json\n\n\n\nThen, we wrap it in an envelope message:\n\n``` {.sourceCode .bash}\necho '{\npayload\n:{\nheader\n:{\nchannel_header\n:{\nchannel_id\n:\ntestchainid\n, \ntype\n:2}},\ndata\n:{\nconfig_update\n:'$(cat config_update.json)'}}}' \n config_update_as_envelope.json\n\n\n\n\nNext, convert it back into the proto form of a full fledged config\ntransaction:\n\n\n``` {.sourceCode .bash}\ncurl -X POST --data-binary @config_update_as_envelope.json http://127.0.0.1:7059/protolator/encode/common.Envelope \n config_update_as_envelope.pb\n\n\n\nFinally, submit the config update transaction to ordering to perform a\nconfig update.\n\n``` {.sourceCode .bash}\npeer channel update -f config_update_as_envelope.pb -c testchainid -o 127.0.0.1:7050\n\n\n\n\nAdding an organization\n\n\nFirst start the \nconfigtxlator\n:\n\n\n``` {.sourceCode .bash}\n$ configtxlator start\n2017-05-31 12:57:22.499 EDT [configtxlator] main -\n INFO 001 Serving HTTP requests on port: 7059\n\n\n\nStart the orderer using the `SampleDevModeSolo` profile option.\n\n``` {.sourceCode .bash}\nORDERER_GENERAL_LOGLEVEL=debug ORDERER_GENERAL_GENESISPROFILE=SampleDevModeSolo orderer\n\n\n\n\nThe process to add an organization then follows exactly like the batch\nsize example. However, instead of setting the batch size, a new org is\ndefined at the application level. Adding an organization is slightly\nmore involved because we must first create a channel, then modify its\nmembership set.", 
            "title": "Channel Reconfiguration"
        }, 
        {
            "location": "/configtxlator/#reconfiguring-with-configtxlator", 
            "text": "", 
            "title": "Reconfiguring with configtxlator"
        }, 
        {
            "location": "/configtxlator/#overview", 
            "text": "The  configtxlator  tool was created to support reconfiguration\nindependent of SDKs. Channel configuration is stored as a transaction in\nconfiguration blocks of a channel and may be manipulated directly, such\nas in the bdd behave tests. However, at the time of this writing, no SDK\nnatively supports manipulating the configuration directly, so the configtxlator  tool is designed to provide an API which consumers of\nany SDK may interact with to assist with configuration updates.  The tool name is a portmanteau of  configtx  and  translator  and is\nintended to convey that the tool simply converts between different\nequivalent data representations. It does not generate configuration. It\ndoes not submit or retrieve configuration. It does not modify\nconfiguration itself, it simply provides some bijective operations\nbetween different views of the configtx format.  The standard usage is expected to be:    SDK retrieves latest config  configtxlator  produces human readable version of config  User or application edits the config  configtxlator  is used to compute config update representation of\n    changes to the config  SDK submits signs and submits config    The  configtxlator  tool exposes a truly stateless REST API for\ninteracting with configuration elements. These REST components support\nconverting the native configuration format to/from a human readable JSON\nrepresentation, as well as computing configuration updates based on the\ndifference between two configurations.  Because the  configtxlator  service deliberately does not contain any\ncrypto material, or otherwise secret information, it does not include\nany authorization or access control. The anticipated typical deployment\nwould be to operate as a sandboxed container, locally with the\napplication, so that there is a dedicated  configtxlator  process for\neach consumer of it.", 
            "title": "Overview"
        }, 
        {
            "location": "/configtxlator/#running-the-configtxlator", 
            "text": "The  configtxlator  tool can be downloaded with the other Hyperledger\nFabric platform-specific binaries. Please see\n[download-platform-specific-binaries]{role=\"ref\"} for details.  The tool may be configured to listen on a different port and you may\nalso specify the hostname using the  --port  and  --hostname  flags. To\nexplore the complete set of commands and flags, run configtxlator --help .  The binary will start an http server listening on the designated port\nand is now ready to process request.  To start the  configtxlator  server:  ``` {.sourceCode .bash}\nconfigtxlator start\n2017-06-21 18:16:58.248 HKT [configtxlator] startServer -  INFO 001 Serving HTTP requests on 0.0.0.0:7059  \nProto translation\n-----------------\n\nFor extensibility, and because certain fields must be signed over, many\nproto fields are stored as bytes. This makes the natural proto to JSON\ntranslation using the `jsonpb` package ineffective for producing a human\nreadable version of the protobufs. Instead, the `configtxlator` exposes\na REST component to do a more sophisticated translation.\n\nTo convert a proto to its human readable JSON equivalent, simply post\nthe binary proto to the rest target\n`http://$SERVER:$PORT/protolator/decode/ message.Name `, where\n` message.Name ` is the fully qualified proto name of the message.\n\nFor instance, to decode a configuration block saved as\n`configuration_block.pb`, run the command:\n\n``` {.sourceCode .bash}\ncurl -X POST --data-binary @configuration_block.pb http://127.0.0.1:7059/protolator/decode/common.Block  To convert the human readable JSON version of the proto message, simply\npost the JSON version to http://$SERVER:$PORT/protolator/encode/ message.Name , where message.Name  is again the fully qualified proto name of the message.  For instance, to re-encode the block saved as configuration_block.json , run the command:  ``` {.sourceCode .bash}\ncurl -X POST --data-binary @configuration_block.json http://127.0.0.1:7059/protolator/encode/common.Block  \nAny of the configuration related protos, including `common.Block`,\n`common.Envelope`, `common.ConfigEnvelope`,\n`common.ConfigUpdateEnvelope`, `common.Config`, and\n`common.ConfigUpdate` are valid targets for these URLs. In the future,\nother proto decoding types may be added, such as for endorser\ntransactions.\n\nConfig update computation\n-------------------------\n\nGiven two different configurations, it is possible to compute the config\nupdate which transitions between them. Simply POST the two\n`common.Config` proto encoded configurations as `multipart/formdata`,\nwith the original as field `original` and the updated as field\n`updated`, to\n`http://$SERVER:$PORT/configtxlator/compute/update-from-configs`.\n\nFor example, given the original config as the file `original_config.pb`\nand the updated config as the file `updated_config.pb` for the channel\n`desiredchannel`:\n\n``` {.sourceCode .bash}\ncurl -X POST -F channel=desiredchannel -F original=@original_config.pb -F updated=@updated_config.pb http://127.0.0.1:7059/configtxlator/compute/update-from-configs", 
            "title": "Running the configtxlator"
        }, 
        {
            "location": "/configtxlator/#bootstraping-example", 
            "text": "First start the  configtxlator :  ``` {.sourceCode .bash}\n$ configtxlator start\n2017-05-31 12:57:22.499 EDT [configtxlator] main -  INFO 001 Serving HTTP requests on port: 7059  \nFirst, produce a genesis block for the ordering system channel:\n\n``` {.sourceCode .bash}\n$ configtxgen -outputBlock genesis_block.pb\n2017-05-31 14:15:16.634 EDT [common/configtx/tool] main -  INFO 001 Loading configuration\n2017-05-31 14:15:16.646 EDT [common/configtx/tool] doOutputBlock -  INFO 002 Generating genesis block\n2017-05-31 14:15:16.646 EDT [common/configtx/tool] doOutputBlock -  INFO 003 Writing genesis block  Decode the genesis block into a human editable form:  ``` {.sourceCode .bash}\ncurl -X POST --data-binary @genesis_block.pb http://127.0.0.1:7059/protolator/decode/common.Block   genesis_block.json  \nEdit the `genesis_block.json` file in your favorite JSON editor, or\nmanipulate it programatically. Here we use the JSON CLI tool `jq`. For\nsimplicity, we are editing the batch size for the channel, because it is\na single numeric field. However, any edits, including policy and MSP\nedits may be made here.\n\nFirst, let\\'s establish an environment variable to hold the string that\ndefines the path to a property in the json:\n\n``` {.sourceCode .bash}\nexport MAXBATCHSIZEPATH= .data.data[0].payload.data.config.channel_group.groups.Orderer.values.BatchSize.value.max_message_count   Next, let\\'s display the value of that property:  ``` {.sourceCode .bash}\njq \"$MAXBATCHSIZEPATH\" genesis_block.json\n10  \nNow, let\\'s set the new batch size, and display the new value:  jq \\ \\$MAXBATCHSIZEPATH = 20\\  genesis\\_block.json \\   updated\\_genesis\\_block.json jq \\ \\$MAXBATCHSIZEPATH\\   updated\\_genesis\\_block.json 20\n\nThe genesis block is now ready to be re-encoded into the native proto\nform to be used for bootstrapping:\n\n``` {.sourceCode .bash}\ncurl -X POST --data-binary @updated_genesis_block.json http://127.0.0.1:7059/protolator/encode/common.Block   updated_genesis_block.pb  The  updated_genesis_block.pb  file may now be used as the genesis block\nfor bootstrapping an ordering system channel.", 
            "title": "Bootstraping example"
        }, 
        {
            "location": "/configtxlator/#reconfiguration-example", 
            "text": "In another terminal window, start the orderer using the default options,\nincluding the provisional bootstrapper which will create a  testchainid \nordering system channel.  ``` {.sourceCode .bash}\nORDERER_GENERAL_LOGLEVEL=debug orderer  \nReconfiguring a channel can be performed in a very similar way to\nmodifying a genesis config.\n\nFirst, fetch the config\\_block proto:\n\n``` {.sourceCode .bash}\n$ peer channel fetch config config_block.pb -o 127.0.0.1:7050 -c testchainid\n2017-05-31 15:11:37.617 EDT [msp] getMspConfig -  INFO 001 intermediate certs folder not found at [/home/yellickj/go/src/github.com/hyperledger/fabric/sampleconfig/msp/intermediatecerts]. Skipping.: [stat /home/yellickj/go/src/github.com/hyperledger/fabric/sampleconfig/msp/intermediatecerts: no such file or directory]\n2017-05-31 15:11:37.617 EDT [msp] getMspConfig -  INFO 002 crls folder not found at [/home/yellickj/go/src/github.com/hyperledger/fabric/sampleconfig/msp/intermediatecerts]. Skipping.: [stat /home/yellickj/go/src/github.com/hyperledger/fabric/sampleconfig/msp/crls: no such file or directory]\nReceived block:  1\nReceived block:  1\n2017-05-31 15:11:37.635 EDT [main] main -  INFO 003 Exiting.....  Next, send the config block to the  configtxlator  service for decoding:  ``` {.sourceCode .bash}\ncurl -X POST --data-binary @config_block.pb http://127.0.0.1:7059/protolator/decode/common.Block   config_block.json  \nExtract the config section from the block:\n\n``` {.sourceCode .bash}\njq .data.data[0].payload.data.config config_block.json   config.json  Edit the config, saving it as a new  updated_config.json . Here, we set\nthe batch size to 30.  ``` {.sourceCode .bash}\njq \".channel_group.groups.Orderer.values.BatchSize.value.max_message_count = 30\" config.json    updated_config.json  \nRe-encode both the original config, and the updated config into proto:\n\n``` {.sourceCode .bash}\ncurl -X POST --data-binary @config.json http://127.0.0.1:7059/protolator/encode/common.Config   config.pb  ``` {.sourceCode .bash}\ncurl -X POST --data-binary @updated_config.json http://127.0.0.1:7059/protolator/encode/common.Config   updated_config.pb  \nNow, with both configs properly encoded, send them to the configtxlator\nservice to compute the config update which transitions between the two.\n\n``` {.sourceCode .bash}\ncurl -X POST -F original=@config.pb -F updated=@updated_config.pb http://127.0.0.1:7059/configtxlator/compute/update-from-configs -F channel=testchainid   config_update.pb  At this point, the computed config update is now prepared.\nTraditionally, an SDK would be used to sign and wrap this message.\nHowever, in the interest of using only the peer cli, the configtxlator\ncan also be used for this task.  First, we decode the ConfigUpdate so that we may work with it as text:  ``` {.sourceCode .bash}\n$ curl -X POST --data-binary @config_update.pb http://127.0.0.1:7059/protolator/decode/common.ConfigUpdate   config_update.json  \nThen, we wrap it in an envelope message:\n\n``` {.sourceCode .bash}\necho '{ payload :{ header :{ channel_header :{ channel_id : testchainid ,  type :2}}, data :{ config_update :'$(cat config_update.json)'}}}'   config_update_as_envelope.json  Next, convert it back into the proto form of a full fledged config\ntransaction:  ``` {.sourceCode .bash}\ncurl -X POST --data-binary @config_update_as_envelope.json http://127.0.0.1:7059/protolator/encode/common.Envelope   config_update_as_envelope.pb  \nFinally, submit the config update transaction to ordering to perform a\nconfig update.\n\n``` {.sourceCode .bash}\npeer channel update -f config_update_as_envelope.pb -c testchainid -o 127.0.0.1:7050", 
            "title": "Reconfiguration example"
        }, 
        {
            "location": "/configtxlator/#adding-an-organization", 
            "text": "First start the  configtxlator :  ``` {.sourceCode .bash}\n$ configtxlator start\n2017-05-31 12:57:22.499 EDT [configtxlator] main -  INFO 001 Serving HTTP requests on port: 7059  \nStart the orderer using the `SampleDevModeSolo` profile option.\n\n``` {.sourceCode .bash}\nORDERER_GENERAL_LOGLEVEL=debug ORDERER_GENERAL_GENESISPROFILE=SampleDevModeSolo orderer  The process to add an organization then follows exactly like the batch\nsize example. However, instead of setting the batch size, a new org is\ndefined at the application level. Adding an organization is slightly\nmore involved because we must first create a channel, then modify its\nmembership set.", 
            "title": "Adding an organization"
        }, 
        {
            "location": "/tbd/", 
            "text": "PLACEHOLDER", 
            "title": "Certificate Authority Tasks"
        }, 
        {
            "location": "/tbd/#placeholder", 
            "text": "", 
            "title": "PLACEHOLDER"
        }, 
        {
            "location": "/getting_started/", 
            "text": "Getting Started\n\n\nInstall Prerequisites\n\n\nBefore we begin, if you haven\\'t already done so, you may wish to check\nthat you have all the [prereqs]{role=\"doc\"} installed on the platform(s)\non which you\\'ll be developing blockchain applications and/or operating\nHyperledger Fabric.\n\n\nInstall Binaries and Docker Images\n\n\nWhile we work on developing real installers for the Hyperledger Fabric\nbinaries, we provide a script that will [binaries]{role=\"ref\"} to your\nsystem. The script also will download the Docker images to your local\nregistry.\n\n\nHyperledger Fabric Samples\n\n\nWe offer a set of sample applications that you may wish to install these\n[samples]{role=\"doc\"} before starting with the tutorials as the\ntutorials leverage the sample code.\n\n\nAPI Documentation\n\n\nThe API documentation for Hyperledger Fabric\\'s Golang APIs can be found\non the godoc site for\n\nFabric\n. If you plan on\ndoing any development using these APIs, you may want to bookmark those\nlinks now.\n\n\nHyperledger Fabric SDKs\n\n\nHyperledger Fabric intends to offer a number of SDKs for a wide variety\nof programming languages. The first two delivered SDKs are the Node.js\nand Java SDKs. We hope to provide Python and Go SDKs soon after the\n1.0.0 release.\n\n\n\n\n\n\nHyperledger Fabric Node SDK\n    documentation\n.\n\n\nHyperledger Fabric Java SDK\n    documentation\n.\n\n\n\n\n\n\nHyperledger Fabric CA\n\n\nHyperledger Fabric provides an optional \ncertificate authority\nservice\n that you\nmay choose to use to generate the certificates and key material to\nconfigure and manage identity in your blockchain network. However, any\nCA that can generate ECDSA certificates may be used.\n\n\nTutorials\n\n\nWe offer four initial tutorials to get you started with Hyperledger\nFabric. The first is oriented to the Hyperledger Fabric \napplication\ndeveloper\n, [write_first_app]{role=\"doc\"}. It takes you through the\nprocess of writing your first blockchain application for Hyperledger\nFabric using the Hyperledger Fabric \nNode\nSDK\n.\n\n\nThe second tutorial is oriented towards the Hyperledger Fabric network\noperators, [build_network]{role=\"doc\"}. This one walks you through the\nprocess of establishing a blockchain network using Hyperledger Fabric\nand provides a basic sample application to test it out.\n\n\nFinally, we offer two chaincode tutorials. One oriented to developers,\n[chaincode4ade]{role=\"doc\"}, and the other oriented to operators,\n[chaincode4noah]{role=\"doc\"}.\n\n\nNote: If you have questions not addressed by this documentation, or run into\nissues with any of the tutorials, please visit the [questions]{role=\"doc\"}\npage for some tips on where to find additional help.\n\n\nThis work is licensed under a \nCreative Commons Attribution 4.0 International License", 
            "title": "Getting Started"
        }, 
        {
            "location": "/getting_started/#getting-started", 
            "text": "", 
            "title": "Getting Started"
        }, 
        {
            "location": "/getting_started/#install-prerequisites", 
            "text": "Before we begin, if you haven\\'t already done so, you may wish to check\nthat you have all the [prereqs]{role=\"doc\"} installed on the platform(s)\non which you\\'ll be developing blockchain applications and/or operating\nHyperledger Fabric.", 
            "title": "Install Prerequisites"
        }, 
        {
            "location": "/getting_started/#install-binaries-and-docker-images", 
            "text": "While we work on developing real installers for the Hyperledger Fabric\nbinaries, we provide a script that will [binaries]{role=\"ref\"} to your\nsystem. The script also will download the Docker images to your local\nregistry.", 
            "title": "Install Binaries and Docker Images"
        }, 
        {
            "location": "/getting_started/#hyperledger-fabric-samples", 
            "text": "We offer a set of sample applications that you may wish to install these\n[samples]{role=\"doc\"} before starting with the tutorials as the\ntutorials leverage the sample code.", 
            "title": "Hyperledger Fabric Samples"
        }, 
        {
            "location": "/getting_started/#api-documentation", 
            "text": "The API documentation for Hyperledger Fabric\\'s Golang APIs can be found\non the godoc site for Fabric . If you plan on\ndoing any development using these APIs, you may want to bookmark those\nlinks now.", 
            "title": "API Documentation"
        }, 
        {
            "location": "/getting_started/#hyperledger-fabric-sdks", 
            "text": "Hyperledger Fabric intends to offer a number of SDKs for a wide variety\nof programming languages. The first two delivered SDKs are the Node.js\nand Java SDKs. We hope to provide Python and Go SDKs soon after the\n1.0.0 release.    Hyperledger Fabric Node SDK\n    documentation .  Hyperledger Fabric Java SDK\n    documentation .", 
            "title": "Hyperledger Fabric SDKs"
        }, 
        {
            "location": "/getting_started/#hyperledger-fabric-ca", 
            "text": "Hyperledger Fabric provides an optional  certificate authority\nservice  that you\nmay choose to use to generate the certificates and key material to\nconfigure and manage identity in your blockchain network. However, any\nCA that can generate ECDSA certificates may be used.", 
            "title": "Hyperledger Fabric CA"
        }, 
        {
            "location": "/getting_started/#tutorials", 
            "text": "We offer four initial tutorials to get you started with Hyperledger\nFabric. The first is oriented to the Hyperledger Fabric  application\ndeveloper , [write_first_app]{role=\"doc\"}. It takes you through the\nprocess of writing your first blockchain application for Hyperledger\nFabric using the Hyperledger Fabric  Node\nSDK .  The second tutorial is oriented towards the Hyperledger Fabric network\noperators, [build_network]{role=\"doc\"}. This one walks you through the\nprocess of establishing a blockchain network using Hyperledger Fabric\nand provides a basic sample application to test it out.  Finally, we offer two chaincode tutorials. One oriented to developers,\n[chaincode4ade]{role=\"doc\"}, and the other oriented to operators,\n[chaincode4noah]{role=\"doc\"}.  Note: If you have questions not addressed by this documentation, or run into\nissues with any of the tutorials, please visit the [questions]{role=\"doc\"}\npage for some tips on where to find additional help.  This work is licensed under a  Creative Commons Attribution 4.0 International License", 
            "title": "Tutorials"
        }, 
        {
            "location": "/build_network/", 
            "text": "Building Your First Network\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nThese instructions have been verified to work against the\n\n\n:   latest stable Docker images and the pre-compiled setup utilities\n    within the supplied tar file. If you run these commands with images\n    or tools from the current master branch, it is possible that you\n    will see configuration and panic errors.\n:::\n\n\nThe build your first network (BYFN) scenario provisions a sample\nHyperledger Fabric network consisting of two organizations, each\nmaintaining two peer nodes, and a \\\"solo\\\" ordering service.\n\n\nInstall prerequisites\n\n\nBefore we begin, if you haven\\'t already done so, you may wish to check\nthat you have all the [prereqs]{role=\"doc\"} installed on the platform(s)\non which you\\'ll be developing blockchain applications and/or operating\nHyperledger Fabric.\n\n\nYou will also need to download and install the [samples]{role=\"doc\"}.\nYou will notice that there are a number of samples included in the\n\nfabric-samples\n repository. We will be using the \nfirst-network\n\nsample. Let\\'s open that sub-directory now.\n\n\n``` {.sourceCode .bash}\ncd fabric-samples/first-network\n\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\nThe supplied commands in this documentation\n\n:   **MUST** be run from your `first-network` sub-directory of the\n    `fabric-samples` repository clone. If you elect to run the commands\n    from a different location, the various provided scripts will be\n    unable to find the binaries.\n:::\n\nWant to run it now?\n-------------------\n\nWe provide a fully annotated script - `byfn.sh` - that leverages these\nDocker images to quickly bootstrap a Hyperledger Fabric network\ncomprised of 4 peers representing two different organizations, and an\norderer node. It will also launch a container to run a scripted\nexecution that will join peers to a channel, deploy and instantiate\nchaincode and drive execution of transactions against the deployed\nchaincode.\n\nHere\\'s the help text for the `byfn.sh` script:\n\n``` {.sourceCode .bash}\n./byfn.sh --help\nUsage:\nbyfn.sh -m up|down|restart|generate [-c \nchannel name\n] [-t \ntimeout\n] [-d \ndelay\n] [-f \ndocker-compose-file\n] [-s \ndbtype\n]\nbyfn.sh -h|--help (print this message)\n  -m \nmode\n - one of 'up', 'down', 'restart' or 'generate'\n    - 'up' - bring up the network with docker-compose up\n    - 'down' - clear the network with docker-compose down\n    - 'restart' - restart the network\n    - 'generate' - generate required certificates and genesis block\n  -c \nchannel name\n - channel name to use (defaults to \nmychannel\n)\n  -t \ntimeout\n - CLI timeout duration in seconds (defaults to 10000)\n  -d \ndelay\n - delay duration in seconds (defaults to 3)\n  -f \ndocker-compose-file\n - specify which docker-compose file use (defaults to docker-compose-cli.yaml)\n  -s \ndbtype\n - the database backend to use: goleveldb (default) or couchdb\n  -l \nlanguage\n - the chaincode language: golang (default) or node\n\n  Typically, one would first generate the required certificates and\n  genesis block, then bring up the network. e.g.:\n\n  byfn.sh -m generate -c mychannel\n  byfn.sh -m up -c mychannel -s couchdb\n\n\n\n\nIf you choose not to supply a channel name, then the script will use a\ndefault name of \nmychannel\n. The CLI timeout parameter (specified with\nthe -t flag) is an optional value; if you choose not to set it, then\nyour CLI container will exit after the default setting of 10000 seconds.\n\n\nGenerate Network Artifacts\n\n\nReady to give it a go? Okay then! Execute the following command:\n\n\n``` {.sourceCode .bash}\n./byfn.sh -m generate\n\n\n\nYou will see a brief description as to what will occur, along with a\nyes/no command line prompt. Respond with a `y` to execute the described\naction.\n\n``` {.sourceCode .bash}\nGenerating certs and genesis block for with channel 'mychannel' and CLI timeout of '10000'\nContinue (y/n)?y\nproceeding ...\n/Users/xxx/dev/fabric-samples/bin/cryptogen\n\n##########################################################\n##### Generate certificates using cryptogen tool #########\n##########################################################\norg1.example.com\n2017-06-12 21:01:37.334 EDT [bccsp] GetDefault -\n WARN 001 Before using BCCSP, please call InitFactories(). Falling back to bootBCCSP.\n...\n\n/Users/xxx/dev/fabric-samples/bin/configtxgen\n##########################################################\n#########  Generating Orderer Genesis block ##############\n##########################################################\n2017-06-12 21:01:37.558 EDT [common/configtx/tool] main -\n INFO 001 Loading configuration\n2017-06-12 21:01:37.562 EDT [msp] getMspConfig -\n INFO 002 intermediate certs folder not found at [/Users/xxx/dev/byfn/crypto-config/ordererOrganizations/example.com/msp/intermediatecerts]. Skipping.: [stat /Users/xxx/dev/byfn/crypto-config/ordererOrganizations/example.com/msp/intermediatecerts: no such file or directory]\n...\n2017-06-12 21:01:37.588 EDT [common/configtx/tool] doOutputBlock -\n INFO 00b Generating genesis block\n2017-06-12 21:01:37.590 EDT [common/configtx/tool] doOutputBlock -\n INFO 00c Writing genesis block\n\n#################################################################\n### Generating channel configuration transaction 'channel.tx' ###\n#################################################################\n2017-06-12 21:01:37.634 EDT [common/configtx/tool] main -\n INFO 001 Loading configuration\n2017-06-12 21:01:37.644 EDT [common/configtx/tool] doOutputChannelCreateTx -\n INFO 002 Generating new channel configtx\n2017-06-12 21:01:37.645 EDT [common/configtx/tool] doOutputChannelCreateTx -\n INFO 003 Writing new channel tx\n\n#################################################################\n#######    Generating anchor peer update for Org1MSP   ##########\n#################################################################\n2017-06-12 21:01:37.674 EDT [common/configtx/tool] main -\n INFO 001 Loading configuration\n2017-06-12 21:01:37.678 EDT [common/configtx/tool] doOutputAnchorPeersUpdate -\n INFO 002 Generating anchor peer update\n2017-06-12 21:01:37.679 EDT [common/configtx/tool] doOutputAnchorPeersUpdate -\n INFO 003 Writing anchor peer update\n\n#################################################################\n#######    Generating anchor peer update for Org2MSP   ##########\n#################################################################\n2017-06-12 21:01:37.700 EDT [common/configtx/tool] main -\n INFO 001 Loading configuration\n2017-06-12 21:01:37.704 EDT [common/configtx/tool] doOutputAnchorPeersUpdate -\n INFO 002 Generating anchor peer update\n2017-06-12 21:01:37.704 EDT [common/configtx/tool] doOutputAnchorPeersUpdate -\n INFO 003 Writing anchor peer update\n\n\n\n\nThis first step generates all of the certificates and keys for our\nvarious network entities, the \ngenesis block\n used to bootstrap the\nordering service, and a collection of configuration transactions\nrequired to configure a [Channel]{role=\"ref\"}.\n\n\nBring Up the Network\n\n\nNext, you can bring the network up with one of the following commands:\n\n\n``` {.sourceCode .bash}\n./byfn.sh -m up\n\n\n\nThe above command will compile Golang chaincode images and spin up the\ncorresponding containers. Go is the default chaincode language, however\nthere is also support for Node.js chaincode. If you\\'d like to run\nthrough this tutorial with node chaincode, pass the following command\ninstead:\n\n``` {.sourceCode .bash}\n# we use the -l flag to specify the chaincode language\n# forgoing the -l flag will default to Golang\n\n./byfn.sh -m up -l node\n\n\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nView the \nHyperledger Fabric Shim\n\n\n:   documentation for more info on the node.js chaincode shim APIs.\n:::\n\n\nOnce again, you will be prompted as to whether you wish to continue or\nabort. Respond with a \ny\n:\n\n\n``` {.sourceCode .bash}\nStarting with channel 'mychannel' and CLI timeout of '10000'\nContinue (y/n)?y\nproceeding ...\nCreating network \"net_byfn\" with the default driver\nCreating peer0.org1.example.com\nCreating peer1.org1.example.com\nCreating peer0.org2.example.com\nCreating orderer.example.com\nCreating peer1.org2.example.com\nCreating cli\n\n\n_    \n      _      \n_    \n\n/ \n|  |\n   \n|    / \\    |  _ \\  |\n   _|\n_\n \\    | |     / _ \\   | |\n) |   | |\n \n) |   | |    / \n \\  |  _ \n    | |\n|____/    |\n|   /\n/   _\\ |\n| _\\   |_|\n\n\nChannel name : mychannel\nCreating channel...\n\n\n\nThe logs will continue from there. This will launch all of the\ncontainers, and then drive a complete end-to-end application scenario.\nUpon successful completion, it should report the following in your\nterminal window:\n\n``` {.sourceCode .bash}\n2017-05-16 17:08:01.366 UTC [msp] GetLocalMSP -\n DEBU 004 Returning existing local MSP\n2017-05-16 17:08:01.366 UTC [msp] GetDefaultSigningIdentity -\n DEBU 005 Obtaining default signing identity\n2017-05-16 17:08:01.366 UTC [msp/identity] Sign -\n DEBU 006 Sign: plaintext: 0AB1070A6708031A0C08F1E3ECC80510...6D7963631A0A0A0571756572790A0161\n2017-05-16 17:08:01.367 UTC [msp/identity] Sign -\n DEBU 007 Sign: digest: E61DB37F4E8B0D32C9FE10E3936BA9B8CD278FAA1F3320B08712164248285C54\nQuery Result: 90\n2017-05-16 17:08:15.158 UTC [main] main -\n INFO 008 Exiting.....\n===================== Query on PEER3 on channel 'mychannel' is successful =====================\n\n===================== All GOOD, BYFN execution completed =====================\n\n\n _____   _   _   ____\n| ____| | \\ | | |  _ \\\n|  _|   |  \\| | | | | |\n| |___  | |\\  | | |_| |\n|_____| |_| \\_| |____/\n\n\n\n\nYou can scroll through these logs to see the various transactions. If\nyou don\\'t get this result, then jump down to the\n[Troubleshoot]{role=\"ref\"} section and let\\'s see whether we can help\nyou discover what went wrong.\n\n\nBring Down the Network\n\n\nFinally, let\\'s bring it all down so we can explore the network setup\none step at a time. The following will kill your containers, remove the\ncrypto material and four artifacts, and delete the chaincode images from\nyour Docker Registry:\n\n\n``` {.sourceCode .bash}\n./byfn.sh -m down\n\n\n\nOnce again, you will be prompted to continue, respond with a `y`:\n\n``` {.sourceCode .bash}\nStopping with channel 'mychannel' and CLI timeout of '10000'\nContinue (y/n)?y\nproceeding ...\nWARNING: The CHANNEL_NAME variable is not set. Defaulting to a blank string.\nWARNING: The TIMEOUT variable is not set. Defaulting to a blank string.\nRemoving network net_byfn\n468aaa6201ed\n...\nUntagged: dev-peer1.org2.example.com-mycc-1.0:latest\nDeleted: sha256:ed3230614e64e1c83e510c0c282e982d2b06d148b1c498bbdcc429e2b2531e91\n...\n\n\n\n\nIf you\\'d like to learn more about the underlying tooling and bootstrap\nmechanics, continue reading. In these next sections we\\'ll walk through\nthe various steps and requirements to build a fully-functional\nHyperledger Fabric network.\n\n\nCrypto Generator\n\n\nWe will use the \ncryptogen\n tool to generate the cryptographic material\n(x509 certs and signing keys) for our various network entities. These\ncertificates are representative of identities, and they allow for\nsign/verify authentication to take place as our entities communicate and\ntransact.\n\n\nHow does it work?\n\n\nCryptogen consumes a file - \ncrypto-config.yaml\n - that contains the\nnetwork topology and allows us to generate a set of certificates and\nkeys for both the Organizations and the components that belong to those\nOrganizations. Each Organization is provisioned a unique root\ncertificate (\nca-cert\n) that binds specific components (peers and\norderers) to that Org. By assigning each Organization a unique CA\ncertificate, we are mimicking a typical network where a participating\n[Member]{role=\"ref\"} would use its own Certificate Authority.\nTransactions and communications within Hyperledger Fabric are signed by\nan entity\\'s private key (\nkeystore\n), and then verified by means of a\npublic key (\nsigncerts\n).\n\n\nYou will notice a \ncount\n variable within this file. We use this to\nspecify the number of peers per Organization; in our case there are two\npeers per Org. We won\\'t delve into the minutiae of \nx.509 certificates\nand public key\ninfrastructure\n\nright now. If you\\'re interested, you can peruse these topics on your\nown time.\n\n\nBefore running the tool, let\\'s take a quick look at a snippet from the\n\ncrypto-config.yaml\n. Pay specific attention to the \\\"Name\\\", \\\"Domain\\\"\nand \\\"Specs\\\" parameters under the \nOrdererOrgs\n header:\n\n\n``` {.sourceCode .bash}\nOrdererOrgs:\n\n\n---------------------------------------------------------\n\n\nOrderer\n\n\n--------------------------------------------------------\n\n\n\n\nName: Orderer\n  Domain: example.com\n  CA:\n      Country: US\n      Province: California\n      Locality: San Francisco\n  #   OrganizationalUnit: Hyperledger Fabric\n  #   StreetAddress: address for org # default nil\n  #   PostalCode: postalCode for org # default nil\n  # ------------------------------------------------------\n  # \"Specs\" - See PeerOrgs below for complete description\n\n\n\n\n-----------------------------------------------------\n\n\nSpecs:\n    - Hostname: orderer\n\n\n-------------------------------------------------------\n\n\n\"PeerOrgs\" - Definition of organizations managing peer nodes\n\n\n------------------------------------------------------\n\n\nPeerOrgs:\n\n\n-----------------------------------------------------\n\n\nOrg1\n\n\n----------------------------------------------------\n\n\n\n\nName: Org1\n  Domain: org1.example.com\n\n\n\n\n\nThe naming convention for a network entity is as follows\n-\\\n{{.Hostname}}.{{.Domain}}\\\n. So using our ordering node as a\nreference point, we are left with an ordering node named\n-`orderer.example.com` that is tied to an MSP ID of `Orderer`. This file\ncontains extensive documentation on the definitions and syntax. You can\nalso refer to the [msp]{role=\ndoc\n} documentation for a deeper dive on\nMSP.\n\nAfter we run the `cryptogen` tool, the generated certificates and keys\nwill be saved to a folder titled `crypto-config`.\n\nConfiguration Transaction Generator\n-----------------------------------\n\nThe `configtxgen tool` is used to create four configuration artifacts:\n\n\n -   orderer `genesis block`,\n\n -   channel `configuration transaction`,\n\n -   and two `anchor peer transactions` - one for each Peer Org.\n\nPlease see [configtxgen]{role=\ndoc\n} for a complete description of this\ntool\\'s functionality.\n\nThe orderer block is the [Genesis-Block]{role=\nref\n} for the ordering\nservice, and the channel configuration transaction file is broadcast to\nthe orderer at [Channel]{role=\nref\n} creation time. The anchor peer\ntransactions, as the name might suggest, specify each Org\\'s\n[Anchor-Peer]{role=\nref\n} on this channel.\n\n### How does it work?\n\nConfigtxgen consumes a file - `configtx.yaml` - that contains the\ndefinitions for the sample network. There are three members - one\nOrderer Org (`OrdererOrg`) and two Peer Orgs (`Org1` \n `Org2`) each\nmanaging and maintaining two peer nodes. This file also specifies a\nconsortium - `SampleConsortium` - consisting of our two Peer Orgs. Pay\nspecific attention to the \\\nProfiles\\\n section at the top of this file.\nYou will notice that we have two unique headers. One for the orderer\ngenesis block - `TwoOrgsOrdererGenesis` - and one for our channel -\n`TwoOrgsChannel`.\n\nThese headers are important, as we will pass them in as arguments when\nwe create our artifacts.\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\nNotice that our `SampleConsortium` is defined in\n\n:   the system-level profile and then referenced by our channel-level\n    profile. Channels exist within the purview of a consortium, and all\n    consortia must be defined in the scope of the network at large.\n:::\n\nThis file also contains two additional specifications that are worth\nnoting. Firstly, we specify the anchor peers for each Peer Org\n(`peer0.org1.example.com` \n `peer0.org2.example.com`). Secondly, we\npoint to the location of the MSP directory for each member, in turn\nallowing us to store the root certificates for each Org in the orderer\ngenesis block. This is a critical concept. Now any network entity\ncommunicating with the ordering service can have its digital signature\nverified.\n\nRun the tools\n-------------\n\nYou can manually generate the certificates/keys and the various\nconfiguration artifacts using the `configtxgen` and `cryptogen`\ncommands. Alternately, you could try to adapt the byfn.sh script to\naccomplish your objectives.\n\n### Manually generate the artifacts\n\nYou can refer to the `generateCerts` function in the byfn.sh script for\nthe commands necessary to generate the certificates that will be used\nfor your network configuration as defined in the `crypto-config.yaml`\nfile. However, for the sake of convenience, we will also provide a\nreference here.\n\nFirst let\\'s run the `cryptogen` tool. Our binary is in the `bin`\ndirectory, so we need to provide the relative path to where the tool\nresides.\n\n``` {.sourceCode .bash}\n../bin/cryptogen generate --config=./crypto-config.yaml\n\n\n\n\nYou should see the following in your terminal:\n\n\n``` {.sourceCode .bash}\norg1.example.com\norg2.example.com\n\n\n\nThe certs and keys (i.e. the MSP material) will be output into a\ndirectory - `crypto-config` -at the root of the `first-network`\ndirectory.\n\nNext, we need to tell the `configtxgen` tool where to look for the\n`configtx.yaml` file that it needs to ingest. We will tell it look in\nour present working directory:\n\n``` {.sourceCode .bash}\nexport FABRIC_CFG_PATH=$PWD\n\n\n\n\nThen, we\\'ll invoke the \nconfigtxgen\n tool to create the orderer genesis\nblock:\n\n\n``` {.sourceCode .bash}\n../bin/configtxgen -profile TwoOrgsOrdererGenesis -outputBlock ./channel-artifacts/genesis.block\n\n\n\nYou should see an output similar to the following in your terminal:\n\n``` {.sourceCode .bash}\n2017-10-26 19:21:56.301 EDT [common/tools/configtxgen] main -\n INFO 001 Loading configuration\n2017-10-26 19:21:56.309 EDT [common/tools/configtxgen] doOutputBlock -\n INFO 002 Generating genesis block\n2017-10-26 19:21:56.309 EDT [common/tools/configtxgen] doOutputBlock -\n INFO 003 Writing genesis block\n\n\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nThe orderer genesis block and the subsequent artifacts we are about to create\n\n\n:   will be output into the \nchannel-artifacts\n directory at the root of\n    this project.\n:::\n\n\n::: {#createchanneltx}\n\n\nCreate a Channel Configuration Transaction\n\n\n:::\n\n\nNext, we need to create the channel transaction artifact. Be sure to\nreplace \n$CHANNEL_NAME\n or set \nCHANNEL_NAME\n as an environment variable\nthat can be used throughout these instructions:\n\n\n``` {.sourceCode .bash}\n\n\nThe channel.tx artifact contains the definitions for our sample channel\n\n\nexport CHANNEL_NAME=mychannel  \n ../bin/configtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel.tx -channelID $CHANNEL_NAME\n\n\n\nYou should see an ouput similar to the following in your terminal:\n\n``` {.sourceCode .bash}\n2017-10-26 19:24:05.324 EDT [common/tools/configtxgen] main -\n INFO 001 Loading configuration\n2017-10-26 19:24:05.329 EDT [common/tools/configtxgen] doOutputChannelCreateTx -\n INFO 002 Generating new channel configtx\n2017-10-26 19:24:05.329 EDT [common/tools/configtxgen] doOutputChannelCreateTx -\n INFO 003 Writing new channel tx\n\n\n\n\nNext, we will define the anchor peer for Org1 on the channel that we are\nconstructing. Again, be sure to replace \n$CHANNEL_NAME\n or set the\nenvironment variable for the following commands. The terminal output\nwill mimic that of the channel transaction artifact:\n\n\n``` {.sourceCode .bash}\n../bin/configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors.tx -channelID $CHANNEL_NAME -asOrg Org1MSP\n\n\n\nNow, we will define the anchor peer for Org2 on the same channel:\n\n``` {.sourceCode .bash}\n../bin/configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org2MSPanchors.tx -channelID $CHANNEL_NAME -asOrg Org2MSP\n\n\n\n\nStart the network\n\n\nWe will leverage a docker-compose script to spin up our network. The\ndocker-compose file references the images that we have previously\ndownloaded, and bootstraps the orderer with our previously generated\n\ngenesis.block\n.\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nBefore launching the network, open the \ndocker-compose-cli.yaml\n file\n\n\n:   and comment out the script.sh in the CLI container. Your\n    docker-compose should be modified to look like this:\n:::\n\n\n``` {.sourceCode .bash}\nworking_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer\n\n\ncommand: /bin/bash -c './scripts/script.sh ${CHANNEL_NAME}; sleep $TIMEOUT'\n\n\nvolumes\n\n\n\nIf left uncommented, that script will exercise all of the CLI commands\nwhen the network is started, as we describe in the\n[behind-scenes]{role=\nref\n} section. However, we want to go through the\ncommands manually in order to expose the syntax and functionality of\neach call.\n\nThe CLI timeout defaults to 10000 seconds. If you need the container\navailable for longer, you can overwrite this setting by passing in a\nvalue for the `TIMEOUT` environment variable.\n\nStart your network:\n\n``` {.sourceCode .bash}\n# if you need the CLI accessible beyond 10000 seconds, pass in TIMEOUT=\nyour_desired_value\n\n# after the CHANNEL_NAME variable\n\nCHANNEL_NAME=$CHANNEL_NAME docker-compose -f docker-compose-cli.yaml up -d\n\n\n\n\nIf you want to see the realtime logs for your network, then do not\nsupply the \n-d\n flag. If you let the logs stream, then you will need to\nopen a second terminal to execute the CLI calls.\n\n\n::: {#peerenvvars}\n\n\nEnvironment variables\n\n\n:::\n\n\nFor the following CLI commands against \npeer0.org1.example.com\n to work,\nwe need to preface our commands with the four environment variables\ngiven below. These variables for \npeer0.org1.example.com\n are baked into\nthe CLI container, therefore we can operate without passing them.\n\nHOWEVER\n, if you want to send calls to other peers or the orderer,\nthen you will need to provide these values accordingly. Inspect the\n\ndocker-compose-base.yaml\n for the specific paths:\n\n\n``` {.sourceCode .bash}\n\n\nEnvironment variables for PEER0\n\n\nCORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp\nCORE_PEER_ADDRESS=peer0.org1.example.com:7051\nCORE_PEER_LOCALMSPID=\"Org1MSP\"\nCORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt\n\n\n\n::: {#createandjoin}\n### Create \n Join Channel\n:::\n\nRecall that we created the channel configuration transaction using the\n`configtxgen` tool in the [createchanneltx]{role=\nref\n} section, above.\nYou can repeat that process to create additional channel configuration\ntransactions, using the same or different profiles in the\n`configtx.yaml` that you pass to the `configtxgen` tool. Then you can\nrepeat the process defined in this section to establish those other\nchannels in your network.\n\nWe will enter the CLI container using the `docker exec` command:\n\n``` {.sourceCode .bash}\ndocker exec -it cli bash\n\n\n\n\nIf successful you should see the following:\n\n\n``` {.sourceCode .bash}\nroot@0d78bb69300d:/opt/gopath/src/github.com/hyperledger/fabric/peer#\n\n\n\nNext, we are going to pass in the generated channel configuration\ntransaction artifact that we created in the\n[createchanneltx]{role=\nref\n} section (we called it `channel.tx`) to the\norderer as part of the create channel request.\n\nWe specify our channel name with the `-c` flag and our channel\nconfiguration transaction with the `-f` flag. In this case it is\n`channel.tx`, however you can mount your own configuration transaction\nwith a different name. Once again we will set the `CHANNEL_NAME`\nenvironment variable within our CLI container so that we don\\'t have to\nexplicitly pass this argument:\n\n``` {.sourceCode .bash}\nexport CHANNEL_NAME=mychannel\n\n# the channel.tx file is mounted in the channel-artifacts directory within your CLI container\n# as a result, we pass the full path for the file\n# we also pass the path for the orderer ca-cert in order to verify the TLS handshake\n# be sure to export or replace the $CHANNEL_NAME variable appropriately\n\npeer channel create -o orderer.example.com:7050 -c $CHANNEL_NAME -f ./channel-artifacts/channel.tx --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem\n\n\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nNotice the \n-- cafile\n that we pass as part of this command. It is\n\n\n:   the local path to the orderer\\'s root cert, allowing us to verify\n    the TLS handshake.\n:::\n\n\nThis command returns a genesis block - \nchannel-ID.block\n - which we\nwill use to join the channel. It contains the configuration information\nspecified in \nchannel.tx\n If you have not made any modifications to the\ndefault channel name, then the command will return you a proto titled\n\nmychannel.block\n.\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nYou will remain in the CLI container for the remainder of\n\n\n:   these manual commands. You must also remember to preface all\n    commands with the corresponding environment variables when targeting\n    a peer other than \npeer0.org1.example.com\n.\n:::\n\n\nNow let\\'s join \npeer0.org1.example.com\n to the channel.\n\n\n``` {.sourceCode .bash}\n\n\nBy default, this joins \npeer0.org1.example.com\n only\n\n\nthe \n was returned by the previous command\n\n\nif you have not modified the channel name, you will join with mychannel.block\n\n\nif you have created a different channel name, then pass in the appropriately named block\n\n\npeer channel join -b mychannel.block\n\n\n\nYou can make other peers join the channel as necessary by making\nappropriate changes in the four environment variables we used in the\n[peerenvvars]{role=\nref\n} section, above.\n\nRather than join every peer, we will simply join\n`peer0.org2.example.com` so that we can properly update the anchor peer\ndefinitions in our channel. Since we are overriding the default\nenvironment variables baked into the CLI container, this full command\nwill be the following:\n\n``` {.sourceCode .bash}\nCORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/msp CORE_PEER_ADDRESS=peer0.org2.example.com:7051 CORE_PEER_LOCALMSPID=\nOrg2MSP\n CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt peer channel join -b mychannel.block\n\n\n\n\nAlternatively, you could choose to set these environment variables\nindividually rather than passing in the entire string. Once they\\'ve\nbeen set, you simply need to issue the \npeer channel join\n command again\nand the CLI container will act on behalf of \npeer0.org2.example.com\n.\n\n\nUpdate the anchor peers\n\n\nThe following commands are channel updates and they will propagate to\nthe definition of the channel. In essence, we adding additional\nconfiguration information on top of the channel\\'s genesis block. Note\nthat we are not modifying the genesis block, but simply adding deltas\ninto the chain that will define the anchor peers.\n\n\nUpdate the channel definition to define the anchor peer for Org1 as\n\npeer0.org1.example.com\n:\n\n\n``` {.sourceCode .bash}\npeer channel update -o orderer.example.com:7050 -c $CHANNEL_NAME -f ./channel-artifacts/Org1MSPanchors.tx --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem\n\n\n\nNow update the channel definition to define the anchor peer for Org2 as\n`peer0.org2.example.com`. Identically to the `peer channel join` command\nfor the Org2 peer, we will need to preface this call with the\nappropriate environment variables.\n\n``` {.sourceCode .bash}\nCORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/msp CORE_PEER_ADDRESS=peer0.org2.example.com:7051 CORE_PEER_LOCALMSPID=\nOrg2MSP\n CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt peer channel update -o orderer.example.com:7050 -c $CHANNEL_NAME -f ./channel-artifacts/Org2MSPanchors.tx --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem\n\n\n\n\nInstall \n Instantiate Chaincode\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nWe will utilize a simple existing chaincode. To learn how to write\n\n\n:   your own chaincode, see the [chaincode4ade]{role=\"doc\"} tutorial.\n:::\n\n\nApplications interact with the blockchain ledger through \nchaincode\n. As\nsuch we need to install the chaincode on every peer that will execute\nand endorse our transactions, and then instantiate the chaincode on the\nchannel.\n\n\nFirst, install the sample Go or Node.js chaincode onto one of the four\npeer nodes. These commands place the specified source code flavor onto\nour peer\\'s filesystem.\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nYou can only install one version of the source code per chaincode name\n\n\n:   and version. The source code exists on the peer\\'s file system in\n    the context of chaincode name and version; it is language agnostic.\n    Similarly the instantiated chaincode container will be reflective of\n    whichever language has been installed on the peer.\n:::\n\n\nGolang\n\n\n``` {.sourceCode .bash}\n\n\nthis installs the Go chaincode\n\n\npeer chaincode install -n mycc -v 1.0 -p github.com/chaincode/chaincode_example02/go/\n\n\n\n**Node.js**\n\n``` {.sourceCode .bash}\n# this installs the Node.js chaincode\n# make note of the -l flag; we use this to specify the language\npeer chaincode install -n mycc -v 1.0 -l node -p /opt/gopath/src/github.com/chaincode/chaincode_example02/node/\n\n\n\n\nNext, instantiate the chaincode on the channel. This will initialize the\nchaincode on the channel, set the endorsement policy for the chaincode,\nand launch a chaincode container for the targeted peer. Take note of the\n\n-P\n argument. This is our policy where we specify the required level of\nendorsement for a transaction against this chaincode to be validated.\n\n\nIn the command below you'll notice that we specify our policy as\n\n-P \"OR ('Org0MSP.member','Org1MSP.member')\"\n. This means that we need\n\"endorsement\" from a peer belonging to Org1 \nOR\n Org2 (i.e. only one\nendorsement). If we changed the syntax to \nAND\n then we would need two\nendorsements.\n\n\nGolang\n\n\n``` {.sourceCode .bash}\n\n\nbe sure to replace the $CHANNEL_NAME environment variable if you have not exported it\n\n\nif you did not install your chaincode with a name of mycc, then modify that argument as well\n\n\npeer chaincode instantiate -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n mycc -v 1.0 -c '{\"Args\":[\"init\",\"a\", \"100\", \"b\",\"200\"]}' -P \"OR ('Org1MSP.member','Org2MSP.member')\"\n\n\n\n**Node.js**\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\nThe instantiation of the Node.js chaincode will take roughly a minute.\n\n:   The command is not hanging; rather it is installing the fabric-shim\n    layer as the image is being compiled.\n:::\n\n``` {.sourceCode .bash}\n# be sure to replace the $CHANNEL_NAME environment variable if you have not exported it\n# if you did not install your chaincode with a name of mycc, then modify that argument as well\n# notice that we must pass the -l flag after the chaincode name to identify the language\n\npeer chaincode instantiate -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n mycc -l node -v 1.0 -c '{\nArgs\n:[\ninit\n,\na\n, \n100\n, \nb\n,\n200\n]}' -P \nOR ('Org1MSP.member','Org2MSP.member')\n\n\n\n\n\nSee the \nendorsement\npolicies\n\ndocumentation for more details on policy implementation.\n\n\nIf you want additional peers to interact with ledger, then you will need\nto join them to the channel, and install the same name, version and\nlanguage of the chaincode source onto the appropriate peer\\'s\nfilesystem. A chaincode container will be launched for each peer as soon\nas they try to interact with that specific chaincode. Again, be\ncognizant of the fact that the Node.js images will be slower to compile.\n\n\nOnce the chaincode has been instantiated on the channel, we can forgo\nthe \nl\n flag. We need only pass in the channel identifier and name of\nthe chaincode.\n\n\nQuery\n\n\nLet\\'s query for the value of \na\n to make sure the chaincode was\nproperly instantiated and the state DB was populated. The syntax for\nquery is as follows:\n\n\n``` {.sourceCode .bash}\n\n\nbe sure to set the -C and -n flags appropriately\n\n\npeer chaincode query -C $CHANNEL_NAME -n mycc -c '{\"Args\":[\"query\",\"a\"]}'\n\n\n\n### Invoke\n\nNow let\\'s move `10` from `a` to `b`. This transaction will cut a new\nblock and update the state DB. The syntax for invoke is as follows:\n\n``` {.sourceCode .bash}\n# be sure to set the -C and -n flags appropriately\n\npeer chaincode invoke -o orderer.example.com:7050  --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem  -C $CHANNEL_NAME -n mycc -c '{\nArgs\n:[\ninvoke\n,\na\n,\nb\n,\n10\n]}'\n\n\n\n\nQuery\n\n\nLet\\'s confirm that our previous invocation executed properly. We\ninitialized the key \na\n with a value of \n100\n and just removed \n10\n with\nour previous invocation. Therefore, a query against \na\n should reveal\n\n90\n. The syntax for query is as follows.\n\n\n``` {.sourceCode .bash}\n\n\nbe sure to set the -C and -n flags appropriately\n\n\npeer chaincode query -C $CHANNEL_NAME -n mycc -c '{\"Args\":[\"query\",\"a\"]}'\n\n\n\nWe should see the following:\n\n``` {.sourceCode .bash}\nQuery Result: 90\n\n\n\n\nFeel free to start over and manipulate the key value pairs and\nsubsequent invocations.\n\n\n::: {#behind-scenes}\n\n\nWhat\\'s happening behind the scenes?\n\n\n:::\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nThese steps describe the scenario in which\n\n\n:   \nscript.sh\n is not commented out in the docker-compose-cli.yaml\n    file. Clean your network with \n./byfn.sh -m down\n and ensure this\n    command is active. Then use the same docker-compose prompt to launch\n    your network again\n:::\n\n\n\n\nA script - \nscript.sh\n - is baked inside the CLI container. The\n    script drives the \ncreateChannel\n command against the supplied\n    channel name and uses the channel.tx file for channel configuration.\n\n\nThe output of \ncreateChannel\n is a genesis block\n    -\nyour_channel_name\n.block\n - which gets stored on the peers\\' file\n    systems and contains the channel configuration specified from\n    channel.tx.\n\n\nThe \njoinChannel\n command is exercised for all four peers, which\n    takes as input the previously generated genesis block. This command\n    instructs the peers to join \nyour_channel_name\n and create a chain\n    starting with \nyour_channel_name\n.block\n.\n\n\nNow we have a channel consisting of four peers, and two\n    organizations. This is our \nTwoOrgsChannel\n profile.\n\n\npeer0.org1.example.com\n and \npeer1.org1.example.com\n belong to\n    Org1; \npeer0.org2.example.com\n and \npeer1.org2.example.com\n belong\n    to Org2\n\n\nThese relationships are defined through the \ncrypto-config.yaml\n and\n    the MSP path is specified in our docker compose.\n\n\nThe anchor peers for Org1MSP (\npeer0.org1.example.com\n) and Org2MSP\n    (\npeer0.org2.example.com\n) are then updated. We do this by passing\n    the \nOrg1MSPanchors.tx\n and \nOrg2MSPanchors.tx\n artifacts to the\n    ordering service along with the name of our channel.\n\n\nA chaincode - \nchaincode_example02\n - is installed on\n    \npeer0.org1.example.com\n and \npeer0.org2.example.com\n\n\nThe chaincode is then \\\"instantiated\\\" on \npeer0.org2.example.com\n.\n    Instantiation adds the chaincode to the channel, starts the\n    container for the target peer, and initializes the key value pairs\n    associated with the chaincode. The initial values for this example\n    are [\\\"a\\\",\\\"100\\\" \\\"b\\\",\\\"200\\\"]. This \\\"instantiation\\\" results\n    in a container by the name of \ndev-peer0.org2.example.com-mycc-1.0\n\n    starting.\n\n\nThe instantiation also passes in an argument for the endorsement\n    policy. The policy is defined as\n    \n-P \"OR    ('Org1MSP.member','Org2MSP.member')\"\n, meaning that any\n    transaction must be endorsed by a peer tied to Org1 or Org2.\n\n\nA query against the value of \\\"a\\\" is issued to\n    \npeer0.org1.example.com\n. The chaincode was previously installed on\n    \npeer0.org1.example.com\n, so this will start a container for Org1\n    peer0 by the name of \ndev-peer0.org1.example.com-mycc-1.0\n. The\n    result of the query is also returned. No write operations have\n    occurred, so a query against \\\"a\\\" will still return a value of\n    \\\"100\\\".\n\n\nAn invoke is sent to \npeer0.org1.example.com\n to move \\\"10\\\" from\n    \\\"a\\\" to \\\"b\\\"\n\n\nThe chaincode is then installed on \npeer1.org2.example.com\n\n\nA query is sent to \npeer1.org2.example.com\n for the value of \\\"a\\\".\n    This starts a third chaincode container by the name of\n    \ndev-peer1.org2.example.com-mycc-1.0\n. A value of 90 is returned,\n    correctly reflecting the previous transaction during which the value\n    for key \\\"a\\\" was modified by 10.\n\n\n\n\nWhat does this demonstrate?\n\n\nChaincode \nMUST\n be installed on a peer in order for it to\nsuccessfully perform read/write operations against the ledger.\nFurthermore, a chaincode container is not started for a peer until an\n\ninit\n or traditional transaction - read/write - is performed against\nthat chaincode (e.g. query for the value of \\\"a\\\"). The transaction\ncauses the container to start. Also, all peers in a channel maintain an\nexact copy of the ledger which comprises the blockchain to store the\nimmutable, sequenced record in blocks, as well as a state database to\nmaintain a snapshot of the current state. This includes those peers that\ndo not have chaincode installed on them (like \npeer1.org1.example.com\n\nin the above example) . Finally, the chaincode is accessible after it is\ninstalled (like \npeer1.org2.example.com\n in the above example) because\nit has already been instantiated.\n\n\nHow do I see these transactions?\n\n\nCheck the logs for the CLI Docker container.\n\n\n``` {.sourceCode .bash}\ndocker logs -f cli\n\n\n\nYou should see the following output:\n\n``` {.sourceCode .bash}\n2017-05-16 17:08:01.366 UTC [msp] GetLocalMSP -\n DEBU 004 Returning existing local MSP\n2017-05-16 17:08:01.366 UTC [msp] GetDefaultSigningIdentity -\n DEBU 005 Obtaining default signing identity\n2017-05-16 17:08:01.366 UTC [msp/identity] Sign -\n DEBU 006 Sign: plaintext: 0AB1070A6708031A0C08F1E3ECC80510...6D7963631A0A0A0571756572790A0161\n2017-05-16 17:08:01.367 UTC [msp/identity] Sign -\n DEBU 007 Sign: digest: E61DB37F4E8B0D32C9FE10E3936BA9B8CD278FAA1F3320B08712164248285C54\nQuery Result: 90\n2017-05-16 17:08:15.158 UTC [main] main -\n INFO 008 Exiting.....\n===================== Query on PEER3 on channel 'mychannel' is successful =====================\n\n===================== All GOOD, BYFN execution completed =====================\n\n\n _____   _   _   ____\n| ____| | \\ | | |  _ \\\n|  _|   |  \\| | | | | |\n| |___  | |\\  | | |_| |\n|_____| |_| \\_| |____/\n\n\n\n\nYou can scroll through these logs to see the various transactions.\n\n\nHow can I see the chaincode logs?\n\n\nInspect the individual chaincode containers to see the separate\ntransactions executed against each container. Here is the combined\noutput from each container:\n\n\n``` {.sourceCode .bash}\n$ docker logs dev-peer0.org2.example.com-mycc-1.0\n04:30:45.947 [BCCSP_FACTORY] DEBU : Initialize BCCSP [SW]\nex02 Init\nAval = 100, Bval = 200\n\n\n$ docker logs dev-peer0.org1.example.com-mycc-1.0\n04:31:10.569 [BCCSP_FACTORY] DEBU : Initialize BCCSP [SW]\nex02 Invoke\nQuery Response:{\"Name\":\"a\",\"Amount\":\"100\"}\nex02 Invoke\nAval = 90, Bval = 210\n\n\n$ docker logs dev-peer1.org2.example.com-mycc-1.0\n04:31:30.420 [BCCSP_FACTORY] DEBU : Initialize BCCSP [SW]\nex02 Invoke\nQuery Response:{\"Name\":\"a\",\"Amount\":\"90\"}\n\n\n\nUnderstanding the Docker Compose topology\n-----------------------------------------\n\nThe BYFN sample offers us two flavors of Docker Compose files, both of\nwhich are extended from the `docker-compose-base.yaml` (located in the\n`base` folder). Our first flavor, `docker-compose-cli.yaml`, provides us\nwith a CLI container, along with an orderer, four peers. We use this\nfile for the entirety of the instructions on this page.\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\nthe remainder of this section covers a docker-compose file designed for the\n\n:   SDK. Refer to the [Node\n    SDK](https://github.com/hyperledger/fabric-sdk-node) repo for\n    details on running these tests.\n:::\n\nThe second flavor, `docker-compose-e2e.yaml`, is constructed to run\nend-to-end tests using the Node.js SDK. Aside from functioning with the\nSDK, its primary differentiation is that there are containers for the\nfabric-ca servers. As a result, we are able to send REST calls to the\norganizational CAs for user registration and enrollment.\n\nIf you want to use the `docker-compose-e2e.yaml` without first running\nthe byfn.sh script, then we will need to make four slight modifications.\nWe need to point to the private keys for our Organization\\'s CA\\'s. You\ncan locate these values in your crypto-config folder. For example, to\nlocate the private key for Org1 we would follow this path -\n`crypto-config/peerOrganizations/org1.example.com/ca/`. The private key\nis a long hash value followed by `_sk`. The path for Org2 would be -\n`crypto-config/peerOrganizations/org2.example.com/ca/`.\n\nIn the `docker-compose-e2e.yaml` update the\nFABRIC\\_CA\\_SERVER\\_TLS\\_KEYFILE variable for ca0 and ca1. You also need\nto edit the path that is provided in the command to start the ca server.\nYou are providing the same private key twice for each CA container.\n\nUsing CouchDB\n-------------\n\nThe state database can be switched from the default (goleveldb) to\nCouchDB. The same chaincode functions are available with CouchDB,\nhowever, there is the added ability to perform rich and complex queries\nagainst the state database data content contingent upon the chaincode\ndata being modeled as JSON.\n\nTo use CouchDB instead of the default database (goleveldb), follow the\nsame procedures outlined earlier for generating the artifacts, except\nwhen starting the network pass `docker-compose-couch.yaml` as well:\n\n``` {.sourceCode .bash}\nCHANNEL_NAME=$CHANNEL_NAME TIMEOUT=\npick_a_value\n docker-compose -f docker-compose-cli.yaml -f docker-compose-couch.yaml up -d\n\n\n\n\nchaincode_example02\n should now work using CouchDB underneath.\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nIf you choose to implement mapping of the fabric-couchdb container\n\n\n:   port to a host port, please make sure you are aware of the security\n    implications. Mapping of the port in a development environment makes\n    the CouchDB REST API available, and allows the visualization of the\n    database via the CouchDB web interface (Fauxton). Production\n    environments would likely refrain from implementing port mapping in\n    order to restrict outside access to the CouchDB containers.\n:::\n\n\nYou can use \nchaincode_example02\n chaincode against the CouchDB state\ndatabase using the steps outlined above, however in order to exercise\nthe CouchDB query capabilities you will need to use a chaincode that has\ndata modeled as JSON, (e.g. \nmarbles02\n). You can locate the\n\nmarbles02\n chaincode in the \nfabric/examples/chaincode/go\n directory.\n\n\nWe will follow the same process to create and join the channel as\noutlined in the [createandjoin]{role=\"ref\"} section above. Once you have\njoined your peer(s) to the channel, use the following steps to interact\nwith the \nmarbles02\n chaincode:\n\n\n\n\nInstall and instantiate the chaincode on \npeer0.org1.example.com\n:\n\n\n\n\n``` {.sourceCode .bash}\n\n\nbe sure to modify the $CHANNEL_NAME variable accordingly for the instantiate command\n\n\npeer chaincode install -n marbles -v 1.0 -p github.com/hyperledger/fabric/examples/chaincode/go/marbles02\npeer chaincode instantiate -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n marbles -v 1.0 -c '{\"Args\":[\"init\"]}' -P \"OR ('Org0MSP.member','Org1MSP.member')\"\n\n\n\n-   Create some marbles and move them around:\n\n``` {.sourceCode .bash}\n# be sure to modify the $CHANNEL_NAME variable accordingly\n\npeer chaincode invoke -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n marbles -c '{\nArgs\n:[\ninitMarble\n,\nmarble1\n,\nblue\n,\n35\n,\ntom\n]}'\npeer chaincode invoke -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n marbles -c '{\nArgs\n:[\ninitMarble\n,\nmarble2\n,\nred\n,\n50\n,\ntom\n]}'\npeer chaincode invoke -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n marbles -c '{\nArgs\n:[\ninitMarble\n,\nmarble3\n,\nblue\n,\n70\n,\ntom\n]}'\npeer chaincode invoke -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n marbles -c '{\nArgs\n:[\ntransferMarble\n,\nmarble2\n,\njerry\n]}'\npeer chaincode invoke -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n marbles -c '{\nArgs\n:[\ntransferMarblesBasedOnColor\n,\nblue\n,\njerry\n]}'\npeer chaincode invoke -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n marbles -c '{\nArgs\n:[\ndelete\n,\nmarble1\n]}'\n\n\n\n\n\n\n\n\nIf you chose to map the CouchDB ports in docker-compose, you can now\n    view the state database through the CouchDB web interface (Fauxton)\n    by opening a browser and navigating to the following URL:\n\n\nhttp://localhost:5984/_utils\n\n\n\n\n\n\nYou should see a database named \nmychannel\n (or your unique channel\nname) and the documents inside it.\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nFor the below commands, be sure to update the \\$CHANNEL_NAME variable\nappropriately.\n:::\n\n\nYou can run regular queries from the CLI (e.g. reading \nmarble2\n):\n\n\n``` {.sourceCode .bash}\npeer chaincode query -C $CHANNEL_NAME -n marbles -c '{\"Args\":[\"readMarble\",\"marble2\"]}'\n\n\n\nThe output should display the details of `marble2`:\n\n``` {.sourceCode .bash}\nQuery Result: {\ncolor\n:\nred\n,\ndocType\n:\nmarble\n,\nname\n:\nmarble2\n,\nowner\n:\njerry\n,\nsize\n:50}\n\n\n\n\nYou can retrieve the history of a specific marble - e.g. \nmarble1\n:\n\n\n``` {.sourceCode .bash}\npeer chaincode query -C $CHANNEL_NAME -n marbles -c '{\"Args\":[\"getHistoryForMarble\",\"marble1\"]}'\n\n\n\nThe output should display the transactions on `marble1`:\n\n``` {.sourceCode .bash}\nQuery Result: [{\nTxId\n:\n1c3d3caf124c89f91a4c0f353723ac736c58155325f02890adebaa15e16e6464\n, \nValue\n:{\ndocType\n:\nmarble\n,\nname\n:\nmarble1\n,\ncolor\n:\nblue\n,\nsize\n:35,\nowner\n:\ntom\n}},{\nTxId\n:\n755d55c281889eaeebf405586f9e25d71d36eb3d35420af833a20a2f53a3eefd\n, \nValue\n:{\ndocType\n:\nmarble\n,\nname\n:\nmarble1\n,\ncolor\n:\nblue\n,\nsize\n:35,\nowner\n:\njerry\n}},{\nTxId\n:\n819451032d813dde6247f85e56a89262555e04f14788ee33e28b232eef36d98f\n, \nValue\n:}]\n\n\n\n\nYou can also perform rich queries on the data content, such as querying\nmarble fields by owner \njerry\n:\n\n\n``` {.sourceCode .bash}\npeer chaincode query -C $CHANNEL_NAME -n marbles -c '{\"Args\":[\"queryMarblesByOwner\",\"jerry\"]}'\n\n\n\nThe output should display the two marbles owned by `jerry`:\n\n``` {.sourceCode .bash}\nQuery Result: [{\nKey\n:\nmarble2\n, \nRecord\n:{\ncolor\n:\nred\n,\ndocType\n:\nmarble\n,\nname\n:\nmarble2\n,\nowner\n:\njerry\n,\nsize\n:50}},{\nKey\n:\nmarble3\n, \nRecord\n:{\ncolor\n:\nblue\n,\ndocType\n:\nmarble\n,\nname\n:\nmarble3\n,\nowner\n:\njerry\n,\nsize\n:70}}]\n\n\n\n\nWhy CouchDB\n\n\nCouchDB is a kind of NoSQL solution. It is a document oriented database\nwhere document fields are stored as key-value mpas. Fields can be either\na simple key/value pair, list, or map. In addition to\nkeyed/composite-key/key-range queries which are supported by LevelDB,\nCouchDB also supports full data rich queries capability, such as non-key\nqueries against the whole blockchain data, since its data content is\nstored in JSON format and fully queryable. Therefore, CouchDB can meet\nchaincode, auditing, reporting requirements for many use cases that not\nsupported by LevelDB.\n\n\nCouchDB can also enhance the security for compliance and data protection\nin the blockchain. As it is able to implement field-level security\nthrough the filtering and masking of individual attributes within a\ntransaction, and only authorizing the read-only permission if needed.\n\n\nIn addition, CouchDB falls into the AP-type (Availability and Partition\nTolerance) of the CAP theorem. It uses a master-master replication model\nwith \nEventual Consistency\n. More information can be found on the\n\nEventual Consistency page of the CouchDB\ndocumentation\n.\nHowever, under each fabric peer, there is no database replicas, writes\nto database are guaranteed consistent and durable (not\n\nEventual Consistency\n).\n\n\nCouchDB is the first external pluggable state database for Fabric, and\nthere could and should be other external database options. For example,\nIBM enables the relational database for its blockchain. And the CP-type\n(Consistency and Partition Tolerance) databases may also in need, so as\nto enable data consistency without application level guarantee.\n\n\nA Note on Data Persistence\n\n\nIf data persistence is desired on the peer container or the CouchDB\ncontainer, one option is to mount a directory in the docker-host into a\nrelevant directory in the container. For example, you may add the\nfollowing two lines in the peer container specification in the\n\ndocker-compose-base.yaml\n file:\n\n\n``` {.sourceCode .bash}\nvolumes:\n - /var/hyperledger/peer0:/var/hyperledger/production\n\n\n\nFor the CouchDB container, you may add the following two lines in the\nCouchDB container specification:\n\n``` {.sourceCode .bash}\nvolumes:\n - /var/hyperledger/couchdb0:/opt/couchdb/data\n\n\n\n\n::: {#Troubleshoot}\nTroubleshooting\n\n\n\n\n:::\n\n\n\n\n\n\nAlways start your network fresh. Use the following command to remove\n    artifacts, crypto, containers and chaincode images:\n\n\n{.sourceCode .bash}\n./byfn.sh -m down\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nYou \nwill\n see errors if you do not remove old containers\n\n\n:   and images.\n:::\n\n\n\n\n\n\nIf you see Docker errors, first check your docker version\n    ([prereqs]{role=\"doc\"}), and then try restarting your Docker\n    process. Problems with Docker are oftentimes not immediately\n    recognizable. For example, you may see errors resulting from an\n    inability to access crypto material mounted within a container.\n\n\nIf they persist remove your images and start from scratch:\n\n\n{.sourceCode .bash}\ndocker rm -f $(docker ps -aq)\ndocker rmi -f $(docker images -q)\n\n\n\n\n\n\nIf you see errors on your create, instantiate, invoke or query\n    commands, make sure you have properly updated the channel name and\n    chaincode name. There are placeholder values in the supplied sample\n    commands.\n\n\n\n\n\n\nIf you see the below error:\n\n\n{.sourceCode .bash}\nError: Error endorsing chaincode: rpc error: code = 2 desc = Error installing chaincode code mycc:1.0(chaincode /var/hyperledger/production/chaincodes/mycc.1.0 exits)\n\n\nYou likely have chaincode images (e.g.\n\ndev-peer1.org2.example.com-mycc-1.0\n or\n\ndev-peer0.org1.example.com-mycc-1.0\n) from prior runs. Remove them\nand try again.\n\n\n{.sourceCode .bash}\ndocker rmi -f $(docker images | grep peer[0-9]-peer[0-9] | awk '{print $3}')\n\n\n\n\n\n\nIf you see something similar to the following:\n\n\n{.sourceCode .bash}\nError connecting: rpc error: code = 14 desc = grpc: RPC failed fast due to transport failure\nError: rpc error: code = 14 desc = grpc: RPC failed fast due to transport failure\n\n\nMake sure you are running your network against the \\\"1.0.0\\\" images\nthat have been retagged as \\\"latest\\\".\n\n\n\n\n\n\nIf you see the below error:\n\n\n{.sourceCode .bash}\n[configtx/tool/localconfig] Load -\n CRIT 002 Error reading configuration: Unsupported Config Type \"\"\npanic: Error reading configuration: Unsupported Config Type \"\"\n\n\nThen you did not set the \nFABRIC_CFG_PATH\n environment variable\nproperly. The configtxgen tool needs this variable in order to\nlocate the configtx.yaml. Go back and execute an\n\nexport FABRIC_CFG_PATH=$PWD\n, then recreate your channel artifacts.\n\n\n\n\n\n\nTo cleanup the network, use the \ndown\n option:\n\n\n{.sourceCode .bash}\n./byfn.sh -m down\n\n\n\n\n\n\nIf you see an error stating that you still have \\\"active\n    endpoints\\\", then prune your Docker networks. This will wipe your\n    previous networks and start you with a fresh environment:\n\n\n{.sourceCode .bash}\ndocker network prune\n\n\nYou will see the following message:\n\n\n{.sourceCode .bash}\nWARNING! This will remove all networks not used by at least one container.\nAre you sure you want to continue? [y/N]\n\n\nSelect \ny\n.\n\n\n\n\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nIf you continue to see errors, share your logs on the\n\n\n:   \nfabric-questions\n channel on \nHyperledger Rocket\n    Chat\n or on\n    \nStackOverflow\n.\n:::", 
            "title": "Build Your First Network"
        }, 
        {
            "location": "/build_network/#building-your-first-network", 
            "text": "::: {.note}\n::: {.admonition-title}\nNote\n:::  These instructions have been verified to work against the  :   latest stable Docker images and the pre-compiled setup utilities\n    within the supplied tar file. If you run these commands with images\n    or tools from the current master branch, it is possible that you\n    will see configuration and panic errors.\n:::  The build your first network (BYFN) scenario provisions a sample\nHyperledger Fabric network consisting of two organizations, each\nmaintaining two peer nodes, and a \\\"solo\\\" ordering service.", 
            "title": "Building Your First Network"
        }, 
        {
            "location": "/build_network/#install-prerequisites", 
            "text": "Before we begin, if you haven\\'t already done so, you may wish to check\nthat you have all the [prereqs]{role=\"doc\"} installed on the platform(s)\non which you\\'ll be developing blockchain applications and/or operating\nHyperledger Fabric.  You will also need to download and install the [samples]{role=\"doc\"}.\nYou will notice that there are a number of samples included in the fabric-samples  repository. We will be using the  first-network \nsample. Let\\'s open that sub-directory now.  ``` {.sourceCode .bash}\ncd fabric-samples/first-network  \n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\nThe supplied commands in this documentation\n\n:   **MUST** be run from your `first-network` sub-directory of the\n    `fabric-samples` repository clone. If you elect to run the commands\n    from a different location, the various provided scripts will be\n    unable to find the binaries.\n:::\n\nWant to run it now?\n-------------------\n\nWe provide a fully annotated script - `byfn.sh` - that leverages these\nDocker images to quickly bootstrap a Hyperledger Fabric network\ncomprised of 4 peers representing two different organizations, and an\norderer node. It will also launch a container to run a scripted\nexecution that will join peers to a channel, deploy and instantiate\nchaincode and drive execution of transactions against the deployed\nchaincode.\n\nHere\\'s the help text for the `byfn.sh` script:\n\n``` {.sourceCode .bash}\n./byfn.sh --help\nUsage:\nbyfn.sh -m up|down|restart|generate [-c  channel name ] [-t  timeout ] [-d  delay ] [-f  docker-compose-file ] [-s  dbtype ]\nbyfn.sh -h|--help (print this message)\n  -m  mode  - one of 'up', 'down', 'restart' or 'generate'\n    - 'up' - bring up the network with docker-compose up\n    - 'down' - clear the network with docker-compose down\n    - 'restart' - restart the network\n    - 'generate' - generate required certificates and genesis block\n  -c  channel name  - channel name to use (defaults to  mychannel )\n  -t  timeout  - CLI timeout duration in seconds (defaults to 10000)\n  -d  delay  - delay duration in seconds (defaults to 3)\n  -f  docker-compose-file  - specify which docker-compose file use (defaults to docker-compose-cli.yaml)\n  -s  dbtype  - the database backend to use: goleveldb (default) or couchdb\n  -l  language  - the chaincode language: golang (default) or node\n\n  Typically, one would first generate the required certificates and\n  genesis block, then bring up the network. e.g.:\n\n  byfn.sh -m generate -c mychannel\n  byfn.sh -m up -c mychannel -s couchdb  If you choose not to supply a channel name, then the script will use a\ndefault name of  mychannel . The CLI timeout parameter (specified with\nthe -t flag) is an optional value; if you choose not to set it, then\nyour CLI container will exit after the default setting of 10000 seconds.", 
            "title": "Install prerequisites"
        }, 
        {
            "location": "/build_network/#generate-network-artifacts", 
            "text": "Ready to give it a go? Okay then! Execute the following command:  ``` {.sourceCode .bash}\n./byfn.sh -m generate  \nYou will see a brief description as to what will occur, along with a\nyes/no command line prompt. Respond with a `y` to execute the described\naction.\n\n``` {.sourceCode .bash}\nGenerating certs and genesis block for with channel 'mychannel' and CLI timeout of '10000'\nContinue (y/n)?y\nproceeding ...\n/Users/xxx/dev/fabric-samples/bin/cryptogen\n\n##########################################################\n##### Generate certificates using cryptogen tool #########\n##########################################################\norg1.example.com\n2017-06-12 21:01:37.334 EDT [bccsp] GetDefault -  WARN 001 Before using BCCSP, please call InitFactories(). Falling back to bootBCCSP.\n...\n\n/Users/xxx/dev/fabric-samples/bin/configtxgen\n##########################################################\n#########  Generating Orderer Genesis block ##############\n##########################################################\n2017-06-12 21:01:37.558 EDT [common/configtx/tool] main -  INFO 001 Loading configuration\n2017-06-12 21:01:37.562 EDT [msp] getMspConfig -  INFO 002 intermediate certs folder not found at [/Users/xxx/dev/byfn/crypto-config/ordererOrganizations/example.com/msp/intermediatecerts]. Skipping.: [stat /Users/xxx/dev/byfn/crypto-config/ordererOrganizations/example.com/msp/intermediatecerts: no such file or directory]\n...\n2017-06-12 21:01:37.588 EDT [common/configtx/tool] doOutputBlock -  INFO 00b Generating genesis block\n2017-06-12 21:01:37.590 EDT [common/configtx/tool] doOutputBlock -  INFO 00c Writing genesis block\n\n#################################################################\n### Generating channel configuration transaction 'channel.tx' ###\n#################################################################\n2017-06-12 21:01:37.634 EDT [common/configtx/tool] main -  INFO 001 Loading configuration\n2017-06-12 21:01:37.644 EDT [common/configtx/tool] doOutputChannelCreateTx -  INFO 002 Generating new channel configtx\n2017-06-12 21:01:37.645 EDT [common/configtx/tool] doOutputChannelCreateTx -  INFO 003 Writing new channel tx\n\n#################################################################\n#######    Generating anchor peer update for Org1MSP   ##########\n#################################################################\n2017-06-12 21:01:37.674 EDT [common/configtx/tool] main -  INFO 001 Loading configuration\n2017-06-12 21:01:37.678 EDT [common/configtx/tool] doOutputAnchorPeersUpdate -  INFO 002 Generating anchor peer update\n2017-06-12 21:01:37.679 EDT [common/configtx/tool] doOutputAnchorPeersUpdate -  INFO 003 Writing anchor peer update\n\n#################################################################\n#######    Generating anchor peer update for Org2MSP   ##########\n#################################################################\n2017-06-12 21:01:37.700 EDT [common/configtx/tool] main -  INFO 001 Loading configuration\n2017-06-12 21:01:37.704 EDT [common/configtx/tool] doOutputAnchorPeersUpdate -  INFO 002 Generating anchor peer update\n2017-06-12 21:01:37.704 EDT [common/configtx/tool] doOutputAnchorPeersUpdate -  INFO 003 Writing anchor peer update  This first step generates all of the certificates and keys for our\nvarious network entities, the  genesis block  used to bootstrap the\nordering service, and a collection of configuration transactions\nrequired to configure a [Channel]{role=\"ref\"}.", 
            "title": "Generate Network Artifacts"
        }, 
        {
            "location": "/build_network/#bring-up-the-network", 
            "text": "Next, you can bring the network up with one of the following commands:  ``` {.sourceCode .bash}\n./byfn.sh -m up  \nThe above command will compile Golang chaincode images and spin up the\ncorresponding containers. Go is the default chaincode language, however\nthere is also support for Node.js chaincode. If you\\'d like to run\nthrough this tutorial with node chaincode, pass the following command\ninstead:\n\n``` {.sourceCode .bash}\n# we use the -l flag to specify the chaincode language\n# forgoing the -l flag will default to Golang\n\n./byfn.sh -m up -l node  ::: {.note}\n::: {.admonition-title}\nNote\n:::  View the  Hyperledger Fabric Shim  :   documentation for more info on the node.js chaincode shim APIs.\n:::  Once again, you will be prompted as to whether you wish to continue or\nabort. Respond with a  y :  ``` {.sourceCode .bash}\nStarting with channel 'mychannel' and CLI timeout of '10000'\nContinue (y/n)?y\nproceeding ...\nCreating network \"net_byfn\" with the default driver\nCreating peer0.org1.example.com\nCreating peer1.org1.example.com\nCreating peer0.org2.example.com\nCreating orderer.example.com\nCreating peer1.org2.example.com\nCreating cli  _           _       _     \n/  |  |     |    / \\    |  _ \\  |    _|\n_  \\    | |     / _ \\   | | ) |   | |\n  ) |   | |    /   \\  |  _      | |\n|____/    | |   / /   _\\ | | _\\   |_|  Channel name : mychannel\nCreating channel...  \nThe logs will continue from there. This will launch all of the\ncontainers, and then drive a complete end-to-end application scenario.\nUpon successful completion, it should report the following in your\nterminal window:\n\n``` {.sourceCode .bash}\n2017-05-16 17:08:01.366 UTC [msp] GetLocalMSP -  DEBU 004 Returning existing local MSP\n2017-05-16 17:08:01.366 UTC [msp] GetDefaultSigningIdentity -  DEBU 005 Obtaining default signing identity\n2017-05-16 17:08:01.366 UTC [msp/identity] Sign -  DEBU 006 Sign: plaintext: 0AB1070A6708031A0C08F1E3ECC80510...6D7963631A0A0A0571756572790A0161\n2017-05-16 17:08:01.367 UTC [msp/identity] Sign -  DEBU 007 Sign: digest: E61DB37F4E8B0D32C9FE10E3936BA9B8CD278FAA1F3320B08712164248285C54\nQuery Result: 90\n2017-05-16 17:08:15.158 UTC [main] main -  INFO 008 Exiting.....\n===================== Query on PEER3 on channel 'mychannel' is successful =====================\n\n===================== All GOOD, BYFN execution completed =====================\n\n\n _____   _   _   ____\n| ____| | \\ | | |  _ \\\n|  _|   |  \\| | | | | |\n| |___  | |\\  | | |_| |\n|_____| |_| \\_| |____/  You can scroll through these logs to see the various transactions. If\nyou don\\'t get this result, then jump down to the\n[Troubleshoot]{role=\"ref\"} section and let\\'s see whether we can help\nyou discover what went wrong.", 
            "title": "Bring Up the Network"
        }, 
        {
            "location": "/build_network/#bring-down-the-network", 
            "text": "Finally, let\\'s bring it all down so we can explore the network setup\none step at a time. The following will kill your containers, remove the\ncrypto material and four artifacts, and delete the chaincode images from\nyour Docker Registry:  ``` {.sourceCode .bash}\n./byfn.sh -m down  \nOnce again, you will be prompted to continue, respond with a `y`:\n\n``` {.sourceCode .bash}\nStopping with channel 'mychannel' and CLI timeout of '10000'\nContinue (y/n)?y\nproceeding ...\nWARNING: The CHANNEL_NAME variable is not set. Defaulting to a blank string.\nWARNING: The TIMEOUT variable is not set. Defaulting to a blank string.\nRemoving network net_byfn\n468aaa6201ed\n...\nUntagged: dev-peer1.org2.example.com-mycc-1.0:latest\nDeleted: sha256:ed3230614e64e1c83e510c0c282e982d2b06d148b1c498bbdcc429e2b2531e91\n...  If you\\'d like to learn more about the underlying tooling and bootstrap\nmechanics, continue reading. In these next sections we\\'ll walk through\nthe various steps and requirements to build a fully-functional\nHyperledger Fabric network.", 
            "title": "Bring Down the Network"
        }, 
        {
            "location": "/build_network/#crypto-generator", 
            "text": "We will use the  cryptogen  tool to generate the cryptographic material\n(x509 certs and signing keys) for our various network entities. These\ncertificates are representative of identities, and they allow for\nsign/verify authentication to take place as our entities communicate and\ntransact.", 
            "title": "Crypto Generator"
        }, 
        {
            "location": "/build_network/#how-does-it-work", 
            "text": "Cryptogen consumes a file -  crypto-config.yaml  - that contains the\nnetwork topology and allows us to generate a set of certificates and\nkeys for both the Organizations and the components that belong to those\nOrganizations. Each Organization is provisioned a unique root\ncertificate ( ca-cert ) that binds specific components (peers and\norderers) to that Org. By assigning each Organization a unique CA\ncertificate, we are mimicking a typical network where a participating\n[Member]{role=\"ref\"} would use its own Certificate Authority.\nTransactions and communications within Hyperledger Fabric are signed by\nan entity\\'s private key ( keystore ), and then verified by means of a\npublic key ( signcerts ).  You will notice a  count  variable within this file. We use this to\nspecify the number of peers per Organization; in our case there are two\npeers per Org. We won\\'t delve into the minutiae of  x.509 certificates\nand public key\ninfrastructure \nright now. If you\\'re interested, you can peruse these topics on your\nown time.  Before running the tool, let\\'s take a quick look at a snippet from the crypto-config.yaml . Pay specific attention to the \\\"Name\\\", \\\"Domain\\\"\nand \\\"Specs\\\" parameters under the  OrdererOrgs  header:  ``` {.sourceCode .bash}\nOrdererOrgs:", 
            "title": "How does it work?"
        }, 
        {
            "location": "/build_network/#-", 
            "text": "", 
            "title": "---------------------------------------------------------"
        }, 
        {
            "location": "/build_network/#orderer", 
            "text": "", 
            "title": "Orderer"
        }, 
        {
            "location": "/build_network/#-_1", 
            "text": "Name: Orderer\n  Domain: example.com\n  CA:\n      Country: US\n      Province: California\n      Locality: San Francisco\n  #   OrganizationalUnit: Hyperledger Fabric\n  #   StreetAddress: address for org # default nil\n  #   PostalCode: postalCode for org # default nil\n  # ------------------------------------------------------\n  # \"Specs\" - See PeerOrgs below for complete description", 
            "title": "--------------------------------------------------------"
        }, 
        {
            "location": "/build_network/#-_2", 
            "text": "Specs:\n    - Hostname: orderer", 
            "title": "-----------------------------------------------------"
        }, 
        {
            "location": "/build_network/#-_3", 
            "text": "", 
            "title": "-------------------------------------------------------"
        }, 
        {
            "location": "/build_network/#peerorgs-definition-of-organizations-managing-peer-nodes", 
            "text": "", 
            "title": "\"PeerOrgs\" - Definition of organizations managing peer nodes"
        }, 
        {
            "location": "/build_network/#-_4", 
            "text": "PeerOrgs:", 
            "title": "------------------------------------------------------"
        }, 
        {
            "location": "/build_network/#-_5", 
            "text": "", 
            "title": "-----------------------------------------------------"
        }, 
        {
            "location": "/build_network/#org1", 
            "text": "", 
            "title": "Org1"
        }, 
        {
            "location": "/build_network/#-_6", 
            "text": "Name: Org1\n  Domain: org1.example.com   \nThe naming convention for a network entity is as follows\n-\\ {{.Hostname}}.{{.Domain}}\\ . So using our ordering node as a\nreference point, we are left with an ordering node named\n-`orderer.example.com` that is tied to an MSP ID of `Orderer`. This file\ncontains extensive documentation on the definitions and syntax. You can\nalso refer to the [msp]{role= doc } documentation for a deeper dive on\nMSP.\n\nAfter we run the `cryptogen` tool, the generated certificates and keys\nwill be saved to a folder titled `crypto-config`.\n\nConfiguration Transaction Generator\n-----------------------------------\n\nThe `configtxgen tool` is used to create four configuration artifacts:  -   orderer `genesis block`,  -   channel `configuration transaction`,  -   and two `anchor peer transactions` - one for each Peer Org.\n\nPlease see [configtxgen]{role= doc } for a complete description of this\ntool\\'s functionality.\n\nThe orderer block is the [Genesis-Block]{role= ref } for the ordering\nservice, and the channel configuration transaction file is broadcast to\nthe orderer at [Channel]{role= ref } creation time. The anchor peer\ntransactions, as the name might suggest, specify each Org\\'s\n[Anchor-Peer]{role= ref } on this channel.\n\n### How does it work?\n\nConfigtxgen consumes a file - `configtx.yaml` - that contains the\ndefinitions for the sample network. There are three members - one\nOrderer Org (`OrdererOrg`) and two Peer Orgs (`Org1`   `Org2`) each\nmanaging and maintaining two peer nodes. This file also specifies a\nconsortium - `SampleConsortium` - consisting of our two Peer Orgs. Pay\nspecific attention to the \\ Profiles\\  section at the top of this file.\nYou will notice that we have two unique headers. One for the orderer\ngenesis block - `TwoOrgsOrdererGenesis` - and one for our channel -\n`TwoOrgsChannel`.\n\nThese headers are important, as we will pass them in as arguments when\nwe create our artifacts.\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\nNotice that our `SampleConsortium` is defined in\n\n:   the system-level profile and then referenced by our channel-level\n    profile. Channels exist within the purview of a consortium, and all\n    consortia must be defined in the scope of the network at large.\n:::\n\nThis file also contains two additional specifications that are worth\nnoting. Firstly, we specify the anchor peers for each Peer Org\n(`peer0.org1.example.com`   `peer0.org2.example.com`). Secondly, we\npoint to the location of the MSP directory for each member, in turn\nallowing us to store the root certificates for each Org in the orderer\ngenesis block. This is a critical concept. Now any network entity\ncommunicating with the ordering service can have its digital signature\nverified.\n\nRun the tools\n-------------\n\nYou can manually generate the certificates/keys and the various\nconfiguration artifacts using the `configtxgen` and `cryptogen`\ncommands. Alternately, you could try to adapt the byfn.sh script to\naccomplish your objectives.\n\n### Manually generate the artifacts\n\nYou can refer to the `generateCerts` function in the byfn.sh script for\nthe commands necessary to generate the certificates that will be used\nfor your network configuration as defined in the `crypto-config.yaml`\nfile. However, for the sake of convenience, we will also provide a\nreference here.\n\nFirst let\\'s run the `cryptogen` tool. Our binary is in the `bin`\ndirectory, so we need to provide the relative path to where the tool\nresides.\n\n``` {.sourceCode .bash}\n../bin/cryptogen generate --config=./crypto-config.yaml  You should see the following in your terminal:  ``` {.sourceCode .bash}\norg1.example.com\norg2.example.com  \nThe certs and keys (i.e. the MSP material) will be output into a\ndirectory - `crypto-config` -at the root of the `first-network`\ndirectory.\n\nNext, we need to tell the `configtxgen` tool where to look for the\n`configtx.yaml` file that it needs to ingest. We will tell it look in\nour present working directory:\n\n``` {.sourceCode .bash}\nexport FABRIC_CFG_PATH=$PWD  Then, we\\'ll invoke the  configtxgen  tool to create the orderer genesis\nblock:  ``` {.sourceCode .bash}\n../bin/configtxgen -profile TwoOrgsOrdererGenesis -outputBlock ./channel-artifacts/genesis.block  \nYou should see an output similar to the following in your terminal:\n\n``` {.sourceCode .bash}\n2017-10-26 19:21:56.301 EDT [common/tools/configtxgen] main -  INFO 001 Loading configuration\n2017-10-26 19:21:56.309 EDT [common/tools/configtxgen] doOutputBlock -  INFO 002 Generating genesis block\n2017-10-26 19:21:56.309 EDT [common/tools/configtxgen] doOutputBlock -  INFO 003 Writing genesis block  ::: {.note}\n::: {.admonition-title}\nNote\n:::  The orderer genesis block and the subsequent artifacts we are about to create  :   will be output into the  channel-artifacts  directory at the root of\n    this project.\n:::  ::: {#createchanneltx}", 
            "title": "----------------------------------------------------"
        }, 
        {
            "location": "/build_network/#create-a-channel-configuration-transaction", 
            "text": ":::  Next, we need to create the channel transaction artifact. Be sure to\nreplace  $CHANNEL_NAME  or set  CHANNEL_NAME  as an environment variable\nthat can be used throughout these instructions:  ``` {.sourceCode .bash}", 
            "title": "Create a Channel Configuration Transaction"
        }, 
        {
            "location": "/build_network/#the-channeltx-artifact-contains-the-definitions-for-our-sample-channel", 
            "text": "export CHANNEL_NAME=mychannel    ../bin/configtxgen -profile TwoOrgsChannel -outputCreateChannelTx ./channel-artifacts/channel.tx -channelID $CHANNEL_NAME  \nYou should see an ouput similar to the following in your terminal:\n\n``` {.sourceCode .bash}\n2017-10-26 19:24:05.324 EDT [common/tools/configtxgen] main -  INFO 001 Loading configuration\n2017-10-26 19:24:05.329 EDT [common/tools/configtxgen] doOutputChannelCreateTx -  INFO 002 Generating new channel configtx\n2017-10-26 19:24:05.329 EDT [common/tools/configtxgen] doOutputChannelCreateTx -  INFO 003 Writing new channel tx  Next, we will define the anchor peer for Org1 on the channel that we are\nconstructing. Again, be sure to replace  $CHANNEL_NAME  or set the\nenvironment variable for the following commands. The terminal output\nwill mimic that of the channel transaction artifact:  ``` {.sourceCode .bash}\n../bin/configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org1MSPanchors.tx -channelID $CHANNEL_NAME -asOrg Org1MSP  \nNow, we will define the anchor peer for Org2 on the same channel:\n\n``` {.sourceCode .bash}\n../bin/configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate ./channel-artifacts/Org2MSPanchors.tx -channelID $CHANNEL_NAME -asOrg Org2MSP", 
            "title": "The channel.tx artifact contains the definitions for our sample channel"
        }, 
        {
            "location": "/build_network/#start-the-network", 
            "text": "We will leverage a docker-compose script to spin up our network. The\ndocker-compose file references the images that we have previously\ndownloaded, and bootstraps the orderer with our previously generated genesis.block .  ::: {.note}\n::: {.admonition-title}\nNote\n:::  Before launching the network, open the  docker-compose-cli.yaml  file  :   and comment out the script.sh in the CLI container. Your\n    docker-compose should be modified to look like this:\n:::  ``` {.sourceCode .bash}\nworking_dir: /opt/gopath/src/github.com/hyperledger/fabric/peer", 
            "title": "Start the network"
        }, 
        {
            "location": "/build_network/#command-binbash-c-scriptsscriptsh-channel_name-sleep-timeout", 
            "text": "volumes  \nIf left uncommented, that script will exercise all of the CLI commands\nwhen the network is started, as we describe in the\n[behind-scenes]{role= ref } section. However, we want to go through the\ncommands manually in order to expose the syntax and functionality of\neach call.\n\nThe CLI timeout defaults to 10000 seconds. If you need the container\navailable for longer, you can overwrite this setting by passing in a\nvalue for the `TIMEOUT` environment variable.\n\nStart your network:\n\n``` {.sourceCode .bash}\n# if you need the CLI accessible beyond 10000 seconds, pass in TIMEOUT= your_desired_value \n# after the CHANNEL_NAME variable\n\nCHANNEL_NAME=$CHANNEL_NAME docker-compose -f docker-compose-cli.yaml up -d  If you want to see the realtime logs for your network, then do not\nsupply the  -d  flag. If you let the logs stream, then you will need to\nopen a second terminal to execute the CLI calls.  ::: {#peerenvvars}", 
            "title": "command: /bin/bash -c './scripts/script.sh ${CHANNEL_NAME}; sleep $TIMEOUT'"
        }, 
        {
            "location": "/build_network/#environment-variables", 
            "text": ":::  For the following CLI commands against  peer0.org1.example.com  to work,\nwe need to preface our commands with the four environment variables\ngiven below. These variables for  peer0.org1.example.com  are baked into\nthe CLI container, therefore we can operate without passing them. HOWEVER , if you want to send calls to other peers or the orderer,\nthen you will need to provide these values accordingly. Inspect the docker-compose-base.yaml  for the specific paths:  ``` {.sourceCode .bash}", 
            "title": "Environment variables"
        }, 
        {
            "location": "/build_network/#environment-variables-for-peer0", 
            "text": "CORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/users/Admin@org1.example.com/msp\nCORE_PEER_ADDRESS=peer0.org1.example.com:7051\nCORE_PEER_LOCALMSPID=\"Org1MSP\"\nCORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org1.example.com/peers/peer0.org1.example.com/tls/ca.crt  \n::: {#createandjoin}\n### Create   Join Channel\n:::\n\nRecall that we created the channel configuration transaction using the\n`configtxgen` tool in the [createchanneltx]{role= ref } section, above.\nYou can repeat that process to create additional channel configuration\ntransactions, using the same or different profiles in the\n`configtx.yaml` that you pass to the `configtxgen` tool. Then you can\nrepeat the process defined in this section to establish those other\nchannels in your network.\n\nWe will enter the CLI container using the `docker exec` command:\n\n``` {.sourceCode .bash}\ndocker exec -it cli bash  If successful you should see the following:  ``` {.sourceCode .bash}\nroot@0d78bb69300d:/opt/gopath/src/github.com/hyperledger/fabric/peer#  \nNext, we are going to pass in the generated channel configuration\ntransaction artifact that we created in the\n[createchanneltx]{role= ref } section (we called it `channel.tx`) to the\norderer as part of the create channel request.\n\nWe specify our channel name with the `-c` flag and our channel\nconfiguration transaction with the `-f` flag. In this case it is\n`channel.tx`, however you can mount your own configuration transaction\nwith a different name. Once again we will set the `CHANNEL_NAME`\nenvironment variable within our CLI container so that we don\\'t have to\nexplicitly pass this argument:\n\n``` {.sourceCode .bash}\nexport CHANNEL_NAME=mychannel\n\n# the channel.tx file is mounted in the channel-artifacts directory within your CLI container\n# as a result, we pass the full path for the file\n# we also pass the path for the orderer ca-cert in order to verify the TLS handshake\n# be sure to export or replace the $CHANNEL_NAME variable appropriately\n\npeer channel create -o orderer.example.com:7050 -c $CHANNEL_NAME -f ./channel-artifacts/channel.tx --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem  ::: {.note}\n::: {.admonition-title}\nNote\n:::  Notice the  -- cafile  that we pass as part of this command. It is  :   the local path to the orderer\\'s root cert, allowing us to verify\n    the TLS handshake.\n:::  This command returns a genesis block -  channel-ID.block  - which we\nwill use to join the channel. It contains the configuration information\nspecified in  channel.tx  If you have not made any modifications to the\ndefault channel name, then the command will return you a proto titled mychannel.block .  ::: {.note}\n::: {.admonition-title}\nNote\n:::  You will remain in the CLI container for the remainder of  :   these manual commands. You must also remember to preface all\n    commands with the corresponding environment variables when targeting\n    a peer other than  peer0.org1.example.com .\n:::  Now let\\'s join  peer0.org1.example.com  to the channel.  ``` {.sourceCode .bash}", 
            "title": "Environment variables for PEER0"
        }, 
        {
            "location": "/build_network/#by-default-this-joins-peer0org1examplecom-only", 
            "text": "", 
            "title": "By default, this joins peer0.org1.example.com only"
        }, 
        {
            "location": "/build_network/#the-was-returned-by-the-previous-command", 
            "text": "", 
            "title": "the  was returned by the previous command"
        }, 
        {
            "location": "/build_network/#if-you-have-not-modified-the-channel-name-you-will-join-with-mychannelblock", 
            "text": "", 
            "title": "if you have not modified the channel name, you will join with mychannel.block"
        }, 
        {
            "location": "/build_network/#if-you-have-created-a-different-channel-name-then-pass-in-the-appropriately-named-block", 
            "text": "peer channel join -b mychannel.block  \nYou can make other peers join the channel as necessary by making\nappropriate changes in the four environment variables we used in the\n[peerenvvars]{role= ref } section, above.\n\nRather than join every peer, we will simply join\n`peer0.org2.example.com` so that we can properly update the anchor peer\ndefinitions in our channel. Since we are overriding the default\nenvironment variables baked into the CLI container, this full command\nwill be the following:\n\n``` {.sourceCode .bash}\nCORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/msp CORE_PEER_ADDRESS=peer0.org2.example.com:7051 CORE_PEER_LOCALMSPID= Org2MSP  CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt peer channel join -b mychannel.block  Alternatively, you could choose to set these environment variables\nindividually rather than passing in the entire string. Once they\\'ve\nbeen set, you simply need to issue the  peer channel join  command again\nand the CLI container will act on behalf of  peer0.org2.example.com .", 
            "title": "if you have created a different channel name, then pass in the appropriately named block"
        }, 
        {
            "location": "/build_network/#update-the-anchor-peers", 
            "text": "The following commands are channel updates and they will propagate to\nthe definition of the channel. In essence, we adding additional\nconfiguration information on top of the channel\\'s genesis block. Note\nthat we are not modifying the genesis block, but simply adding deltas\ninto the chain that will define the anchor peers.  Update the channel definition to define the anchor peer for Org1 as peer0.org1.example.com :  ``` {.sourceCode .bash}\npeer channel update -o orderer.example.com:7050 -c $CHANNEL_NAME -f ./channel-artifacts/Org1MSPanchors.tx --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem  \nNow update the channel definition to define the anchor peer for Org2 as\n`peer0.org2.example.com`. Identically to the `peer channel join` command\nfor the Org2 peer, we will need to preface this call with the\nappropriate environment variables.\n\n``` {.sourceCode .bash}\nCORE_PEER_MSPCONFIGPATH=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/users/Admin@org2.example.com/msp CORE_PEER_ADDRESS=peer0.org2.example.com:7051 CORE_PEER_LOCALMSPID= Org2MSP  CORE_PEER_TLS_ROOTCERT_FILE=/opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/peerOrganizations/org2.example.com/peers/peer0.org2.example.com/tls/ca.crt peer channel update -o orderer.example.com:7050 -c $CHANNEL_NAME -f ./channel-artifacts/Org2MSPanchors.tx --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem", 
            "title": "Update the anchor peers"
        }, 
        {
            "location": "/build_network/#install-instantiate-chaincode", 
            "text": "::: {.note}\n::: {.admonition-title}\nNote\n:::  We will utilize a simple existing chaincode. To learn how to write  :   your own chaincode, see the [chaincode4ade]{role=\"doc\"} tutorial.\n:::  Applications interact with the blockchain ledger through  chaincode . As\nsuch we need to install the chaincode on every peer that will execute\nand endorse our transactions, and then instantiate the chaincode on the\nchannel.  First, install the sample Go or Node.js chaincode onto one of the four\npeer nodes. These commands place the specified source code flavor onto\nour peer\\'s filesystem.  ::: {.note}\n::: {.admonition-title}\nNote\n:::  You can only install one version of the source code per chaincode name  :   and version. The source code exists on the peer\\'s file system in\n    the context of chaincode name and version; it is language agnostic.\n    Similarly the instantiated chaincode container will be reflective of\n    whichever language has been installed on the peer.\n:::  Golang  ``` {.sourceCode .bash}", 
            "title": "Install &amp; Instantiate Chaincode"
        }, 
        {
            "location": "/build_network/#this-installs-the-go-chaincode", 
            "text": "peer chaincode install -n mycc -v 1.0 -p github.com/chaincode/chaincode_example02/go/  \n**Node.js**\n\n``` {.sourceCode .bash}\n# this installs the Node.js chaincode\n# make note of the -l flag; we use this to specify the language\npeer chaincode install -n mycc -v 1.0 -l node -p /opt/gopath/src/github.com/chaincode/chaincode_example02/node/  Next, instantiate the chaincode on the channel. This will initialize the\nchaincode on the channel, set the endorsement policy for the chaincode,\nand launch a chaincode container for the targeted peer. Take note of the -P  argument. This is our policy where we specify the required level of\nendorsement for a transaction against this chaincode to be validated.  In the command below you'll notice that we specify our policy as -P \"OR ('Org0MSP.member','Org1MSP.member')\" . This means that we need\n\"endorsement\" from a peer belonging to Org1  OR  Org2 (i.e. only one\nendorsement). If we changed the syntax to  AND  then we would need two\nendorsements.  Golang  ``` {.sourceCode .bash}", 
            "title": "this installs the Go chaincode"
        }, 
        {
            "location": "/build_network/#be-sure-to-replace-the-channel_name-environment-variable-if-you-have-not-exported-it", 
            "text": "", 
            "title": "be sure to replace the $CHANNEL_NAME environment variable if you have not exported it"
        }, 
        {
            "location": "/build_network/#if-you-did-not-install-your-chaincode-with-a-name-of-mycc-then-modify-that-argument-as-well", 
            "text": "peer chaincode instantiate -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n mycc -v 1.0 -c '{\"Args\":[\"init\",\"a\", \"100\", \"b\",\"200\"]}' -P \"OR ('Org1MSP.member','Org2MSP.member')\"  \n**Node.js**\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\nThe instantiation of the Node.js chaincode will take roughly a minute.\n\n:   The command is not hanging; rather it is installing the fabric-shim\n    layer as the image is being compiled.\n:::\n\n``` {.sourceCode .bash}\n# be sure to replace the $CHANNEL_NAME environment variable if you have not exported it\n# if you did not install your chaincode with a name of mycc, then modify that argument as well\n# notice that we must pass the -l flag after the chaincode name to identify the language\n\npeer chaincode instantiate -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n mycc -l node -v 1.0 -c '{ Args :[ init , a ,  100 ,  b , 200 ]}' -P  OR ('Org1MSP.member','Org2MSP.member')   See the  endorsement\npolicies \ndocumentation for more details on policy implementation.  If you want additional peers to interact with ledger, then you will need\nto join them to the channel, and install the same name, version and\nlanguage of the chaincode source onto the appropriate peer\\'s\nfilesystem. A chaincode container will be launched for each peer as soon\nas they try to interact with that specific chaincode. Again, be\ncognizant of the fact that the Node.js images will be slower to compile.  Once the chaincode has been instantiated on the channel, we can forgo\nthe  l  flag. We need only pass in the channel identifier and name of\nthe chaincode.", 
            "title": "if you did not install your chaincode with a name of mycc, then modify that argument as well"
        }, 
        {
            "location": "/build_network/#query", 
            "text": "Let\\'s query for the value of  a  to make sure the chaincode was\nproperly instantiated and the state DB was populated. The syntax for\nquery is as follows:  ``` {.sourceCode .bash}", 
            "title": "Query"
        }, 
        {
            "location": "/build_network/#be-sure-to-set-the-c-and-n-flags-appropriately", 
            "text": "peer chaincode query -C $CHANNEL_NAME -n mycc -c '{\"Args\":[\"query\",\"a\"]}'  \n### Invoke\n\nNow let\\'s move `10` from `a` to `b`. This transaction will cut a new\nblock and update the state DB. The syntax for invoke is as follows:\n\n``` {.sourceCode .bash}\n# be sure to set the -C and -n flags appropriately\n\npeer chaincode invoke -o orderer.example.com:7050  --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem  -C $CHANNEL_NAME -n mycc -c '{ Args :[ invoke , a , b , 10 ]}'", 
            "title": "be sure to set the -C and -n flags appropriately"
        }, 
        {
            "location": "/build_network/#query_1", 
            "text": "Let\\'s confirm that our previous invocation executed properly. We\ninitialized the key  a  with a value of  100  and just removed  10  with\nour previous invocation. Therefore, a query against  a  should reveal 90 . The syntax for query is as follows.  ``` {.sourceCode .bash}", 
            "title": "Query"
        }, 
        {
            "location": "/build_network/#be-sure-to-set-the-c-and-n-flags-appropriately_1", 
            "text": "peer chaincode query -C $CHANNEL_NAME -n mycc -c '{\"Args\":[\"query\",\"a\"]}'  \nWe should see the following:\n\n``` {.sourceCode .bash}\nQuery Result: 90  Feel free to start over and manipulate the key value pairs and\nsubsequent invocations.  ::: {#behind-scenes}", 
            "title": "be sure to set the -C and -n flags appropriately"
        }, 
        {
            "location": "/build_network/#whats-happening-behind-the-scenes", 
            "text": ":::  ::: {.note}\n::: {.admonition-title}\nNote\n:::  These steps describe the scenario in which  :    script.sh  is not commented out in the docker-compose-cli.yaml\n    file. Clean your network with  ./byfn.sh -m down  and ensure this\n    command is active. Then use the same docker-compose prompt to launch\n    your network again\n:::   A script -  script.sh  - is baked inside the CLI container. The\n    script drives the  createChannel  command against the supplied\n    channel name and uses the channel.tx file for channel configuration.  The output of  createChannel  is a genesis block\n    - your_channel_name .block  - which gets stored on the peers\\' file\n    systems and contains the channel configuration specified from\n    channel.tx.  The  joinChannel  command is exercised for all four peers, which\n    takes as input the previously generated genesis block. This command\n    instructs the peers to join  your_channel_name  and create a chain\n    starting with  your_channel_name .block .  Now we have a channel consisting of four peers, and two\n    organizations. This is our  TwoOrgsChannel  profile.  peer0.org1.example.com  and  peer1.org1.example.com  belong to\n    Org1;  peer0.org2.example.com  and  peer1.org2.example.com  belong\n    to Org2  These relationships are defined through the  crypto-config.yaml  and\n    the MSP path is specified in our docker compose.  The anchor peers for Org1MSP ( peer0.org1.example.com ) and Org2MSP\n    ( peer0.org2.example.com ) are then updated. We do this by passing\n    the  Org1MSPanchors.tx  and  Org2MSPanchors.tx  artifacts to the\n    ordering service along with the name of our channel.  A chaincode -  chaincode_example02  - is installed on\n     peer0.org1.example.com  and  peer0.org2.example.com  The chaincode is then \\\"instantiated\\\" on  peer0.org2.example.com .\n    Instantiation adds the chaincode to the channel, starts the\n    container for the target peer, and initializes the key value pairs\n    associated with the chaincode. The initial values for this example\n    are [\\\"a\\\",\\\"100\\\" \\\"b\\\",\\\"200\\\"]. This \\\"instantiation\\\" results\n    in a container by the name of  dev-peer0.org2.example.com-mycc-1.0 \n    starting.  The instantiation also passes in an argument for the endorsement\n    policy. The policy is defined as\n     -P \"OR    ('Org1MSP.member','Org2MSP.member')\" , meaning that any\n    transaction must be endorsed by a peer tied to Org1 or Org2.  A query against the value of \\\"a\\\" is issued to\n     peer0.org1.example.com . The chaincode was previously installed on\n     peer0.org1.example.com , so this will start a container for Org1\n    peer0 by the name of  dev-peer0.org1.example.com-mycc-1.0 . The\n    result of the query is also returned. No write operations have\n    occurred, so a query against \\\"a\\\" will still return a value of\n    \\\"100\\\".  An invoke is sent to  peer0.org1.example.com  to move \\\"10\\\" from\n    \\\"a\\\" to \\\"b\\\"  The chaincode is then installed on  peer1.org2.example.com  A query is sent to  peer1.org2.example.com  for the value of \\\"a\\\".\n    This starts a third chaincode container by the name of\n     dev-peer1.org2.example.com-mycc-1.0 . A value of 90 is returned,\n    correctly reflecting the previous transaction during which the value\n    for key \\\"a\\\" was modified by 10.", 
            "title": "What\\'s happening behind the scenes?"
        }, 
        {
            "location": "/build_network/#what-does-this-demonstrate", 
            "text": "Chaincode  MUST  be installed on a peer in order for it to\nsuccessfully perform read/write operations against the ledger.\nFurthermore, a chaincode container is not started for a peer until an init  or traditional transaction - read/write - is performed against\nthat chaincode (e.g. query for the value of \\\"a\\\"). The transaction\ncauses the container to start. Also, all peers in a channel maintain an\nexact copy of the ledger which comprises the blockchain to store the\nimmutable, sequenced record in blocks, as well as a state database to\nmaintain a snapshot of the current state. This includes those peers that\ndo not have chaincode installed on them (like  peer1.org1.example.com \nin the above example) . Finally, the chaincode is accessible after it is\ninstalled (like  peer1.org2.example.com  in the above example) because\nit has already been instantiated.", 
            "title": "What does this demonstrate?"
        }, 
        {
            "location": "/build_network/#how-do-i-see-these-transactions", 
            "text": "Check the logs for the CLI Docker container.  ``` {.sourceCode .bash}\ndocker logs -f cli  \nYou should see the following output:\n\n``` {.sourceCode .bash}\n2017-05-16 17:08:01.366 UTC [msp] GetLocalMSP -  DEBU 004 Returning existing local MSP\n2017-05-16 17:08:01.366 UTC [msp] GetDefaultSigningIdentity -  DEBU 005 Obtaining default signing identity\n2017-05-16 17:08:01.366 UTC [msp/identity] Sign -  DEBU 006 Sign: plaintext: 0AB1070A6708031A0C08F1E3ECC80510...6D7963631A0A0A0571756572790A0161\n2017-05-16 17:08:01.367 UTC [msp/identity] Sign -  DEBU 007 Sign: digest: E61DB37F4E8B0D32C9FE10E3936BA9B8CD278FAA1F3320B08712164248285C54\nQuery Result: 90\n2017-05-16 17:08:15.158 UTC [main] main -  INFO 008 Exiting.....\n===================== Query on PEER3 on channel 'mychannel' is successful =====================\n\n===================== All GOOD, BYFN execution completed =====================\n\n\n _____   _   _   ____\n| ____| | \\ | | |  _ \\\n|  _|   |  \\| | | | | |\n| |___  | |\\  | | |_| |\n|_____| |_| \\_| |____/  You can scroll through these logs to see the various transactions.", 
            "title": "How do I see these transactions?"
        }, 
        {
            "location": "/build_network/#how-can-i-see-the-chaincode-logs", 
            "text": "Inspect the individual chaincode containers to see the separate\ntransactions executed against each container. Here is the combined\noutput from each container:  ``` {.sourceCode .bash}\n$ docker logs dev-peer0.org2.example.com-mycc-1.0\n04:30:45.947 [BCCSP_FACTORY] DEBU : Initialize BCCSP [SW]\nex02 Init\nAval = 100, Bval = 200  $ docker logs dev-peer0.org1.example.com-mycc-1.0\n04:31:10.569 [BCCSP_FACTORY] DEBU : Initialize BCCSP [SW]\nex02 Invoke\nQuery Response:{\"Name\":\"a\",\"Amount\":\"100\"}\nex02 Invoke\nAval = 90, Bval = 210  $ docker logs dev-peer1.org2.example.com-mycc-1.0\n04:31:30.420 [BCCSP_FACTORY] DEBU : Initialize BCCSP [SW]\nex02 Invoke\nQuery Response:{\"Name\":\"a\",\"Amount\":\"90\"}  \nUnderstanding the Docker Compose topology\n-----------------------------------------\n\nThe BYFN sample offers us two flavors of Docker Compose files, both of\nwhich are extended from the `docker-compose-base.yaml` (located in the\n`base` folder). Our first flavor, `docker-compose-cli.yaml`, provides us\nwith a CLI container, along with an orderer, four peers. We use this\nfile for the entirety of the instructions on this page.\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\nthe remainder of this section covers a docker-compose file designed for the\n\n:   SDK. Refer to the [Node\n    SDK](https://github.com/hyperledger/fabric-sdk-node) repo for\n    details on running these tests.\n:::\n\nThe second flavor, `docker-compose-e2e.yaml`, is constructed to run\nend-to-end tests using the Node.js SDK. Aside from functioning with the\nSDK, its primary differentiation is that there are containers for the\nfabric-ca servers. As a result, we are able to send REST calls to the\norganizational CAs for user registration and enrollment.\n\nIf you want to use the `docker-compose-e2e.yaml` without first running\nthe byfn.sh script, then we will need to make four slight modifications.\nWe need to point to the private keys for our Organization\\'s CA\\'s. You\ncan locate these values in your crypto-config folder. For example, to\nlocate the private key for Org1 we would follow this path -\n`crypto-config/peerOrganizations/org1.example.com/ca/`. The private key\nis a long hash value followed by `_sk`. The path for Org2 would be -\n`crypto-config/peerOrganizations/org2.example.com/ca/`.\n\nIn the `docker-compose-e2e.yaml` update the\nFABRIC\\_CA\\_SERVER\\_TLS\\_KEYFILE variable for ca0 and ca1. You also need\nto edit the path that is provided in the command to start the ca server.\nYou are providing the same private key twice for each CA container.\n\nUsing CouchDB\n-------------\n\nThe state database can be switched from the default (goleveldb) to\nCouchDB. The same chaincode functions are available with CouchDB,\nhowever, there is the added ability to perform rich and complex queries\nagainst the state database data content contingent upon the chaincode\ndata being modeled as JSON.\n\nTo use CouchDB instead of the default database (goleveldb), follow the\nsame procedures outlined earlier for generating the artifacts, except\nwhen starting the network pass `docker-compose-couch.yaml` as well:\n\n``` {.sourceCode .bash}\nCHANNEL_NAME=$CHANNEL_NAME TIMEOUT= pick_a_value  docker-compose -f docker-compose-cli.yaml -f docker-compose-couch.yaml up -d  chaincode_example02  should now work using CouchDB underneath.  ::: {.note}\n::: {.admonition-title}\nNote\n:::  If you choose to implement mapping of the fabric-couchdb container  :   port to a host port, please make sure you are aware of the security\n    implications. Mapping of the port in a development environment makes\n    the CouchDB REST API available, and allows the visualization of the\n    database via the CouchDB web interface (Fauxton). Production\n    environments would likely refrain from implementing port mapping in\n    order to restrict outside access to the CouchDB containers.\n:::  You can use  chaincode_example02  chaincode against the CouchDB state\ndatabase using the steps outlined above, however in order to exercise\nthe CouchDB query capabilities you will need to use a chaincode that has\ndata modeled as JSON, (e.g.  marbles02 ). You can locate the marbles02  chaincode in the  fabric/examples/chaincode/go  directory.  We will follow the same process to create and join the channel as\noutlined in the [createandjoin]{role=\"ref\"} section above. Once you have\njoined your peer(s) to the channel, use the following steps to interact\nwith the  marbles02  chaincode:   Install and instantiate the chaincode on  peer0.org1.example.com :   ``` {.sourceCode .bash}", 
            "title": "How can I see the chaincode logs?"
        }, 
        {
            "location": "/build_network/#be-sure-to-modify-the-channel_name-variable-accordingly-for-the-instantiate-command", 
            "text": "peer chaincode install -n marbles -v 1.0 -p github.com/hyperledger/fabric/examples/chaincode/go/marbles02\npeer chaincode instantiate -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n marbles -v 1.0 -c '{\"Args\":[\"init\"]}' -P \"OR ('Org0MSP.member','Org1MSP.member')\"  \n-   Create some marbles and move them around:\n\n``` {.sourceCode .bash}\n# be sure to modify the $CHANNEL_NAME variable accordingly\n\npeer chaincode invoke -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n marbles -c '{ Args :[ initMarble , marble1 , blue , 35 , tom ]}'\npeer chaincode invoke -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n marbles -c '{ Args :[ initMarble , marble2 , red , 50 , tom ]}'\npeer chaincode invoke -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n marbles -c '{ Args :[ initMarble , marble3 , blue , 70 , tom ]}'\npeer chaincode invoke -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n marbles -c '{ Args :[ transferMarble , marble2 , jerry ]}'\npeer chaincode invoke -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n marbles -c '{ Args :[ transferMarblesBasedOnColor , blue , jerry ]}'\npeer chaincode invoke -o orderer.example.com:7050 --tls --cafile /opt/gopath/src/github.com/hyperledger/fabric/peer/crypto/ordererOrganizations/example.com/orderers/orderer.example.com/msp/tlscacerts/tlsca.example.com-cert.pem -C $CHANNEL_NAME -n marbles -c '{ Args :[ delete , marble1 ]}'    If you chose to map the CouchDB ports in docker-compose, you can now\n    view the state database through the CouchDB web interface (Fauxton)\n    by opening a browser and navigating to the following URL:  http://localhost:5984/_utils    You should see a database named  mychannel  (or your unique channel\nname) and the documents inside it.  ::: {.note}\n::: {.admonition-title}\nNote\n:::  For the below commands, be sure to update the \\$CHANNEL_NAME variable\nappropriately.\n:::  You can run regular queries from the CLI (e.g. reading  marble2 ):  ``` {.sourceCode .bash}\npeer chaincode query -C $CHANNEL_NAME -n marbles -c '{\"Args\":[\"readMarble\",\"marble2\"]}'  \nThe output should display the details of `marble2`:\n\n``` {.sourceCode .bash}\nQuery Result: { color : red , docType : marble , name : marble2 , owner : jerry , size :50}  You can retrieve the history of a specific marble - e.g.  marble1 :  ``` {.sourceCode .bash}\npeer chaincode query -C $CHANNEL_NAME -n marbles -c '{\"Args\":[\"getHistoryForMarble\",\"marble1\"]}'  \nThe output should display the transactions on `marble1`:\n\n``` {.sourceCode .bash}\nQuery Result: [{ TxId : 1c3d3caf124c89f91a4c0f353723ac736c58155325f02890adebaa15e16e6464 ,  Value :{ docType : marble , name : marble1 , color : blue , size :35, owner : tom }},{ TxId : 755d55c281889eaeebf405586f9e25d71d36eb3d35420af833a20a2f53a3eefd ,  Value :{ docType : marble , name : marble1 , color : blue , size :35, owner : jerry }},{ TxId : 819451032d813dde6247f85e56a89262555e04f14788ee33e28b232eef36d98f ,  Value :}]  You can also perform rich queries on the data content, such as querying\nmarble fields by owner  jerry :  ``` {.sourceCode .bash}\npeer chaincode query -C $CHANNEL_NAME -n marbles -c '{\"Args\":[\"queryMarblesByOwner\",\"jerry\"]}'  \nThe output should display the two marbles owned by `jerry`:\n\n``` {.sourceCode .bash}\nQuery Result: [{ Key : marble2 ,  Record :{ color : red , docType : marble , name : marble2 , owner : jerry , size :50}},{ Key : marble3 ,  Record :{ color : blue , docType : marble , name : marble3 , owner : jerry , size :70}}]", 
            "title": "be sure to modify the $CHANNEL_NAME variable accordingly for the instantiate command"
        }, 
        {
            "location": "/build_network/#why-couchdb", 
            "text": "CouchDB is a kind of NoSQL solution. It is a document oriented database\nwhere document fields are stored as key-value mpas. Fields can be either\na simple key/value pair, list, or map. In addition to\nkeyed/composite-key/key-range queries which are supported by LevelDB,\nCouchDB also supports full data rich queries capability, such as non-key\nqueries against the whole blockchain data, since its data content is\nstored in JSON format and fully queryable. Therefore, CouchDB can meet\nchaincode, auditing, reporting requirements for many use cases that not\nsupported by LevelDB.  CouchDB can also enhance the security for compliance and data protection\nin the blockchain. As it is able to implement field-level security\nthrough the filtering and masking of individual attributes within a\ntransaction, and only authorizing the read-only permission if needed.  In addition, CouchDB falls into the AP-type (Availability and Partition\nTolerance) of the CAP theorem. It uses a master-master replication model\nwith  Eventual Consistency . More information can be found on the Eventual Consistency page of the CouchDB\ndocumentation .\nHowever, under each fabric peer, there is no database replicas, writes\nto database are guaranteed consistent and durable (not Eventual Consistency ).  CouchDB is the first external pluggable state database for Fabric, and\nthere could and should be other external database options. For example,\nIBM enables the relational database for its blockchain. And the CP-type\n(Consistency and Partition Tolerance) databases may also in need, so as\nto enable data consistency without application level guarantee.", 
            "title": "Why CouchDB"
        }, 
        {
            "location": "/build_network/#a-note-on-data-persistence", 
            "text": "If data persistence is desired on the peer container or the CouchDB\ncontainer, one option is to mount a directory in the docker-host into a\nrelevant directory in the container. For example, you may add the\nfollowing two lines in the peer container specification in the docker-compose-base.yaml  file:  ``` {.sourceCode .bash}\nvolumes:\n - /var/hyperledger/peer0:/var/hyperledger/production  \nFor the CouchDB container, you may add the following two lines in the\nCouchDB container specification:\n\n``` {.sourceCode .bash}\nvolumes:\n - /var/hyperledger/couchdb0:/opt/couchdb/data  ::: {#Troubleshoot}\nTroubleshooting   :::    Always start your network fresh. Use the following command to remove\n    artifacts, crypto, containers and chaincode images:  {.sourceCode .bash}\n./byfn.sh -m down  ::: {.note}\n::: {.admonition-title}\nNote\n:::  You  will  see errors if you do not remove old containers  :   and images.\n:::    If you see Docker errors, first check your docker version\n    ([prereqs]{role=\"doc\"}), and then try restarting your Docker\n    process. Problems with Docker are oftentimes not immediately\n    recognizable. For example, you may see errors resulting from an\n    inability to access crypto material mounted within a container.  If they persist remove your images and start from scratch:  {.sourceCode .bash}\ndocker rm -f $(docker ps -aq)\ndocker rmi -f $(docker images -q)    If you see errors on your create, instantiate, invoke or query\n    commands, make sure you have properly updated the channel name and\n    chaincode name. There are placeholder values in the supplied sample\n    commands.    If you see the below error:  {.sourceCode .bash}\nError: Error endorsing chaincode: rpc error: code = 2 desc = Error installing chaincode code mycc:1.0(chaincode /var/hyperledger/production/chaincodes/mycc.1.0 exits)  You likely have chaincode images (e.g. dev-peer1.org2.example.com-mycc-1.0  or dev-peer0.org1.example.com-mycc-1.0 ) from prior runs. Remove them\nand try again.  {.sourceCode .bash}\ndocker rmi -f $(docker images | grep peer[0-9]-peer[0-9] | awk '{print $3}')    If you see something similar to the following:  {.sourceCode .bash}\nError connecting: rpc error: code = 14 desc = grpc: RPC failed fast due to transport failure\nError: rpc error: code = 14 desc = grpc: RPC failed fast due to transport failure  Make sure you are running your network against the \\\"1.0.0\\\" images\nthat have been retagged as \\\"latest\\\".    If you see the below error:  {.sourceCode .bash}\n[configtx/tool/localconfig] Load -  CRIT 002 Error reading configuration: Unsupported Config Type \"\"\npanic: Error reading configuration: Unsupported Config Type \"\"  Then you did not set the  FABRIC_CFG_PATH  environment variable\nproperly. The configtxgen tool needs this variable in order to\nlocate the configtx.yaml. Go back and execute an export FABRIC_CFG_PATH=$PWD , then recreate your channel artifacts.    To cleanup the network, use the  down  option:  {.sourceCode .bash}\n./byfn.sh -m down    If you see an error stating that you still have \\\"active\n    endpoints\\\", then prune your Docker networks. This will wipe your\n    previous networks and start you with a fresh environment:  {.sourceCode .bash}\ndocker network prune  You will see the following message:  {.sourceCode .bash}\nWARNING! This will remove all networks not used by at least one container.\nAre you sure you want to continue? [y/N]  Select  y .    ::: {.note}\n::: {.admonition-title}\nNote\n:::  If you continue to see errors, share your logs on the  :    fabric-questions  channel on  Hyperledger Rocket\n    Chat  or on\n     StackOverflow .\n:::", 
            "title": "A Note on Data Persistence"
        }, 
        {
            "location": "/write_first_app/", 
            "text": "Writing Your First Application\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nIf you\\'re not yet familiar with the fundamental architecture of a\n\n\n:   Fabric network, you may want to visit the [blockchain]{role=\"doc\"}\n    and [build_network]{role=\"doc\"} documentation prior to continuing.\n:::\n\n\nIn this section we\\'ll be looking at a handful of sample programs to see\nhow Fabric apps work. These apps (and the smart contract they use) --\ncollectively known as \nfabcar\n -- provide a broad demonstration of\nFabric functionality. Notably, we will show the process for interacting\nwith a Certificate Authority and generating enrollment certificates,\nafter which we will leverage these generated identities (user objects)\nto query and update a ledger.\n\n\nWe'll go through three principle steps:\n\n\n\n\n1. Setting up a development environment.\n Our application needs a\nnetwork to interact with, so we\\'ll download one stripped down to just\nthe components we need for registration/enrollment, queries and\nupdates:\n\n\n\n\n2. Learning the parameters of the sample smart contract our app will\nuse.\n Our smart contract contains various functions that allow us to\ninteract with the ledger in different ways. We'll go in and inspect\nthat smart contract to learn about the functions our applications will\nbe using.\n\n\n3. Developing the applications to be able to query and update assets\non the ledger.\n We\\'ll get into the app code itself (our apps have\nbeen written in Javascript) and manually manipulate the variables to\nrun different kinds of queries and updates.\n\n\n\n\nAfter completing this tutorial you should have a basic understanding of\nhow an application is programmed in conjunction with a smart contract to\ninteract with the ledger (i.e. the peer) on a Fabric network.\n\n\nSetting up your Dev Environment\n\n\nFirst thing, let\\'s download the Fabric images and the accompanying\nartifacts for the network and applications...\n\n\nVisit the [prereqs]{role=\"doc\"} page and ensure you have the necessary\ndependencies installed on your machine.\n\n\nNext, visit the [samples]{role=\"doc\"} page and follow the provided\ninstructions. Return to this tutorial once you have cloned the\n\nfabric-samples\n repository, and downloaded the latest stable Fabric\nimages and available utilities.\n\n\nAt this point everything should be installed. Navigate to the \nfabcar\n\nsubdirectory within your \nfabric-samples\n repository and take a look at\nwhat\\'s inside:\n\n\n``` {.sourceCode .bash}\ncd fabric-samples/fabcar  \n ls\n\n\n\nYou should see the following:\n\n``` {.sourceCode .bash}\nenrollAdmin.js invoke.js   package.json    query.js    registerUser.js startFabric.sh\n\n\n\n\nBefore starting we also need to do a little housekeeping. Run the\nfollowing command to kill any stale or active containers:\n\n\n``` {.sourceCode .bash}\ndocker rm -f $(docker ps -aq)\n\n\n\nClear any cached networks:\n\n``` {.sourceCode .bash}\n# Press 'y' when prompted by the command\n\ndocker network prune\n\n\n\n\nAnd lastly if you\\'ve already run through this tutorial, you\\'ll also\nwant to delete the underlying chaincode image for the \nfabcar\n smart\ncontract. If you\\'re a user going through this content for the first\ntime, then you won\\'t have this chaincode image on your system:\n\n\n``` {.sourceCode .bash}\ndocker rmi dev-peer0.org1.example.com-fabcar-1.0-5c906e402ed29f20260ae42283216aa75549c571e2e380f3615826365d8269ba\n\n\n\n### Install the clients \n launch the network\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\nThe following instructions require you to be in the `fabcar` subdirectory\n\n:   within your local clone of the `fabric-samples` repo. Remain at the\n    root of this subdirectory for the remainder of this tutorial.\n:::\n\nRun the following command to install the Fabric dependencies for the\napplications. We are concerned with `fabric-ca-client` which will allow\nour app(s) to communicate with the CA server and retrieve identity\nmaterial, and with `fabric-client` which allows us to load the identity\nmaterial and talk to the peers and ordering service.\n\n``` {.sourceCode .bash}\nnpm install\n\n\n\n\nLaunch your network using the \nstartFabric.sh\n shell script. This\ncommand will spin up our various Fabric entities and launch a smart\ncontract container for chaincode written in Golang:\n\n\n``` {.sourceCode .bash}\n./startFabric.sh\n\n\n\nYou also have the option of running this tutorial against chaincode\nwritten in Node.js. If you\\'d like to pursue this route, issue the\nfollowing command instead:\n\n``` {.sourceCode .bash}\n./startFabric.sh node\n\n\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nBe aware that the Node.js chaincode scenario will take roughly 90 seconds\n\n\n:   to complete; perhaps longer. The script is not hanging, rather the\n    increased time is a result of the fabric-shim being installed as the\n    chaincode image is being built.\n:::\n\n\nAlright, now that you've got a sample network and some code, let's take\na look at how the different pieces fit together.\n\n\nHow Applications Interact with the Network\n\n\nFor a more in-depth look at the components in our \nfabcar\n network (and\nhow they\\'re deployed) as well as how applications interact with those\ncomponents on more of a granular level, see\n[understand_fabcar_network]{role=\"doc\"}.\n\n\nDevelopers more interested in seeing what applications \ndo\n -- as\nwell as looking at the code itself to see how an application is\nconstructed -- should continue. For now, the most important thing to\nknow is that applications use a software development kit (SDK) to access\nthe \nAPIs\n that permit queries and updates to the ledger.\n\n\nEnrolling the Admin User\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nThe following two sections involve communication with the Certificate\n\n\n:   Authority. You may find it useful to stream the CA logs when running\n    the upcoming programs.\n:::\n\n\nTo stream your CA logs, split your terminal or open a new shell and\nissue the following:\n\n\n``` {.sourceCode .bash}\ndocker logs -f ca.example.com\n\n\n\nNow hop back to your terminal with the `fabcar` content\\...\n\nWhen we launched our network, an admin user - `admin` - was registered\nwith our Certificate Authority. Now we need to send an enroll call to\nthe CA server and retrieve the enrollment certificate (eCert) for this\nuser. We won\\'t delve into enrollment details here, but suffice it to\nsay that the SDK and by extension our applications need this cert in\norder to form a user object for the admin. We will then use this admin\nobject to subsequently register and enroll a new user. Send the admin\nenroll call to the CA server:\n\n``` {.sourceCode .bash}\nnode enrollAdmin.js\n\n\n\n\nThis program will invoke a certificate signing request (CSR) and\nultimately output an eCert and key material into a newly created folder\n- \nhfc-key-store\n - at the root of this project. Our apps will then look\nto this location when they need to create or load the identity objects\nfor our various users.\n\n\nRegister and Enroll \nuser1\n\n\nWith our newly generated admin eCert, we will now communicate with the\nCA server once more to register and enroll a new user. This user -\n\nuser1\n - will be the identity we use when querying and updating the\nledger. It\\'s important to note here that it is the \nadmin\n identity\nthat is issuing the registration and enrollment calls for our new user\n(i.e. this user is acting in the role of a registrar). Send the register\nand enroll calls for \nuser1\n:\n\n\n``` {.sourceCode .bash}\nnode registerUser.js\n\n\n\nSimilar to the admin enrollment, this program invokes a CSR and outputs\nthe keys and eCert into the `hfc-key-store` subdirectory. So now we have\nidentity material for two separate users - `admin` \n `user1`. Time to\ninteract with the ledger\\...\n\nQuerying the Ledger\n-------------------\n\nQueries are how you read data from the ledger. This data is stored as a\nseries of key/value pairs, and you can query for the value of a single\nkey, multiple keys, or \\-- if the ledger is written in a rich data\nstorage format like JSON \\--perform complex searches against it (looking\nfor all assets that contain certain keywords, for example).\n\nThis is a representation of how a query works:\n\n![image](images/QueryingtheLedger.png)\n\nFirst, let\\'s run our `query.js` program to return a listing of all the\ncars on the ledger. We will use our second identity - `user1` - as the\nsigning entity for this application. The following line in our program\nspecifies `user1` as the signer:\n\n``` {.sourceCode .bash}\nfabric_client.getUserContext('user1', true);\n\n\n\n\nRecall that the \nuser1\n enrollment material has already been placed into\nour \nhfc-key-store\n subdirectory, so we simply need to tell our\napplication to grab that identity. With the user object defined, we can\nnow proceed with reading from the ledger. A function that will query all\nthe cars, \nqueryAllCars\n, is pre-loaded in the app, so we can simply run\nthe program as is:\n\n\n``` {.sourceCode .bash}\nnode query.js\n\n\n\nIt should return something like this:\n\n``` {.sourceCode .json}\nSuccessfully loaded user1 from persistence\nQuery has completed, checking results\nResponse is  [{\nKey\n:\nCAR0\n, \nRecord\n:{\ncolour\n:\nblue\n,\nmake\n:\nToyota\n,\nmodel\n:\nPrius\n,\nowner\n:\nTomoko\n}},\n{\nKey\n:\nCAR1\n,   \nRecord\n:{\ncolour\n:\nred\n,\nmake\n:\nFord\n,\nmodel\n:\nMustang\n,\nowner\n:\nBrad\n}},\n{\nKey\n:\nCAR2\n, \nRecord\n:{\ncolour\n:\ngreen\n,\nmake\n:\nHyundai\n,\nmodel\n:\nTucson\n,\nowner\n:\nJin Soo\n}},\n{\nKey\n:\nCAR3\n, \nRecord\n:{\ncolour\n:\nyellow\n,\nmake\n:\nVolkswagen\n,\nmodel\n:\nPassat\n,\nowner\n:\nMax\n}},\n{\nKey\n:\nCAR4\n, \nRecord\n:{\ncolour\n:\nblack\n,\nmake\n:\nTesla\n,\nmodel\n:\nS\n,\nowner\n:\nAdriana\n}},\n{\nKey\n:\nCAR5\n, \nRecord\n:{\ncolour\n:\npurple\n,\nmake\n:\nPeugeot\n,\nmodel\n:\n205\n,\nowner\n:\nMichel\n}},\n{\nKey\n:\nCAR6\n, \nRecord\n:{\ncolour\n:\nwhite\n,\nmake\n:\nChery\n,\nmodel\n:\nS22L\n,\nowner\n:\nAarav\n}},\n{\nKey\n:\nCAR7\n, \nRecord\n:{\ncolour\n:\nviolet\n,\nmake\n:\nFiat\n,\nmodel\n:\nPunto\n,\nowner\n:\nPari\n}},\n{\nKey\n:\nCAR8\n, \nRecord\n:{\ncolour\n:\nindigo\n,\nmake\n:\nTata\n,\nmodel\n:\nNano\n,\nowner\n:\nValeria\n}},\n{\nKey\n:\nCAR9\n, \nRecord\n:{\ncolour\n:\nbrown\n,\nmake\n:\nHolden\n,\nmodel\n:\nBarina\n,\nowner\n:\nShotaro\n}}]\n\n\n\n\nThese are the 10 cars. A black Tesla Model S owned by Adriana, a red\nFord Mustang owned by Brad, a violet Fiat Punto owned by Pari, and so\non. The ledger is key/value based and in our implementation the key is\n\nCAR0\n through \nCAR9\n. This will become particularly important in a\nmoment.\n\n\nLet\\'s take a closer look at this program. Use an editor (e.g. atom or\nvisual studio) and open \nquery.js\n.\n\n\nThe initial section of the application defines certain variables such as\nchannel name, cert store location and network endpoints. In our sample\napp, these variables have been baked-in, but in a real app these\nvariables would have to be specified by the app dev.\n\n\n``` {.sourceCode .bash}\nvar channel = fabric_client.newChannel('mychannel');\nvar peer = fabric_client.newPeer('grpc://localhost:7051');\nchannel.addPeer(peer);\n\n\nvar member_user = null;\nvar store_path = path.join(__dirname, 'hfc-key-store');\nconsole.log('Store path:'+store_path);\nvar tx_id = null;\n\n\n\nThis is the chunk where we construct our query:\n\n``` {.sourceCode .bash}\n// queryCar chaincode function - requires 1 argument, ex: args: ['CAR4'],\n// queryAllCars chaincode function - requires no arguments , ex: args: [''],\nconst request = {\n  //targets : --- letting this default to the peers assigned to the channel\n  chaincodeId: 'fabcar',\n  fcn: 'queryAllCars',\n  args: ['']\n};\n\n\n\n\nWhen the application ran, it invoked the \nfabcar\n chaincode on the peer,\nran the \nqueryAllCars\n function within it, and passed no arguments to\nit.\n\n\nTo take a look at the available functions within our smart contract,\nnavigate to the \nchaincode/fabcar/go\n subdirectory at the root of\n\nfabric-samples\n and open \nfabcar.go\n in your editor.\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nThese same functions are defined within the Node.js version of the\n\n\n:   \nfabcar\n chaincode.\n:::\n\n\nYou\\'ll see that we have the following functions available to call:\n\ninitLedger\n, \nqueryCar\n, \nqueryAllCars\n, \ncreateCar\n, and\n\nchangeCarOwner\n.\n\n\nLet\\'s take a closer look at the \nqueryAllCars\n function to see how it\ninteracts with the ledger.\n\n\n``` {.sourceCode .bash}\nfunc (s *SmartContract) queryAllCars(APIstub shim.ChaincodeStubInterface) sc.Response {\n\n\nstartKey := \"CAR0\"\n  endKey := \"CAR999\"\n\n\nresultsIterator, err := APIstub.GetStateByRange(startKey, endKey)\n\n\n\nThis defines the range of `queryAllCars`. Every car between `CAR0` and\n`CAR999` \\-- 1,000 cars in all, assuming every key has been tagged\nproperly \\-- will be returned by the query.\n\nBelow is a representation of how an app would call different functions\nin chaincode. Each function must be coded against an available API in\nthe chaincode shim interface, which in turn allows the smart contract\ncontainer to properly interface with the peer ledger.\n\n![image](images/RunningtheSample.png)\n\nWe can see our `queryAllCars` function, as well as one called\n`createCar`, that will allow us to update the ledger and ultimately\nappend a new block to the chain in a moment.\n\nBut first, go back to the `query.js` program and edit the constructor\nrequest to query `CAR4`. We do this by changing the function in\n`query.js` from `queryAllCars` to `queryCar` and passing `CAR4` as the\nspecific key.\n\nThe `query.js` program should now look like this:\n\n``` {.sourceCode .bash}\nconst request = {\n  //targets : --- letting this default to the peers assigned to the channel\n  chaincodeId: 'fabcar',\n  fcn: 'queryCar',\n  args: ['CAR4']\n};\n\n\n\n\nSave the program and navigate back to your \nfabcar\n directory. Now run\nthe program again:\n\n\n``` {.sourceCode .bash}\nnode query.js\n\n\n\nYou should see the following:\n\n``` {.sourceCode .json}\n{\ncolour\n:\nblack\n,\nmake\n:\nTesla\n,\nmodel\n:\nS\n,\nowner\n:\nAdriana\n}\n\n\n\n\nIf you go back and look at the result from when we queried every car\nbefore, you can see that \nCAR4\n was Adriana's black Tesla model S, which\nis the result that was returned here.\n\n\nUsing the \nqueryCar\n function, we can query against any key (e.g.\n\nCAR0\n) and get whatever make, model, color, and owner correspond to\nthat car.\n\n\nGreat. At this point you should be comfortable with the basic query\nfunctions in the smart contract and the handful of parameters in the\nquery program. Time to update the ledger...\n\n\nUpdating the Ledger\n\n\nNow that we've done a few ledger queries and added a bit of code, we're\nready to update the ledger. There are a lot of potential updates we\ncould make, but let\\'s start by creating a car.\n\n\nBelow we can see how this process works. An update is proposed,\nendorsed, then returned to the application, which in turn sends it to be\nordered and written to every peer\\'s ledger:\n\n\n\n\nOur first update to the ledger will be to create a new car. We have a\nseparate Javascript program -- \ninvoke.js\n -- that we will use to make\nupdates. Just as with queries, use an editor to open the program and\nnavigate to the code block where we construct our invocation:\n\n\n``` {.sourceCode .bash}\n// createCar chaincode function - requires 5 args, ex: args: ['CAR12', 'Honda', 'Accord', 'Black', 'Tom'],\n// changeCarOwner chaincode function - requires 2 args , ex: args: ['CAR10', 'Barry'],\n// must send the proposal to endorsing peers\nvar request = {\n  //targets: let default to the peer assigned to the client\n  chaincodeId: 'fabcar',\n  fcn: '',\n  args: [''],\n  chainId: 'mychannel',\n  txId: tx_id\n};\n\n\n\nYou\\'ll see that we can call one of two functions - `createCar` or\n`changeCarOwner`. First, let's create a red Chevy Volt and give it to an\nowner named Nick. We\\'re up to `CAR9` on our ledger, so we\\'ll use\n`CAR10` as the identifying key here. Edit this code block to look like\nthis:\n\n``` {.sourceCode .bash}\nvar request = {\n  //targets: let default to the peer assigned to the client\n  chaincodeId: 'fabcar',\n  fcn: 'createCar',\n  args: ['CAR10', 'Chevy', 'Volt', 'Red', 'Nick'],\n  chainId: 'mychannel',\n  txId: tx_id\n};\n\n\n\n\nSave it and run the program:\n\n\n``` {.sourceCode .bash}\nnode invoke.js\n\n\n\nThere will be some output in the terminal about `ProposalResponse` and\npromises. However, all we\\'re concerned with is this message:\n\n``` {.sourceCode .bash}\nThe transaction has been committed on peer localhost:7053\n\n\n\n\nTo see that this transaction has been written, go back to \nquery.js\n and\nchange the argument from \nCAR4\n to \nCAR10\n.\n\n\nIn other words, change this:\n\n\n``` {.sourceCode .bash}\nconst request = {\n  //targets : --- letting this default to the peers assigned to the channel\n  chaincodeId: 'fabcar',\n  fcn: 'queryCar',\n  args: ['CAR4']\n};\n\n\n\nTo this:\n\n``` {.sourceCode .bash}\nconst request = {\n  //targets : --- letting this default to the peers assigned to the channel\n  chaincodeId: 'fabcar',\n  fcn: 'queryCar',\n  args: ['CAR10']\n};\n\n\n\n\nSave once again, then query:\n\n\n``` {.sourceCode .bash}\nnode query.js\n\n\n\nWhich should return this:\n\n``` {.sourceCode .bash}\nResponse is  {\ncolour\n:\nRed\n,\nmake\n:\nChevy\n,\nmodel\n:\nVolt\n,\nowner\n:\nNick\n}\n\n\n\n\nCongratulations. You've created a car!\n\n\nSo now that we've done that, let's say that Nick is feeling generous and\nhe wants to give his Chevy Volt to someone named Dave.\n\n\nTo do this go back to \ninvoke.js\n and change the function from\n\ncreateCar\n to \nchangeCarOwner\n and input the arguments like this:\n\n\n``` {.sourceCode .bash}\nvar request = {\n  //targets: let default to the peer assigned to the client\n  chaincodeId: 'fabcar',\n  fcn: 'changeCarOwner',\n  args: ['CAR10', 'Dave'],\n  chainId: 'mychannel',\n  txId: tx_id\n};\n\n\n\nThe first argument \\-- `CAR10` \\-- reflects the car that will be\nchanging owners. The second argument \\-- `Dave` \\-- defines the new\nowner of the car.\n\nSave and execute the program again:\n\n``` {.sourceCode .bash}\nnode invoke.js\n\n\n\n\nNow let's query the ledger again and ensure that Dave is now associated\nwith the \nCAR10\n key:\n\n\n``` {.sourceCode .bash}\nnode query.js\n\n\n\nIt should return this result:\n\n``` {.sourceCode .bash}\nResponse is  {\ncolour\n:\nRed\n,\nmake\n:\nChevy\n,\nmodel\n:\nVolt\n,\nowner\n:\nDave\n}\n\n\n\n\nThe ownership of \nCAR10\n has been changed from Nick to Dave.\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nIn a real world application the chaincode would likely have some access\n\n\n:   control logic. For example, only certain authorized users may create\n    new cars, and only the car owner may transfer the car to somebody\n    else.\n:::\n\n\nSummary\n\n\nNow that we've done a few queries and a few updates, you should have a\npretty good sense of how applications interact with the network. You've\nseen the basics of the roles smart contracts, APIs, and the SDK play in\nqueries and updates and you should have a feel for how different kinds\nof applications could be used to perform other business tasks and\noperations.\n\n\nIn subsequent documents we'll learn how to actually \nwrite\n a smart\ncontract and how some of these more low level application functions can\nbe leveraged (especially relating to identity and membership services).\n\n\nAdditional Resources\n\n\nThe \nHyperledger Fabric Node SDK\nrepo\n is an excellent\nresource for deeper documentation and sample code. You can also consult\nthe Fabric community and component experts on \nHyperledger Rocket\nChat\n.\n\n\nThis work is licensed under a \nCreative Commons Attribution 4.0 International License", 
            "title": "Writing Your First Application"
        }, 
        {
            "location": "/write_first_app/#writing-your-first-application", 
            "text": "::: {.note}\n::: {.admonition-title}\nNote\n:::  If you\\'re not yet familiar with the fundamental architecture of a  :   Fabric network, you may want to visit the [blockchain]{role=\"doc\"}\n    and [build_network]{role=\"doc\"} documentation prior to continuing.\n:::  In this section we\\'ll be looking at a handful of sample programs to see\nhow Fabric apps work. These apps (and the smart contract they use) --\ncollectively known as  fabcar  -- provide a broad demonstration of\nFabric functionality. Notably, we will show the process for interacting\nwith a Certificate Authority and generating enrollment certificates,\nafter which we will leverage these generated identities (user objects)\nto query and update a ledger.  We'll go through three principle steps:   1. Setting up a development environment.  Our application needs a\nnetwork to interact with, so we\\'ll download one stripped down to just\nthe components we need for registration/enrollment, queries and\nupdates:   2. Learning the parameters of the sample smart contract our app will\nuse.  Our smart contract contains various functions that allow us to\ninteract with the ledger in different ways. We'll go in and inspect\nthat smart contract to learn about the functions our applications will\nbe using.  3. Developing the applications to be able to query and update assets\non the ledger.  We\\'ll get into the app code itself (our apps have\nbeen written in Javascript) and manually manipulate the variables to\nrun different kinds of queries and updates.   After completing this tutorial you should have a basic understanding of\nhow an application is programmed in conjunction with a smart contract to\ninteract with the ledger (i.e. the peer) on a Fabric network.", 
            "title": "Writing Your First Application"
        }, 
        {
            "location": "/write_first_app/#setting-up-your-dev-environment", 
            "text": "First thing, let\\'s download the Fabric images and the accompanying\nartifacts for the network and applications...  Visit the [prereqs]{role=\"doc\"} page and ensure you have the necessary\ndependencies installed on your machine.  Next, visit the [samples]{role=\"doc\"} page and follow the provided\ninstructions. Return to this tutorial once you have cloned the fabric-samples  repository, and downloaded the latest stable Fabric\nimages and available utilities.  At this point everything should be installed. Navigate to the  fabcar \nsubdirectory within your  fabric-samples  repository and take a look at\nwhat\\'s inside:  ``` {.sourceCode .bash}\ncd fabric-samples/fabcar    ls  \nYou should see the following:\n\n``` {.sourceCode .bash}\nenrollAdmin.js invoke.js   package.json    query.js    registerUser.js startFabric.sh  Before starting we also need to do a little housekeeping. Run the\nfollowing command to kill any stale or active containers:  ``` {.sourceCode .bash}\ndocker rm -f $(docker ps -aq)  \nClear any cached networks:\n\n``` {.sourceCode .bash}\n# Press 'y' when prompted by the command\n\ndocker network prune  And lastly if you\\'ve already run through this tutorial, you\\'ll also\nwant to delete the underlying chaincode image for the  fabcar  smart\ncontract. If you\\'re a user going through this content for the first\ntime, then you won\\'t have this chaincode image on your system:  ``` {.sourceCode .bash}\ndocker rmi dev-peer0.org1.example.com-fabcar-1.0-5c906e402ed29f20260ae42283216aa75549c571e2e380f3615826365d8269ba  \n### Install the clients   launch the network\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\nThe following instructions require you to be in the `fabcar` subdirectory\n\n:   within your local clone of the `fabric-samples` repo. Remain at the\n    root of this subdirectory for the remainder of this tutorial.\n:::\n\nRun the following command to install the Fabric dependencies for the\napplications. We are concerned with `fabric-ca-client` which will allow\nour app(s) to communicate with the CA server and retrieve identity\nmaterial, and with `fabric-client` which allows us to load the identity\nmaterial and talk to the peers and ordering service.\n\n``` {.sourceCode .bash}\nnpm install  Launch your network using the  startFabric.sh  shell script. This\ncommand will spin up our various Fabric entities and launch a smart\ncontract container for chaincode written in Golang:  ``` {.sourceCode .bash}\n./startFabric.sh  \nYou also have the option of running this tutorial against chaincode\nwritten in Node.js. If you\\'d like to pursue this route, issue the\nfollowing command instead:\n\n``` {.sourceCode .bash}\n./startFabric.sh node  ::: {.note}\n::: {.admonition-title}\nNote\n:::  Be aware that the Node.js chaincode scenario will take roughly 90 seconds  :   to complete; perhaps longer. The script is not hanging, rather the\n    increased time is a result of the fabric-shim being installed as the\n    chaincode image is being built.\n:::  Alright, now that you've got a sample network and some code, let's take\na look at how the different pieces fit together.", 
            "title": "Setting up your Dev Environment"
        }, 
        {
            "location": "/write_first_app/#how-applications-interact-with-the-network", 
            "text": "For a more in-depth look at the components in our  fabcar  network (and\nhow they\\'re deployed) as well as how applications interact with those\ncomponents on more of a granular level, see\n[understand_fabcar_network]{role=\"doc\"}.  Developers more interested in seeing what applications  do  -- as\nwell as looking at the code itself to see how an application is\nconstructed -- should continue. For now, the most important thing to\nknow is that applications use a software development kit (SDK) to access\nthe  APIs  that permit queries and updates to the ledger.", 
            "title": "How Applications Interact with the Network"
        }, 
        {
            "location": "/write_first_app/#enrolling-the-admin-user", 
            "text": "::: {.note}\n::: {.admonition-title}\nNote\n:::  The following two sections involve communication with the Certificate  :   Authority. You may find it useful to stream the CA logs when running\n    the upcoming programs.\n:::  To stream your CA logs, split your terminal or open a new shell and\nissue the following:  ``` {.sourceCode .bash}\ndocker logs -f ca.example.com  \nNow hop back to your terminal with the `fabcar` content\\...\n\nWhen we launched our network, an admin user - `admin` - was registered\nwith our Certificate Authority. Now we need to send an enroll call to\nthe CA server and retrieve the enrollment certificate (eCert) for this\nuser. We won\\'t delve into enrollment details here, but suffice it to\nsay that the SDK and by extension our applications need this cert in\norder to form a user object for the admin. We will then use this admin\nobject to subsequently register and enroll a new user. Send the admin\nenroll call to the CA server:\n\n``` {.sourceCode .bash}\nnode enrollAdmin.js  This program will invoke a certificate signing request (CSR) and\nultimately output an eCert and key material into a newly created folder\n-  hfc-key-store  - at the root of this project. Our apps will then look\nto this location when they need to create or load the identity objects\nfor our various users.", 
            "title": "Enrolling the Admin User"
        }, 
        {
            "location": "/write_first_app/#register-and-enroll-user1", 
            "text": "With our newly generated admin eCert, we will now communicate with the\nCA server once more to register and enroll a new user. This user - user1  - will be the identity we use when querying and updating the\nledger. It\\'s important to note here that it is the  admin  identity\nthat is issuing the registration and enrollment calls for our new user\n(i.e. this user is acting in the role of a registrar). Send the register\nand enroll calls for  user1 :  ``` {.sourceCode .bash}\nnode registerUser.js  \nSimilar to the admin enrollment, this program invokes a CSR and outputs\nthe keys and eCert into the `hfc-key-store` subdirectory. So now we have\nidentity material for two separate users - `admin`   `user1`. Time to\ninteract with the ledger\\...\n\nQuerying the Ledger\n-------------------\n\nQueries are how you read data from the ledger. This data is stored as a\nseries of key/value pairs, and you can query for the value of a single\nkey, multiple keys, or \\-- if the ledger is written in a rich data\nstorage format like JSON \\--perform complex searches against it (looking\nfor all assets that contain certain keywords, for example).\n\nThis is a representation of how a query works:\n\n![image](images/QueryingtheLedger.png)\n\nFirst, let\\'s run our `query.js` program to return a listing of all the\ncars on the ledger. We will use our second identity - `user1` - as the\nsigning entity for this application. The following line in our program\nspecifies `user1` as the signer:\n\n``` {.sourceCode .bash}\nfabric_client.getUserContext('user1', true);  Recall that the  user1  enrollment material has already been placed into\nour  hfc-key-store  subdirectory, so we simply need to tell our\napplication to grab that identity. With the user object defined, we can\nnow proceed with reading from the ledger. A function that will query all\nthe cars,  queryAllCars , is pre-loaded in the app, so we can simply run\nthe program as is:  ``` {.sourceCode .bash}\nnode query.js  \nIt should return something like this:\n\n``` {.sourceCode .json}\nSuccessfully loaded user1 from persistence\nQuery has completed, checking results\nResponse is  [{ Key : CAR0 ,  Record :{ colour : blue , make : Toyota , model : Prius , owner : Tomoko }},\n{ Key : CAR1 ,    Record :{ colour : red , make : Ford , model : Mustang , owner : Brad }},\n{ Key : CAR2 ,  Record :{ colour : green , make : Hyundai , model : Tucson , owner : Jin Soo }},\n{ Key : CAR3 ,  Record :{ colour : yellow , make : Volkswagen , model : Passat , owner : Max }},\n{ Key : CAR4 ,  Record :{ colour : black , make : Tesla , model : S , owner : Adriana }},\n{ Key : CAR5 ,  Record :{ colour : purple , make : Peugeot , model : 205 , owner : Michel }},\n{ Key : CAR6 ,  Record :{ colour : white , make : Chery , model : S22L , owner : Aarav }},\n{ Key : CAR7 ,  Record :{ colour : violet , make : Fiat , model : Punto , owner : Pari }},\n{ Key : CAR8 ,  Record :{ colour : indigo , make : Tata , model : Nano , owner : Valeria }},\n{ Key : CAR9 ,  Record :{ colour : brown , make : Holden , model : Barina , owner : Shotaro }}]  These are the 10 cars. A black Tesla Model S owned by Adriana, a red\nFord Mustang owned by Brad, a violet Fiat Punto owned by Pari, and so\non. The ledger is key/value based and in our implementation the key is CAR0  through  CAR9 . This will become particularly important in a\nmoment.  Let\\'s take a closer look at this program. Use an editor (e.g. atom or\nvisual studio) and open  query.js .  The initial section of the application defines certain variables such as\nchannel name, cert store location and network endpoints. In our sample\napp, these variables have been baked-in, but in a real app these\nvariables would have to be specified by the app dev.  ``` {.sourceCode .bash}\nvar channel = fabric_client.newChannel('mychannel');\nvar peer = fabric_client.newPeer('grpc://localhost:7051');\nchannel.addPeer(peer);  var member_user = null;\nvar store_path = path.join(__dirname, 'hfc-key-store');\nconsole.log('Store path:'+store_path);\nvar tx_id = null;  \nThis is the chunk where we construct our query:\n\n``` {.sourceCode .bash}\n// queryCar chaincode function - requires 1 argument, ex: args: ['CAR4'],\n// queryAllCars chaincode function - requires no arguments , ex: args: [''],\nconst request = {\n  //targets : --- letting this default to the peers assigned to the channel\n  chaincodeId: 'fabcar',\n  fcn: 'queryAllCars',\n  args: ['']\n};  When the application ran, it invoked the  fabcar  chaincode on the peer,\nran the  queryAllCars  function within it, and passed no arguments to\nit.  To take a look at the available functions within our smart contract,\nnavigate to the  chaincode/fabcar/go  subdirectory at the root of fabric-samples  and open  fabcar.go  in your editor.  ::: {.note}\n::: {.admonition-title}\nNote\n:::  These same functions are defined within the Node.js version of the  :    fabcar  chaincode.\n:::  You\\'ll see that we have the following functions available to call: initLedger ,  queryCar ,  queryAllCars ,  createCar , and changeCarOwner .  Let\\'s take a closer look at the  queryAllCars  function to see how it\ninteracts with the ledger.  ``` {.sourceCode .bash}\nfunc (s *SmartContract) queryAllCars(APIstub shim.ChaincodeStubInterface) sc.Response {  startKey := \"CAR0\"\n  endKey := \"CAR999\"  resultsIterator, err := APIstub.GetStateByRange(startKey, endKey)  \nThis defines the range of `queryAllCars`. Every car between `CAR0` and\n`CAR999` \\-- 1,000 cars in all, assuming every key has been tagged\nproperly \\-- will be returned by the query.\n\nBelow is a representation of how an app would call different functions\nin chaincode. Each function must be coded against an available API in\nthe chaincode shim interface, which in turn allows the smart contract\ncontainer to properly interface with the peer ledger.\n\n![image](images/RunningtheSample.png)\n\nWe can see our `queryAllCars` function, as well as one called\n`createCar`, that will allow us to update the ledger and ultimately\nappend a new block to the chain in a moment.\n\nBut first, go back to the `query.js` program and edit the constructor\nrequest to query `CAR4`. We do this by changing the function in\n`query.js` from `queryAllCars` to `queryCar` and passing `CAR4` as the\nspecific key.\n\nThe `query.js` program should now look like this:\n\n``` {.sourceCode .bash}\nconst request = {\n  //targets : --- letting this default to the peers assigned to the channel\n  chaincodeId: 'fabcar',\n  fcn: 'queryCar',\n  args: ['CAR4']\n};  Save the program and navigate back to your  fabcar  directory. Now run\nthe program again:  ``` {.sourceCode .bash}\nnode query.js  \nYou should see the following:\n\n``` {.sourceCode .json}\n{ colour : black , make : Tesla , model : S , owner : Adriana }  If you go back and look at the result from when we queried every car\nbefore, you can see that  CAR4  was Adriana's black Tesla model S, which\nis the result that was returned here.  Using the  queryCar  function, we can query against any key (e.g. CAR0 ) and get whatever make, model, color, and owner correspond to\nthat car.  Great. At this point you should be comfortable with the basic query\nfunctions in the smart contract and the handful of parameters in the\nquery program. Time to update the ledger...", 
            "title": "Register and Enroll user1"
        }, 
        {
            "location": "/write_first_app/#updating-the-ledger", 
            "text": "Now that we've done a few ledger queries and added a bit of code, we're\nready to update the ledger. There are a lot of potential updates we\ncould make, but let\\'s start by creating a car.  Below we can see how this process works. An update is proposed,\nendorsed, then returned to the application, which in turn sends it to be\nordered and written to every peer\\'s ledger:   Our first update to the ledger will be to create a new car. We have a\nseparate Javascript program --  invoke.js  -- that we will use to make\nupdates. Just as with queries, use an editor to open the program and\nnavigate to the code block where we construct our invocation:  ``` {.sourceCode .bash}\n// createCar chaincode function - requires 5 args, ex: args: ['CAR12', 'Honda', 'Accord', 'Black', 'Tom'],\n// changeCarOwner chaincode function - requires 2 args , ex: args: ['CAR10', 'Barry'],\n// must send the proposal to endorsing peers\nvar request = {\n  //targets: let default to the peer assigned to the client\n  chaincodeId: 'fabcar',\n  fcn: '',\n  args: [''],\n  chainId: 'mychannel',\n  txId: tx_id\n};  \nYou\\'ll see that we can call one of two functions - `createCar` or\n`changeCarOwner`. First, let's create a red Chevy Volt and give it to an\nowner named Nick. We\\'re up to `CAR9` on our ledger, so we\\'ll use\n`CAR10` as the identifying key here. Edit this code block to look like\nthis:\n\n``` {.sourceCode .bash}\nvar request = {\n  //targets: let default to the peer assigned to the client\n  chaincodeId: 'fabcar',\n  fcn: 'createCar',\n  args: ['CAR10', 'Chevy', 'Volt', 'Red', 'Nick'],\n  chainId: 'mychannel',\n  txId: tx_id\n};  Save it and run the program:  ``` {.sourceCode .bash}\nnode invoke.js  \nThere will be some output in the terminal about `ProposalResponse` and\npromises. However, all we\\'re concerned with is this message:\n\n``` {.sourceCode .bash}\nThe transaction has been committed on peer localhost:7053  To see that this transaction has been written, go back to  query.js  and\nchange the argument from  CAR4  to  CAR10 .  In other words, change this:  ``` {.sourceCode .bash}\nconst request = {\n  //targets : --- letting this default to the peers assigned to the channel\n  chaincodeId: 'fabcar',\n  fcn: 'queryCar',\n  args: ['CAR4']\n};  \nTo this:\n\n``` {.sourceCode .bash}\nconst request = {\n  //targets : --- letting this default to the peers assigned to the channel\n  chaincodeId: 'fabcar',\n  fcn: 'queryCar',\n  args: ['CAR10']\n};  Save once again, then query:  ``` {.sourceCode .bash}\nnode query.js  \nWhich should return this:\n\n``` {.sourceCode .bash}\nResponse is  { colour : Red , make : Chevy , model : Volt , owner : Nick }  Congratulations. You've created a car!  So now that we've done that, let's say that Nick is feeling generous and\nhe wants to give his Chevy Volt to someone named Dave.  To do this go back to  invoke.js  and change the function from createCar  to  changeCarOwner  and input the arguments like this:  ``` {.sourceCode .bash}\nvar request = {\n  //targets: let default to the peer assigned to the client\n  chaincodeId: 'fabcar',\n  fcn: 'changeCarOwner',\n  args: ['CAR10', 'Dave'],\n  chainId: 'mychannel',\n  txId: tx_id\n};  \nThe first argument \\-- `CAR10` \\-- reflects the car that will be\nchanging owners. The second argument \\-- `Dave` \\-- defines the new\nowner of the car.\n\nSave and execute the program again:\n\n``` {.sourceCode .bash}\nnode invoke.js  Now let's query the ledger again and ensure that Dave is now associated\nwith the  CAR10  key:  ``` {.sourceCode .bash}\nnode query.js  \nIt should return this result:\n\n``` {.sourceCode .bash}\nResponse is  { colour : Red , make : Chevy , model : Volt , owner : Dave }  The ownership of  CAR10  has been changed from Nick to Dave.  ::: {.note}\n::: {.admonition-title}\nNote\n:::  In a real world application the chaincode would likely have some access  :   control logic. For example, only certain authorized users may create\n    new cars, and only the car owner may transfer the car to somebody\n    else.\n:::", 
            "title": "Updating the Ledger"
        }, 
        {
            "location": "/write_first_app/#summary", 
            "text": "Now that we've done a few queries and a few updates, you should have a\npretty good sense of how applications interact with the network. You've\nseen the basics of the roles smart contracts, APIs, and the SDK play in\nqueries and updates and you should have a feel for how different kinds\nof applications could be used to perform other business tasks and\noperations.  In subsequent documents we'll learn how to actually  write  a smart\ncontract and how some of these more low level application functions can\nbe leveraged (especially relating to identity and membership services).", 
            "title": "Summary"
        }, 
        {
            "location": "/write_first_app/#additional-resources", 
            "text": "The  Hyperledger Fabric Node SDK\nrepo  is an excellent\nresource for deeper documentation and sample code. You can also consult\nthe Fabric community and component experts on  Hyperledger Rocket\nChat .  This work is licensed under a  Creative Commons Attribution 4.0 International License", 
            "title": "Additional Resources"
        }, 
        {
            "location": "/chaincode4ade/", 
            "text": "Chaincode for Developers\n\n\nWhat is Chaincode?\n\n\nChaincode is a program, written in \nGo\n,\n\nnode.js\n, that implements a prescribed interface.\nEventually, other programming languages such as Java, will be supported.\nChaincode runs in a secured Docker container isolated from the endorsing\npeer process. Chaincode initializes and manages the ledger state through\ntransactions submitted by applications.\n\n\nA chaincode typically handles business logic agreed to by members of the\nnetwork, so it similar to a \\\"smart contract\\\". Ledger state created by\na chaincode is scoped exclusively to that chaincode and can\\'t be\naccessed directly by another chaincode. Given the appropriate\npermission, a chaincode may invoke another chaincode to access its state\nwithin the same network.\n\n\nIn the following sections, we will explore chaincode through the eyes of\nan application developer. We\\'ll present a simple chaincode sample\napplication and walk through the purpose of each method in the Chaincode\nShim API.\n\n\nChaincode API\n\n\nEvery chaincode program must implement the \nChaincode interface\n:\n\n\n\n\n\n\nGo\n\n\nnode.js\n\n\n\n\n\n\nwhose methods are called in response to received transactions. In\nparticular the \nInit\n method is called when a chaincode receives an\n\ninstantiate\n or \nupgrade\n transaction so that the chaincode may perform\nany necessary initialization, including initialization of application\nstate. The \nInvoke\n method is called in response to receiving an\n\ninvoke\n transaction to process transaction proposals.\n\n\nThe other interface in the chaincode \\\"shim\\\" APIs is the\n\nChaincodeStubInterface\n:\n\n\n\n\n\n\nGo\n\n\nnode.js\n\n\n\n\n\n\nwhich is used to access and modify the ledger, and to make invocations\nbetween chaincodes.\n\n\nIn this tutorial, we will demonstrate the use of these APIs by\nimplementing a simple chaincode application that manages simple\n\\\"assets\\\".\n\n\n::: {#Simple Asset Chaincode}\nSimple Asset Chaincode\n\n\n\n\n:::\n\n\nOur application is a basic sample chaincode to create assets (key-value\npairs) on the ledger.\n\n\nChoosing a Location for the Code\n\n\nIf you haven\\'t been doing programming in Go, you may want to make sure\nthat you have [Golang]{role=\"ref\"} installed and your system properly\nconfigured.\n\n\nNow, you will want to create a directory for your chaincode application\nas a child directory of \n$GOPATH/src/\n.\n\n\nTo keep things simple, let\\'s use the following command:\n\n\n``` {.sourceCode .bash}\nmkdir -p $GOPATH/src/sacc \n cd $GOPATH/src/sacc\n\n\n\nNow, let\\'s create the source file that we\\'ll fill in with code:\n\n``` {.sourceCode .bash}\ntouch sacc.go\n\n\n\n\nHousekeeping\n\n\nFirst, let\\'s start with some housekeeping. As with every chaincode, it\nimplements the \nChaincode\ninterface\n\nin particular, \nInit\n and \nInvoke\n functions. So, let\\'s add the go\nimport statements for the necessary dependencies for our chaincode.\nWe\\'ll import the chaincode shim package and the \npeer protobuf\npackage\n.\nNext, let\\'s add a struct \nSimpleAsset\n as a receiver for Chaincode shim\nfunctions.\n\n\n``` {.sourceCode .go}\npackage main\n\n\nimport (\n    \"fmt\"\n\n\n\"github.com/hyperledger/fabric/core/chaincode/shim\"\n\"github.com/hyperledger/fabric/protos/peer\"\n\n\n\n)\n\n\n// SimpleAsset implements a simple chaincode to manage an asset\ntype SimpleAsset struct {\n}\n\n\n\n### Initializing the Chaincode\n\nNext, we\\'ll implement the `Init` function.\n\n``` {.sourceCode .go}\n// Init is called during chaincode instantiation to initialize any data.\nfunc (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response {\n\n}\n\n\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nNote that chaincode upgrade also calls this function. When writing a\n\n\n:   chaincode that will upgrade an existing one, make sure to modify the\n    \nInit\n function appropriately. In particular, provide an empty\n    \\\"Init\\\" method if there\\'s no \\\"migration\\\" or nothing to be\n    initialized as part of the upgrade.\n:::\n\n\nNext, we\\'ll retrieve the arguments to the \nInit\n call using the\n\nChaincodeStubInterface.GetStringArgs\n\nfunction and check for validity. In our case, we are expecting a\nkey-value pair.\n\n\n\n\n{.sourceCode .go}\n// Init is called during chaincode instantiation to initialize any\n// data. Note that chaincode upgrade also calls this function to reset\n// or to migrate data, so be careful to avoid a scenario where you\n// inadvertently clobber your ledger's data!\nfunc (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response {\n  // Get the args from the transaction proposal\n  args := stub.GetStringArgs()\n  if len(args) != 2 {\n    return shim.Error(\"Incorrect arguments. Expecting a key and a value\")\n  }\n}\n\n\n\n\nNext, now that we have established that the call is valid, we\\'ll store\nthe initial state in the ledger. To do this, we will call\n\nChaincodeStubInterface.PutState\n\nwith the key and value passed in as the arguments. Assuming all went\nwell, return a peer.Response object that indicates the initialization\nwas a success.\n\n\n``` {.sourceCode .go}\n// Init is called during chaincode instantiation to initialize any\n// data. Note that chaincode upgrade also calls this function to reset\n// or to migrate data, so be careful to avoid a scenario where you\n// inadvertently clobber your ledger's data!\nfunc (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response {\n  // Get the args from the transaction proposal\n  args := stub.GetStringArgs()\n  if len(args) != 2 {\n    return shim.Error(\"Incorrect arguments. Expecting a key and a value\")\n  }\n\n\n// Set up any variables or assets here by calling stub.PutState()\n\n\n// We store the key and the value on the ledger\n  err := stub.PutState(args[0], []byte(args[1]))\n  if err != nil {\n    return shim.Error(fmt.Sprintf(\"Failed to create asset: %s\", args[0]))\n  }\n  return shim.Success(nil)\n}\n\n\n\n### Invoking the Chaincode\n\nFirst, let\\'s add the `Invoke` function\\'s signature.\n\n``` {.sourceCode .go}\n// Invoke is called per transaction on the chaincode. Each transaction is\n// either a 'get' or a 'set' on the asset created by Init function. The 'set'\n// method may create a new asset by specifying a new key-value pair.\nfunc (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response {\n\n}\n\n\n\n\nAs with the \nInit\n function above, we need to extract the arguments from\nthe \nChaincodeStubInterface\n. The \nInvoke\n function\\'s arguments will be\nthe name of the chaincode application function to invoke. In our case,\nour application will simply have two functions: \nset\n and \nget\n, that\nallow the value of an asset to be set or its current state to be\nretrieved. We first call\n\nChaincodeStubInterface.GetFunctionAndParameters\n\nto extract the function name and the parameters to that chaincode\napplication function.\n\n\n``` {.sourceCode .go}\n// Invoke is called per transaction on the chaincode. Each transaction is\n// either a 'get' or a 'set' on the asset created by Init function. The Set\n// method may create a new asset by specifying a new key-value pair.\nfunc (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response {\n    // Extract the function and args from the transaction proposal\n    fn, args := stub.GetFunctionAndParameters()\n\n\n}\n\n\n\nNext, we\\'ll validate the function name as being either `set` or `get`,\nand invoke those chaincode application functions, returning an\nappropriate response via the `shim.Success` or `shim.Error` functions\nthat will serialize the response into a gRPC protobuf message.\n\n``` {.sourceCode .go}\n// Invoke is called per transaction on the chaincode. Each transaction is\n// either a 'get' or a 'set' on the asset created by Init function. The Set\n// method may create a new asset by specifying a new key-value pair.\nfunc (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response {\n    // Extract the function and args from the transaction proposal\n    fn, args := stub.GetFunctionAndParameters()\n\n    var result string\n    var err error\n    if fn == \nset\n {\n        result, err = set(stub, args)\n    } else {\n        result, err = get(stub, args)\n    }\n    if err != nil {\n        return shim.Error(err.Error())\n    }\n\n    // Return the result as success payload\n    return shim.Success([]byte(result))\n}\n\n\n\n\nImplementing the Chaincode Application\n\n\nAs noted, our chaincode application implements two functions that can be\ninvoked via the \nInvoke\n function. Let\\'s implement those functions now.\nNote that as we mentioned above, to access the ledger\\'s state, we will\nleverage the\n\nChaincodeStubInterface.PutState\n\nand\n\nChaincodeStubInterface.GetState\n\nfunctions of the chaincode shim API.\n\n\n``` {.sourceCode .go}\n// Set stores the asset (both key and value) on the ledger. If the key exists,\n// it will override the value with the new one\nfunc set(stub shim.ChaincodeStubInterface, args []string) (string, error) {\n    if len(args) != 2 {\n        return \"\", fmt.Errorf(\"Incorrect arguments. Expecting a key and a value\")\n    }\n\n\nerr := stub.PutState(args[0], []byte(args[1]))\nif err != nil {\n    return \"\", fmt.Errorf(\"Failed to set asset: %s\", args[0])\n}\nreturn args[1], nil\n\n\n\n}\n\n\n// Get returns the value of the specified asset key\nfunc get(stub shim.ChaincodeStubInterface, args []string) (string, error) {\n    if len(args) != 1 {\n        return \"\", fmt.Errorf(\"Incorrect arguments. Expecting a key\")\n    }\n\n\nvalue, err := stub.GetState(args[0])\nif err != nil {\n    return \"\", fmt.Errorf(\"Failed to get asset: %s with error: %s\", args[0], err)\n}\nif value == nil {\n    return \"\", fmt.Errorf(\"Asset not found: %s\", args[0])\n}\nreturn string(value), nil\n\n\n\n}\n\n\n\n::: {#Chaincode Sample}\n### Pulling it All Together\n:::\n\nFinally, we need to add the `main` function, which will call the\n[shim.Start](http://godoc.org/github.com/hyperledger/fabric/core/chaincode/shim#Start)\nfunction. Here\\'s the whole chaincode program source.\n\n``` {.sourceCode .go}\npackage main\n\nimport (\n    \nfmt\n\n\n    \ngithub.com/hyperledger/fabric/core/chaincode/shim\n\n    \ngithub.com/hyperledger/fabric/protos/peer\n\n)\n\n// SimpleAsset implements a simple chaincode to manage an asset\ntype SimpleAsset struct {\n}\n\n// Init is called during chaincode instantiation to initialize any\n// data. Note that chaincode upgrade also calls this function to reset\n// or to migrate data.\nfunc (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response {\n    // Get the args from the transaction proposal\n    args := stub.GetStringArgs()\n    if len(args) != 2 {\n        return shim.Error(\nIncorrect arguments. Expecting a key and a value\n)\n    }\n\n    // Set up any variables or assets here by calling stub.PutState()\n\n    // We store the key and the value on the ledger\n    err := stub.PutState(args[0], []byte(args[1]))\n    if err != nil {\n        return shim.Error(fmt.Sprintf(\nFailed to create asset: %s\n, args[0]))\n    }\n    return shim.Success(nil)\n}\n\n// Invoke is called per transaction on the chaincode. Each transaction is\n// either a 'get' or a 'set' on the asset created by Init function. The Set\n// method may create a new asset by specifying a new key-value pair.\nfunc (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response {\n    // Extract the function and args from the transaction proposal\n    fn, args := stub.GetFunctionAndParameters()\n\n    var result string\n    var err error\n    if fn == \nset\n {\n        result, err = set(stub, args)\n    } else { // assume 'get' even if fn is nil\n        result, err = get(stub, args)\n    }\n    if err != nil {\n        return shim.Error(err.Error())\n    }\n\n    // Return the result as success payload\n    return shim.Success([]byte(result))\n}\n\n// Set stores the asset (both key and value) on the ledger. If the key exists,\n// it will override the value with the new one\nfunc set(stub shim.ChaincodeStubInterface, args []string) (string, error) {\n    if len(args) != 2 {\n        return \n, fmt.Errorf(\nIncorrect arguments. Expecting a key and a value\n)\n    }\n\n    err := stub.PutState(args[0], []byte(args[1]))\n    if err != nil {\n        return \n, fmt.Errorf(\nFailed to set asset: %s\n, args[0])\n    }\n    return args[1], nil\n}\n\n// Get returns the value of the specified asset key\nfunc get(stub shim.ChaincodeStubInterface, args []string) (string, error) {\n    if len(args) != 1 {\n        return \n, fmt.Errorf(\nIncorrect arguments. Expecting a key\n)\n    }\n\n    value, err := stub.GetState(args[0])\n    if err != nil {\n        return \n, fmt.Errorf(\nFailed to get asset: %s with error: %s\n, args[0], err)\n    }\n    if value == nil {\n        return \n, fmt.Errorf(\nAsset not found: %s\n, args[0])\n    }\n    return string(value), nil\n}\n\n// main function starts up the chaincode in the container during instantiate\nfunc main() {\n    if err := shim.Start(new(SimpleAsset)); err != nil {\n        fmt.Printf(\nError starting SimpleAsset chaincode: %s\n, err)\n    }\n}\n\n\n\n\nBuilding Chaincode\n\n\nNow let\\'s compile your chaincode.\n\n\n``` {.sourceCode .bash}\ngo get -u --tags nopkcs11 github.com/hyperledger/fabric/core/chaincode/shim\ngo build --tags nopkcs11\n\n\n\nAssuming there are no errors, now we can proceed to the next step,\ntesting your chaincode.\n\n### Testing Using dev mode\n\nNormally chaincodes are started and maintained by peer. However in \ndev\nmode\\\n, chaincode is built and started by the user. This mode is useful\nduring chaincode development phase for rapid code/build/run/debug cycle\nturnaround.\n\nWe start \\\ndev mode\\\n by leveraging pre-generated orderer and channel\nartifacts for a sample dev network. As such, the user can immediately\njump into the process of compiling chaincode and driving calls.\n\nInstall Hyperledger Fabric Samples\n\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\--\n\nIf you haven\\'t already done so, please install the\n[samples]{role=\ndoc\n}.\n\nNavigate to the `chaincode-docker-devmode` directory of the\n`fabric-samples` clone:\n\n``` {.sourceCode .bash}\ncd chaincode-docker-devmode\n\n\n\n\nDownload Docker images\n\n\nWe need four Docker images in order for \\\"dev mode\\\" to run against the\nsupplied docker compose script. If you installed the \nfabric-samples\n\nrepo clone and followed the instructions to [binaries]{role=\"ref\"}, then\nyou should have the necessary Docker images installed locally.\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nIf you choose to manually pull the images then you must retag them as\n\n\n:   \nlatest\n.\n:::\n\n\nIssue a \ndocker images\n command to reveal your local Docker Registry.\nYou should see something similar to following:\n\n\n``` {.sourceCode .bash}\ndocker images\nREPOSITORY                     TAG                                  IMAGE ID            CREATED             SIZE\nhyperledger/fabric-tools       latest                               e09f38f8928d        4 hours ago         1.32 GB\nhyperledger/fabric-tools       x86_64-1.0.0                         e09f38f8928d        4 hours ago         1.32 GB\nhyperledger/fabric-orderer     latest                               0df93ba35a25        4 hours ago         179 MB\nhyperledger/fabric-orderer     x86_64-1.0.0                         0df93ba35a25        4 hours ago         179 MB\nhyperledger/fabric-peer        latest                               533aec3f5a01        4 hours ago         182 MB\nhyperledger/fabric-peer        x86_64-1.0.0                         533aec3f5a01        4 hours ago         182 MB\nhyperledger/fabric-ccenv       latest                               4b70698a71d3        4 hours ago         1.29 GB\nhyperledger/fabric-ccenv       x86_64-1.0.0                         4b70698a71d3        4 hours ago         1.29 GB\n\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\nIf you retrieved the images through the [binaries]{role=\nref\n},\n\n:   then you will see additional images listed. However, we are only\n    concerned with these four.\n:::\n\nNow open three terminals and navigate to your `chaincode-docker-devmode`\ndirectory in each.\n\nTerminal 1 - Start the network\n------------------------------\n\n``` {.sourceCode .bash}\ndocker-compose -f docker-compose-simple.yaml up\n\n\n\n\nThe above starts the network with the \nSingleSampleMSPSolo\n orderer\nprofile and launches the peer in \\\"dev mode\\\". It also launches two\nadditional containers -one for the chaincode environment and a CLI to\ninteract with the chaincode. The commands for create and join channel\nare embedded in the CLI container, so we can jump immediately to the\nchaincode calls.\n\n\nTerminal 2 - Build \n start the chaincode\n\n\n``` {.sourceCode .bash}\ndocker exec -it chaincode bash\n\n\n\nYou should see the following:\n\n``` {.sourceCode .bash}\nroot@d2629980e76b:/opt/gopath/src/chaincode#\n\n\n\n\nNow, compile your chaincode:\n\n\n``` {.sourceCode .bash}\ncd sacc\ngo build\n\n\n\nNow run the chaincode:\n\n``` {.sourceCode .bash}\nCORE_PEER_ADDRESS=peer:7052 CORE_CHAINCODE_ID_NAME=mycc:0 ./sacc\n\n\n\n\nThe chaincode is started with peer and chaincode logs indicating\nsuccessful registration with the peer. Note that at this stage the\nchaincode is not associated with any channel. This is done in subsequent\nsteps using the \ninstantiate\n command.\n\n\nTerminal 3 - Use the chaincode\n\n\nEven though you are in \n--peer-chaincodedev\n mode, you still have to\ninstall the chaincode so the life-cycle system chaincode can go through\nits checks normally. This requirement may be removed in future when in\n\n--peer-chaincodedev\n mode.\n\n\nWe\\'ll leverage the CLI container to drive these calls.\n\n\n``` {.sourceCode .bash}\ndocker exec -it cli bash\n\n\n\n``` {.sourceCode .bash}\npeer chaincode install -p chaincodedev/chaincode/sacc -n mycc -v 0\npeer chaincode instantiate -n mycc -v 0 -c '{\nArgs\n:[\na\n,\n10\n]}' -C myc\n\n\n\n\nNow issue an invoke to change the value of \\\"a\\\" to \\\"20\\\".\n\n\n``` {.sourceCode .bash}\npeer chaincode invoke -n mycc -c '{\"Args\":[\"set\", \"a\", \"20\"]}' -C myc\n\n\n\nFinally, query `a`. We should see a value of `20`.\n\n``` {.sourceCode .bash}\npeer chaincode query -n mycc -c '{\nArgs\n:[\nquery\n,\na\n]}' -C myc\n\n\n\n\nTesting new chaincode\n\n\nBy default, we mount only \nsacc\n. However, you can easily test different\nchaincodes by adding them to the \nchaincode\n subdirectory and\nrelaunching your network. At this point they will be accessible in your\n\nchaincode\n container.\n\n\nChaincode encryption\n\n\nIn certain scenarios, it may be useful to encrypt values associated with\na key in their entirety or simply in part. For example, if a person\\'s\nsocial security number or address was being written to the ledger, then\nyou likely would not want this data to appear in plaintext. Chaincode\nencryption is achieved by leveraging the \nentities\nextension\n\nwhich is a BCCSP wrapper with commodity factories and functions to\nperform cryptographic operations such as encryption and elliptic curve\ndigital signatures. For example, to encrypt, the invoker of a chaincode\npasses in a cryptographic key via the transient field. The same key may\nthen be used for subsequent query operations, allowing for proper\ndecryption of the encrypted state values.\n\n\nFor more information and samples, see the \nEncc\nExample\n\nwithin the \nfabric/examples\n directory. Pay specific attention to the\n\nutils.go\n helper program. This utility loads the chaincode shim APIs\nand Entities extension and builds a new class of functions (e.g.\n\nencryptAndPutState\n \n \ngetStateAndDecrypt\n) that the sample encryption\nchaincode then leverages. As such, the chaincode can now marry the basic\nshim APIs of \nGet\n and \nPut\n with the added functionality of \nEncrypt\n\nand \nDecrypt\n.", 
            "title": "Chaincode for Developers"
        }, 
        {
            "location": "/chaincode4ade/#chaincode-for-developers", 
            "text": "", 
            "title": "Chaincode for Developers"
        }, 
        {
            "location": "/chaincode4ade/#what-is-chaincode", 
            "text": "Chaincode is a program, written in  Go , node.js , that implements a prescribed interface.\nEventually, other programming languages such as Java, will be supported.\nChaincode runs in a secured Docker container isolated from the endorsing\npeer process. Chaincode initializes and manages the ledger state through\ntransactions submitted by applications.  A chaincode typically handles business logic agreed to by members of the\nnetwork, so it similar to a \\\"smart contract\\\". Ledger state created by\na chaincode is scoped exclusively to that chaincode and can\\'t be\naccessed directly by another chaincode. Given the appropriate\npermission, a chaincode may invoke another chaincode to access its state\nwithin the same network.  In the following sections, we will explore chaincode through the eyes of\nan application developer. We\\'ll present a simple chaincode sample\napplication and walk through the purpose of each method in the Chaincode\nShim API.", 
            "title": "What is Chaincode?"
        }, 
        {
            "location": "/chaincode4ade/#chaincode-api", 
            "text": "Every chaincode program must implement the  Chaincode interface :    Go  node.js    whose methods are called in response to received transactions. In\nparticular the  Init  method is called when a chaincode receives an instantiate  or  upgrade  transaction so that the chaincode may perform\nany necessary initialization, including initialization of application\nstate. The  Invoke  method is called in response to receiving an invoke  transaction to process transaction proposals.  The other interface in the chaincode \\\"shim\\\" APIs is the ChaincodeStubInterface :    Go  node.js    which is used to access and modify the ledger, and to make invocations\nbetween chaincodes.  In this tutorial, we will demonstrate the use of these APIs by\nimplementing a simple chaincode application that manages simple\n\\\"assets\\\".  ::: {#Simple Asset Chaincode}\nSimple Asset Chaincode   :::  Our application is a basic sample chaincode to create assets (key-value\npairs) on the ledger.", 
            "title": "Chaincode API"
        }, 
        {
            "location": "/chaincode4ade/#choosing-a-location-for-the-code", 
            "text": "If you haven\\'t been doing programming in Go, you may want to make sure\nthat you have [Golang]{role=\"ref\"} installed and your system properly\nconfigured.  Now, you will want to create a directory for your chaincode application\nas a child directory of  $GOPATH/src/ .  To keep things simple, let\\'s use the following command:  ``` {.sourceCode .bash}\nmkdir -p $GOPATH/src/sacc   cd $GOPATH/src/sacc  \nNow, let\\'s create the source file that we\\'ll fill in with code:\n\n``` {.sourceCode .bash}\ntouch sacc.go", 
            "title": "Choosing a Location for the Code"
        }, 
        {
            "location": "/chaincode4ade/#housekeeping", 
            "text": "First, let\\'s start with some housekeeping. As with every chaincode, it\nimplements the  Chaincode\ninterface \nin particular,  Init  and  Invoke  functions. So, let\\'s add the go\nimport statements for the necessary dependencies for our chaincode.\nWe\\'ll import the chaincode shim package and the  peer protobuf\npackage .\nNext, let\\'s add a struct  SimpleAsset  as a receiver for Chaincode shim\nfunctions.  ``` {.sourceCode .go}\npackage main  import (\n    \"fmt\"  \"github.com/hyperledger/fabric/core/chaincode/shim\"\n\"github.com/hyperledger/fabric/protos/peer\"  )  // SimpleAsset implements a simple chaincode to manage an asset\ntype SimpleAsset struct {\n}  \n### Initializing the Chaincode\n\nNext, we\\'ll implement the `Init` function.\n\n``` {.sourceCode .go}\n// Init is called during chaincode instantiation to initialize any data.\nfunc (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response {\n\n}  ::: {.note}\n::: {.admonition-title}\nNote\n:::  Note that chaincode upgrade also calls this function. When writing a  :   chaincode that will upgrade an existing one, make sure to modify the\n     Init  function appropriately. In particular, provide an empty\n    \\\"Init\\\" method if there\\'s no \\\"migration\\\" or nothing to be\n    initialized as part of the upgrade.\n:::  Next, we\\'ll retrieve the arguments to the  Init  call using the ChaincodeStubInterface.GetStringArgs \nfunction and check for validity. In our case, we are expecting a\nkey-value pair.   {.sourceCode .go}\n// Init is called during chaincode instantiation to initialize any\n// data. Note that chaincode upgrade also calls this function to reset\n// or to migrate data, so be careful to avoid a scenario where you\n// inadvertently clobber your ledger's data!\nfunc (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response {\n  // Get the args from the transaction proposal\n  args := stub.GetStringArgs()\n  if len(args) != 2 {\n    return shim.Error(\"Incorrect arguments. Expecting a key and a value\")\n  }\n}   Next, now that we have established that the call is valid, we\\'ll store\nthe initial state in the ledger. To do this, we will call ChaincodeStubInterface.PutState \nwith the key and value passed in as the arguments. Assuming all went\nwell, return a peer.Response object that indicates the initialization\nwas a success.  ``` {.sourceCode .go}\n// Init is called during chaincode instantiation to initialize any\n// data. Note that chaincode upgrade also calls this function to reset\n// or to migrate data, so be careful to avoid a scenario where you\n// inadvertently clobber your ledger's data!\nfunc (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response {\n  // Get the args from the transaction proposal\n  args := stub.GetStringArgs()\n  if len(args) != 2 {\n    return shim.Error(\"Incorrect arguments. Expecting a key and a value\")\n  }  // Set up any variables or assets here by calling stub.PutState()  // We store the key and the value on the ledger\n  err := stub.PutState(args[0], []byte(args[1]))\n  if err != nil {\n    return shim.Error(fmt.Sprintf(\"Failed to create asset: %s\", args[0]))\n  }\n  return shim.Success(nil)\n}  \n### Invoking the Chaincode\n\nFirst, let\\'s add the `Invoke` function\\'s signature.\n\n``` {.sourceCode .go}\n// Invoke is called per transaction on the chaincode. Each transaction is\n// either a 'get' or a 'set' on the asset created by Init function. The 'set'\n// method may create a new asset by specifying a new key-value pair.\nfunc (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response {\n\n}  As with the  Init  function above, we need to extract the arguments from\nthe  ChaincodeStubInterface . The  Invoke  function\\'s arguments will be\nthe name of the chaincode application function to invoke. In our case,\nour application will simply have two functions:  set  and  get , that\nallow the value of an asset to be set or its current state to be\nretrieved. We first call ChaincodeStubInterface.GetFunctionAndParameters \nto extract the function name and the parameters to that chaincode\napplication function.  ``` {.sourceCode .go}\n// Invoke is called per transaction on the chaincode. Each transaction is\n// either a 'get' or a 'set' on the asset created by Init function. The Set\n// method may create a new asset by specifying a new key-value pair.\nfunc (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response {\n    // Extract the function and args from the transaction proposal\n    fn, args := stub.GetFunctionAndParameters()  }  \nNext, we\\'ll validate the function name as being either `set` or `get`,\nand invoke those chaincode application functions, returning an\nappropriate response via the `shim.Success` or `shim.Error` functions\nthat will serialize the response into a gRPC protobuf message.\n\n``` {.sourceCode .go}\n// Invoke is called per transaction on the chaincode. Each transaction is\n// either a 'get' or a 'set' on the asset created by Init function. The Set\n// method may create a new asset by specifying a new key-value pair.\nfunc (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response {\n    // Extract the function and args from the transaction proposal\n    fn, args := stub.GetFunctionAndParameters()\n\n    var result string\n    var err error\n    if fn ==  set  {\n        result, err = set(stub, args)\n    } else {\n        result, err = get(stub, args)\n    }\n    if err != nil {\n        return shim.Error(err.Error())\n    }\n\n    // Return the result as success payload\n    return shim.Success([]byte(result))\n}", 
            "title": "Housekeeping"
        }, 
        {
            "location": "/chaincode4ade/#implementing-the-chaincode-application", 
            "text": "As noted, our chaincode application implements two functions that can be\ninvoked via the  Invoke  function. Let\\'s implement those functions now.\nNote that as we mentioned above, to access the ledger\\'s state, we will\nleverage the ChaincodeStubInterface.PutState \nand ChaincodeStubInterface.GetState \nfunctions of the chaincode shim API.  ``` {.sourceCode .go}\n// Set stores the asset (both key and value) on the ledger. If the key exists,\n// it will override the value with the new one\nfunc set(stub shim.ChaincodeStubInterface, args []string) (string, error) {\n    if len(args) != 2 {\n        return \"\", fmt.Errorf(\"Incorrect arguments. Expecting a key and a value\")\n    }  err := stub.PutState(args[0], []byte(args[1]))\nif err != nil {\n    return \"\", fmt.Errorf(\"Failed to set asset: %s\", args[0])\n}\nreturn args[1], nil  }  // Get returns the value of the specified asset key\nfunc get(stub shim.ChaincodeStubInterface, args []string) (string, error) {\n    if len(args) != 1 {\n        return \"\", fmt.Errorf(\"Incorrect arguments. Expecting a key\")\n    }  value, err := stub.GetState(args[0])\nif err != nil {\n    return \"\", fmt.Errorf(\"Failed to get asset: %s with error: %s\", args[0], err)\n}\nif value == nil {\n    return \"\", fmt.Errorf(\"Asset not found: %s\", args[0])\n}\nreturn string(value), nil  }  \n::: {#Chaincode Sample}\n### Pulling it All Together\n:::\n\nFinally, we need to add the `main` function, which will call the\n[shim.Start](http://godoc.org/github.com/hyperledger/fabric/core/chaincode/shim#Start)\nfunction. Here\\'s the whole chaincode program source.\n\n``` {.sourceCode .go}\npackage main\n\nimport (\n     fmt \n\n     github.com/hyperledger/fabric/core/chaincode/shim \n     github.com/hyperledger/fabric/protos/peer \n)\n\n// SimpleAsset implements a simple chaincode to manage an asset\ntype SimpleAsset struct {\n}\n\n// Init is called during chaincode instantiation to initialize any\n// data. Note that chaincode upgrade also calls this function to reset\n// or to migrate data.\nfunc (t *SimpleAsset) Init(stub shim.ChaincodeStubInterface) peer.Response {\n    // Get the args from the transaction proposal\n    args := stub.GetStringArgs()\n    if len(args) != 2 {\n        return shim.Error( Incorrect arguments. Expecting a key and a value )\n    }\n\n    // Set up any variables or assets here by calling stub.PutState()\n\n    // We store the key and the value on the ledger\n    err := stub.PutState(args[0], []byte(args[1]))\n    if err != nil {\n        return shim.Error(fmt.Sprintf( Failed to create asset: %s , args[0]))\n    }\n    return shim.Success(nil)\n}\n\n// Invoke is called per transaction on the chaincode. Each transaction is\n// either a 'get' or a 'set' on the asset created by Init function. The Set\n// method may create a new asset by specifying a new key-value pair.\nfunc (t *SimpleAsset) Invoke(stub shim.ChaincodeStubInterface) peer.Response {\n    // Extract the function and args from the transaction proposal\n    fn, args := stub.GetFunctionAndParameters()\n\n    var result string\n    var err error\n    if fn ==  set  {\n        result, err = set(stub, args)\n    } else { // assume 'get' even if fn is nil\n        result, err = get(stub, args)\n    }\n    if err != nil {\n        return shim.Error(err.Error())\n    }\n\n    // Return the result as success payload\n    return shim.Success([]byte(result))\n}\n\n// Set stores the asset (both key and value) on the ledger. If the key exists,\n// it will override the value with the new one\nfunc set(stub shim.ChaincodeStubInterface, args []string) (string, error) {\n    if len(args) != 2 {\n        return  , fmt.Errorf( Incorrect arguments. Expecting a key and a value )\n    }\n\n    err := stub.PutState(args[0], []byte(args[1]))\n    if err != nil {\n        return  , fmt.Errorf( Failed to set asset: %s , args[0])\n    }\n    return args[1], nil\n}\n\n// Get returns the value of the specified asset key\nfunc get(stub shim.ChaincodeStubInterface, args []string) (string, error) {\n    if len(args) != 1 {\n        return  , fmt.Errorf( Incorrect arguments. Expecting a key )\n    }\n\n    value, err := stub.GetState(args[0])\n    if err != nil {\n        return  , fmt.Errorf( Failed to get asset: %s with error: %s , args[0], err)\n    }\n    if value == nil {\n        return  , fmt.Errorf( Asset not found: %s , args[0])\n    }\n    return string(value), nil\n}\n\n// main function starts up the chaincode in the container during instantiate\nfunc main() {\n    if err := shim.Start(new(SimpleAsset)); err != nil {\n        fmt.Printf( Error starting SimpleAsset chaincode: %s , err)\n    }\n}", 
            "title": "Implementing the Chaincode Application"
        }, 
        {
            "location": "/chaincode4ade/#building-chaincode", 
            "text": "Now let\\'s compile your chaincode.  ``` {.sourceCode .bash}\ngo get -u --tags nopkcs11 github.com/hyperledger/fabric/core/chaincode/shim\ngo build --tags nopkcs11  \nAssuming there are no errors, now we can proceed to the next step,\ntesting your chaincode.\n\n### Testing Using dev mode\n\nNormally chaincodes are started and maintained by peer. However in  dev\nmode\\ , chaincode is built and started by the user. This mode is useful\nduring chaincode development phase for rapid code/build/run/debug cycle\nturnaround.\n\nWe start \\ dev mode\\  by leveraging pre-generated orderer and channel\nartifacts for a sample dev network. As such, the user can immediately\njump into the process of compiling chaincode and driving calls.\n\nInstall Hyperledger Fabric Samples\n\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\-\\--\n\nIf you haven\\'t already done so, please install the\n[samples]{role= doc }.\n\nNavigate to the `chaincode-docker-devmode` directory of the\n`fabric-samples` clone:\n\n``` {.sourceCode .bash}\ncd chaincode-docker-devmode", 
            "title": "Building Chaincode"
        }, 
        {
            "location": "/chaincode4ade/#download-docker-images", 
            "text": "We need four Docker images in order for \\\"dev mode\\\" to run against the\nsupplied docker compose script. If you installed the  fabric-samples \nrepo clone and followed the instructions to [binaries]{role=\"ref\"}, then\nyou should have the necessary Docker images installed locally.  ::: {.note}\n::: {.admonition-title}\nNote\n:::  If you choose to manually pull the images then you must retag them as  :    latest .\n:::  Issue a  docker images  command to reveal your local Docker Registry.\nYou should see something similar to following:  ``` {.sourceCode .bash}\ndocker images\nREPOSITORY                     TAG                                  IMAGE ID            CREATED             SIZE\nhyperledger/fabric-tools       latest                               e09f38f8928d        4 hours ago         1.32 GB\nhyperledger/fabric-tools       x86_64-1.0.0                         e09f38f8928d        4 hours ago         1.32 GB\nhyperledger/fabric-orderer     latest                               0df93ba35a25        4 hours ago         179 MB\nhyperledger/fabric-orderer     x86_64-1.0.0                         0df93ba35a25        4 hours ago         179 MB\nhyperledger/fabric-peer        latest                               533aec3f5a01        4 hours ago         182 MB\nhyperledger/fabric-peer        x86_64-1.0.0                         533aec3f5a01        4 hours ago         182 MB\nhyperledger/fabric-ccenv       latest                               4b70698a71d3        4 hours ago         1.29 GB\nhyperledger/fabric-ccenv       x86_64-1.0.0                         4b70698a71d3        4 hours ago         1.29 GB  \n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\nIf you retrieved the images through the [binaries]{role= ref },\n\n:   then you will see additional images listed. However, we are only\n    concerned with these four.\n:::\n\nNow open three terminals and navigate to your `chaincode-docker-devmode`\ndirectory in each.\n\nTerminal 1 - Start the network\n------------------------------\n\n``` {.sourceCode .bash}\ndocker-compose -f docker-compose-simple.yaml up  The above starts the network with the  SingleSampleMSPSolo  orderer\nprofile and launches the peer in \\\"dev mode\\\". It also launches two\nadditional containers -one for the chaincode environment and a CLI to\ninteract with the chaincode. The commands for create and join channel\nare embedded in the CLI container, so we can jump immediately to the\nchaincode calls.", 
            "title": "Download Docker images"
        }, 
        {
            "location": "/chaincode4ade/#terminal-2-build-start-the-chaincode", 
            "text": "``` {.sourceCode .bash}\ndocker exec -it chaincode bash  \nYou should see the following:\n\n``` {.sourceCode .bash}\nroot@d2629980e76b:/opt/gopath/src/chaincode#  Now, compile your chaincode:  ``` {.sourceCode .bash}\ncd sacc\ngo build  \nNow run the chaincode:\n\n``` {.sourceCode .bash}\nCORE_PEER_ADDRESS=peer:7052 CORE_CHAINCODE_ID_NAME=mycc:0 ./sacc  The chaincode is started with peer and chaincode logs indicating\nsuccessful registration with the peer. Note that at this stage the\nchaincode is not associated with any channel. This is done in subsequent\nsteps using the  instantiate  command.", 
            "title": "Terminal 2 - Build &amp; start the chaincode"
        }, 
        {
            "location": "/chaincode4ade/#terminal-3-use-the-chaincode", 
            "text": "Even though you are in  --peer-chaincodedev  mode, you still have to\ninstall the chaincode so the life-cycle system chaincode can go through\nits checks normally. This requirement may be removed in future when in --peer-chaincodedev  mode.  We\\'ll leverage the CLI container to drive these calls.  ``` {.sourceCode .bash}\ndocker exec -it cli bash  \n``` {.sourceCode .bash}\npeer chaincode install -p chaincodedev/chaincode/sacc -n mycc -v 0\npeer chaincode instantiate -n mycc -v 0 -c '{ Args :[ a , 10 ]}' -C myc  Now issue an invoke to change the value of \\\"a\\\" to \\\"20\\\".  ``` {.sourceCode .bash}\npeer chaincode invoke -n mycc -c '{\"Args\":[\"set\", \"a\", \"20\"]}' -C myc  \nFinally, query `a`. We should see a value of `20`.\n\n``` {.sourceCode .bash}\npeer chaincode query -n mycc -c '{ Args :[ query , a ]}' -C myc", 
            "title": "Terminal 3 - Use the chaincode"
        }, 
        {
            "location": "/chaincode4ade/#testing-new-chaincode", 
            "text": "By default, we mount only  sacc . However, you can easily test different\nchaincodes by adding them to the  chaincode  subdirectory and\nrelaunching your network. At this point they will be accessible in your chaincode  container.", 
            "title": "Testing new chaincode"
        }, 
        {
            "location": "/chaincode4ade/#chaincode-encryption", 
            "text": "In certain scenarios, it may be useful to encrypt values associated with\na key in their entirety or simply in part. For example, if a person\\'s\nsocial security number or address was being written to the ledger, then\nyou likely would not want this data to appear in plaintext. Chaincode\nencryption is achieved by leveraging the  entities\nextension \nwhich is a BCCSP wrapper with commodity factories and functions to\nperform cryptographic operations such as encryption and elliptic curve\ndigital signatures. For example, to encrypt, the invoker of a chaincode\npasses in a cryptographic key via the transient field. The same key may\nthen be used for subsequent query operations, allowing for proper\ndecryption of the encrypted state values.  For more information and samples, see the  Encc\nExample \nwithin the  fabric/examples  directory. Pay specific attention to the utils.go  helper program. This utility loads the chaincode shim APIs\nand Entities extension and builds a new class of functions (e.g. encryptAndPutState     getStateAndDecrypt ) that the sample encryption\nchaincode then leverages. As such, the chaincode can now marry the basic\nshim APIs of  Get  and  Put  with the added functionality of  Encrypt \nand  Decrypt .", 
            "title": "Chaincode encryption"
        }, 
        {
            "location": "/chaincode4noah/", 
            "text": "Chaincode for Operators\n\n\nWhat is Chaincode?\n\n\nChaincode is a program, written in \nGo\n, and\neventually in other programming languages such as Java, that implements\na prescribed interface. Chaincode runs in a secured Docker container\nisolated from the endorsing peer process. Chaincode initializes and\nmanages ledger state through transactions submitted by applications.\n\n\nA chaincode typically handles business logic agreed to by members of the\nnetwork, so it may be considered as a \\\"smart contract\\\". State created\nby a chaincode is scoped exclusively to that chaincode and can\\'t be\naccessed directly by another chaincode. However, within the same\nnetwork, given the appropriate permission a chaincode may invoke another\nchaincode to access its state.\n\n\nIn the following sections, we will explore chaincode through the eyes of\na blockchain network operator, Noah. For Noah\\'s interests, we will\nfocus on chaincode lifecycle operations; the process of packaging,\ninstalling, instantiating and upgrading the chaincode as a function of\nthe chaincode\\'s operational lifecycle within a blockchain network.\n\n\nChaincode lifecycle\n\n\nThe Hyperledger Fabric API enables interaction with the various nodes in\na blockchain network - the peers, orderers and MSPs - and it also allows\none to package, install, instantiate and upgrade chaincode on the\nendorsing peer nodes. The Hyperledger Fabric language-specific SDKs\nabstract the specifics of the Hyperledger Fabric API to facilitate\napplication development, though it can be used to manage a chaincode\\'s\nlifecycle. Additionally, the Hyperledger Fabric API can be accessed\ndirectly via the CLI, which we will use in this document.\n\n\nWe provide four commands to manage a chaincode\\'s lifecycle: \npackage\n,\n\ninstall\n, \ninstantiate\n, and \nupgrade\n. In a future release, we are\nconsidering adding \nstop\n and \nstart\n transactions to disable and\nre-enable a chaincode without having to actually uninstall it. After a\nchaincode has been successfully installed and instantiated, the\nchaincode is active (running) and can process transactions via the\n\ninvoke\n transaction. A chaincode may be upgraded any time after it has\nbeen installed.\n\n\n::: {#Package}\nPackaging\n\n\n\n\n:::\n\n\nThe chaincode package consists of 3 parts:\n\n\n\n\n\n\nthe chaincode, as defined by \nChaincodeDeploymentSpec\n or CDS. The\n    CDS defines the chaincode package in terms of the code and other\n    properties such as name and version,\n\n\nan optional instantiation policy which can be syntactically\n    described by the same policy used for endorsement and described in\n    [endorsement-policies]{role=\"doc\"}, and\n\n\na set of signatures by the entities that \"own\" the chaincode.\n\n\n\n\n\n\nThe signatures serve the following purposes:\n\n\n\n\n\n\nto establish an ownership of the chaincode,\n\n\nto allow verification of the contents of the package, and\n\n\nto allow detection of package tampering.\n\n\n\n\n\n\nThe creator of the instantiation transaction of the chaincode on a\nchannel is validated against the instantiation policy of the chaincode.\n\n\nCreating the package\n\n\nThere are two approaches to packaging chaincode. One for when you want\nto have multiple owners of a chaincode, and hence need to have the\nchaincode package signed by multiple identities. This workflow requires\nthat we initially create a signed chaincode package (a \nSignedCDS\n)\nwhich is subsequently passed serially to each of the other owners for\nsigning.\n\n\nThe simpler workflow is for when you are deploying a SignedCDS that has\nonly the signature of the identity of the node that is issuing the\n\ninstall\n transaction.\n\n\nWe will address the more complex case first. However, you may skip ahead\nto the [Install]{role=\"ref\"} section below if you do not need to worry\nabout multiple owners just yet.\n\n\nTo create a signed chaincode package, use the following command:\n\n\n``` {.sourceCode .bash}\npeer chaincode package -n mycc -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -v 0 -s -S -i \"AND('OrgA.admin')\" ccpack.out\n\n\n\nThe `-s` option creates a package that can be signed by multiple owners\nas opposed to simply creating a raw CDS. When `-s` is specified, the\n`-S` option must also be specified if other owners are going to need to\nsign. Otherwise, the process will create a SignedCDS that includes only\nthe instantiation policy in addition to the CDS.\n\nThe `-S` option directs the process to sign the package using the MSP\nidentified by the value of the `localMspid` property in `core.yaml`.\n\nThe `-S` option is optional. However if a package is created without a\nsignature, it cannot be signed by any other owner using the\n`signpackage` command.\n\nThe optional `-i` option allows one to specify an instantiation policy\nfor the chaincode. The instantiation policy has the same format as an\nendorsement policy and specifies which identities can instantiate the\nchaincode. In the example above, only the admin of OrgA is allowed to\ninstantiate the chaincode. If no policy is provided, the default policy\nis used, which only allows the admin identity of the peer\\'s MSP to\ninstantiate chaincode.\n\n### Package signing\n\nA chaincode package that was signed at creation can be handed over to\nother owners for inspection and signing. The workflow supports\nout-of-band signing of chaincode package.\n\nThe\n[ChaincodeDeploymentSpec](https://github.com/hyperledger/fabric/blob/master/protos/peer/chaincode.proto#L78)\nmay be optionally be signed by the collective owners to create a\n[SignedChaincodeDeploymentSpec](https://github.com/hyperledger/fabric/blob/master/protos/peer/signed_cc_dep_spec.proto#L26)\n(or SignedCDS). The SignedCDS contains 3 elements:\n\n\n 1.  The CDS contains the source code, the name, and version of the\n\n     chaincode.\n\n 2.  An instantiation policy of the chaincode, expressed as endorsement\n\n     policies.\n\n 3.  The list of chaincode owners, defined by means of\n\n     [Endorsement](https://github.com/hyperledger/fabric/blob/master/protos/peer/proposal_response.proto#L111).\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\nNote that this endorsement policy is determined out-of-band to\n\n:   provide proper MSP principals when the chaincode is instantiated on\n    some channels. If the instantiation policy is not specified, the\n    default policy is any MSP administrator of the channel.\n:::\n\nEach owner endorses the ChaincodeDeploymentSpec by combining it with\nthat owner\\'s identity (e.g. certificate) and signing the combined\nresult.\n\nA chaincode owner can sign a previously created signed package using the\nfollowing command:\n\n``` {.sourceCode .bash}\npeer chaincode signpackage ccpack.out signedccpack.out\n\n\n\n\nWhere \nccpack.out\n and \nsignedccpack.out\n are the input and output\npackages, respectively. \nsignedccpack.out\n contains an additional\nsignature over the package signed using the Local MSP.\n\n\n::: {#Install}\n\n\nInstalling chaincode\n\n\n:::\n\n\nThe \ninstall\n transaction packages a chaincode\\'s source code into a\nprescribed format called a \nChaincodeDeploymentSpec\n (or CDS) and\ninstalls it on a peer node that will run that chaincode.\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nYou must install the chaincode on \neach\n endorsing peer node\n\n\n:   of a channel that will run your chaincode.\n:::\n\n\nWhen the \ninstall\n API is given simply a \nChaincodeDeploymentSpec\n, it\nwill default the instantiation policy and include an empty owner list.\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nChaincode should only be installed on endorsing peer nodes of the\n\n\n:   owning members of the chaincode to protect the confidentiality of\n    the chaincode logic from other members on the network. Those members\n    without the chaincode, can\\'t be the endorsers of the chaincode\\'s\n    transactions; that is, they can\\'t execute the chaincode. However,\n    they can still validate and commit the transactions to the ledger.\n:::\n\n\nTo install a chaincode, send a\n\nSignedProposal\n\nto the \nlifecycle system chaincode\n (LSCC) described in the \nSystem\nChaincode\n section. For example, to install the\n\nsacc\n sample chaincode described in section\n[simple asset chaincode]{role=\"ref\"} using the CLI, the command would\nlook like the following:\n\n\n``` {.sourceCode .bash}\npeer chaincode install -n asset_mgmt -v 1.0 -p sacc\n\n\n\nThe CLI internally creates the SignedChaincodeDeploymentSpec for\n**sacc** and sends it to the local peer, which calls the `Install`\nmethod on the LSCC. The argument to the `-p` option specifies the path\nto the chaincode, which must be located within the source tree of the\nuser\\'s `GOPATH`, e.g. `$GOPATH/src/sacc`. See the [CLI](#cli) section\nfor a complete description of the command options.\n\nNote that in order to install on a peer, the signature of the\nSignedProposal must be from 1 of the peer\\'s local MSP administrators.\n\n::: {#Instantiate}\n### Instantiate\n:::\n\nThe `instantiate` transaction invokes the `lifecycle System Chaincode`\n(LSCC) to create and initialize a chaincode on a channel. This is a\nchaincode-channel binding process: a chaincode may be bound to any\nnumber of channels and operate on each channel individually and\nindependently. In other words, regardless of how many other channels on\nwhich a chaincode might be installed and instantiated, state is kept\nisolated to the channel to which a transaction is submitted.\n\nThe creator of an `instantiate` transaction must satisfy the\ninstantiation policy of the chaincode included in SignedCDS and must\nalso be a writer on the channel, which is configured as part of the\nchannel creation. This is important for the security of the channel to\nprevent rogue entities from deploying chaincodes or tricking members to\nexecute chaincodes on an unbound channel.\n\nFor example, recall that the default instantiation policy is any channel\nMSP administrator, so the creator of a chaincode instantiate transaction\nmust be a member of the channel administrators. When the transaction\nproposal arrives at the endorser, it verifies the creator\\'s signature\nagainst the instantiation policy. This is done again during the\ntransaction validation before committing it to the ledger.\n\nThe instantiate transaction also sets up the endorsement policy for that\nchaincode on the channel. The endorsement policy describes the\nattestation requirements for the transaction result to be accepted by\nmembers of the channel.\n\nFor example, using the CLI to instantiate the **sacc** chaincode and\ninitialize the state with `john` and `0`, the command would look like\nthe following:\n\n``` {.sourceCode .bash}\npeer chaincode instantiate -n sacc -v 1.0 -c '{\nArgs\n:[\njohn\n,\n0\n]}' -P \nOR ('Org1.member','Org2.member')\n\n\n\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nNote the endorsement policy (CLI uses polish notation), which requires an\n\n\n:   endorsement from either member of Org1 or Org2 for all transactions\n    to \nsacc\n. That is, either Org1 or Org2 must sign the result of\n    executing the Invoke on \nsacc\n for the transactions to be valid.\n:::\n\n\nAfter being successfully instantiated, the chaincode enters the active\nstate on the channel and is ready to process any transaction proposals\nof type\n\nENDORSER_TRANSACTION\n.\nThe transactions are processed concurrently as they arrive at the\nendorsing peer.\n\n\n::: {#Upgrade}\n\n\nUpgrade\n\n\n:::\n\n\nA chaincode may be upgraded any time by changing its version, which is\npart of the SignedCDS. Other parts, such as owners and instantiation\npolicy are optional. However, the chaincode name must be the same;\notherwise it would be considered as a totally different chaincode.\n\n\nPrior to upgrade, the new version of the chaincode must be installed on\nthe required endorsers. Upgrade is a transaction similar to the\ninstantiate transaction, which binds the new version of the chaincode to\nthe channel. Other channels bound to the old version of the chaincode\nstill run with the old version. In other words, the \nupgrade\n\ntransaction only affects one channel at a time, the channel to which the\ntransaction is submitted.\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nNote that since multiple versions of a chaincode may be active\n\n\n:   simultaneously, the upgrade process doesn\\'t automatically remove\n    the old versions, so user must manage this for the time being.\n:::\n\n\nThere\\'s one subtle difference with the \ninstantiate\n transaction: the\n\nupgrade\n transaction is checked against the current chaincode\ninstantiation policy, not the new policy (if specified). This is to\nensure that only existing members specified in the current instantiation\npolicy may upgrade the chaincode.\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nNote that during upgrade, the chaincode \nInit\n function is called to\n\n\n:   perform any data related updates or re-initialize it, so care must\n    be taken to avoid resetting states when upgrading chaincode.\n:::\n\n\n::: {#Stop-and-Start}\n\n\nStop and Start\n\n\n:::\n\n\nNote that \nstop\n and \nstart\n lifecycle transactions have not yet been\nimplemented. However, you may stop a chaincode manually by removing the\nchaincode container and the SignedCDS package from each of the\nendorsers. This is done by deleting the chaincode\\'s container on each\nof the hosts or virtual machines on which the endorsing peer nodes are\nrunning, and then deleting the SignedCDS from each of the endorsing peer\nnodes:\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nTODO - in order to delete the CDS from the peer node, you would need\n\n\n:   to enter the peer node\\'s container, first. We really need to\n    provide a utility script that can do this.\n:::\n\n\n``` {.sourceCode .bash}\ndocker rm -f \n\nrm /var/hyperledger/production/chaincodes/\n:\n\n\n\nStop would be useful in the workflow for doing upgrade in controlled\nmanner, where a chaincode can be stopped on a channel on all peers\nbefore issuing an upgrade.\n\n::: {#CLI}\n### CLI\n:::\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\nWe are assessing the need to distribute platform-specific binaries\n\n:   for the Hyperledger Fabric `peer` binary. For the time being, you\n    can simply invoke the commands from within a running docker\n    container.\n:::\n\nTo view the currently available CLI commands, execute the following\ncommand from within a running `fabric-peer` Docker container:\n\n``` {.sourceCode .bash}\ndocker run -it hyperledger/fabric-peer bash\n# peer chaincode --help\n\n\n\n\nWhich shows output similar to the example below:\n\n\n``` {.sourceCode .bash}\nUsage:\n  peer chaincode [command]\n\n\nAvailable Commands:\n  install     Package the specified chaincode into a deployment spec and save it on the peer's path.\n  instantiate Deploy the specified chaincode to the network.\n  invoke      Invoke the specified chaincode.\n  list        Get the instantiated chaincodes on a channel or installed chaincodes on a peer.\n  package     Package the specified chaincode into a deployment spec.\n  query       Query using the specified chaincode.\n  signpackage Sign the specified chaincode package\n  upgrade     Upgrade chaincode.\n\n\nFlags:\n    --cafile string      Path to file containing PEM-encoded trusted certificate(s) for the ordering endpoint\n-h, --help               help for chaincode\n-o, --orderer string     Ordering service endpoint\n    --tls                Use TLS when communicating with the orderer endpoint\n    --transient string   Transient map of arguments in JSON encoding\n\n\n\nGlobal Flags:\n\n:   \\--logging-level string Default logging level and overrides, see\n    core.yaml for full syntax \\--test.coverprofile string Done (default\n    \\\ncoverage.cov\\\n)\n\n\n -v, \\--version\n\n\n\n Use \\\npeer chaincode \\[command\\] \\--help\\\n for more information about\n\n a command.\n\nTo facilitate its use in scripted applications, the `peer` command\nalways produces a non-zero return code in the event of command failure.\n\nExample of chaincode commands:\n\n``` {.sourceCode .bash}\npeer chaincode install -n mycc -v 0 -p path/to/my/chaincode/v0\npeer chaincode instantiate -n mycc -v 0 -c '{\nArgs\n:[\na\n, \nb\n, \nc\n]}' -C mychannel\npeer chaincode install -n mycc -v 1 -p path/to/my/chaincode/v1\npeer chaincode upgrade -n mycc -v 1 -c '{\nArgs\n:[\nd\n, \ne\n, \nf\n]}' -C mychannel\npeer chaincode query -C mychannel -n mycc -c '{\nArgs\n:[\nquery\n,\ne\n]}'\npeer chaincode invoke -o orderer.example.com:7050  --tls --cafile $ORDERER_CA -C mychannel -n mycc -c '{\nArgs\n:[\ninvoke\n,\na\n,\nb\n,\n10\n]}'\n\n\n\n\n::: {#System Chaincode}\nSystem chaincode\n\n\n\n\n:::\n\n\nSystem chaincode has the same programming model except that it runs\nwithin the peer process rather than in an isolated container like normal\nchaincode. Therefore, system chaincode is built into the peer executable\nand doesn\\'t follow the same lifecycle described above. In particular,\n\ninstall\n, \ninstantiate\n and \nupgrade\n do not apply to system\nchaincodes.\n\n\nThe purpose of system chaincode is to shortcut gRPC communication cost\nbetween peer and chaincode, and tradeoff the flexibility in management.\nFor example, a system chaincode can only be upgraded with the peer\nbinary. It must also register with a \nfixed set of\nparameters\n\ncompiled in and doesn\\'t have endorsement policies or endorsement policy\nfunctionality.\n\n\nSystem chaincode is used in Hyperledger Fabric to implement a number of\nsystem behaviors so that they can be replaced or modified as appropriate\nby a system integrator.\n\n\nThe current list of system chaincodes:\n\n\n\n\nLSCC\n\n    Lifecycle system chaincode handles lifecycle requests described\n    above.\n\n\nCSCC\n\n    Configuration system chaincode handles channel configuration on the\n    peer side.\n\n\nQSCC\n\n    Query system chaincode provides ledger query APIs such as getting\n    blocks and transactions.\n\n\nESCC\n\n    Endorsement system chaincode handles endorsement by signing the\n    transaction proposal response.\n\n\nVSCC\n\n    Validation system chaincode handles the transaction validation,\n    including checking endorsement policy and multiversioning\n    concurrency control.\n\n\n\n\nCare must be taken when modifying or replacing these system chaincodes,\nespecially LSCC, ESCC and VSCC since they are in the main transaction\nexecution path. It is worth noting that as VSCC validates a block before\ncommitting it to the ledger, it is important that all peers in the\nchannel compute the same validation to avoid ledger divergence\n(non-determinism). So special care is needed if VSCC is modified or\nreplaced.", 
            "title": "Chaincode for Operations"
        }, 
        {
            "location": "/chaincode4noah/#chaincode-for-operators", 
            "text": "", 
            "title": "Chaincode for Operators"
        }, 
        {
            "location": "/chaincode4noah/#what-is-chaincode", 
            "text": "Chaincode is a program, written in  Go , and\neventually in other programming languages such as Java, that implements\na prescribed interface. Chaincode runs in a secured Docker container\nisolated from the endorsing peer process. Chaincode initializes and\nmanages ledger state through transactions submitted by applications.  A chaincode typically handles business logic agreed to by members of the\nnetwork, so it may be considered as a \\\"smart contract\\\". State created\nby a chaincode is scoped exclusively to that chaincode and can\\'t be\naccessed directly by another chaincode. However, within the same\nnetwork, given the appropriate permission a chaincode may invoke another\nchaincode to access its state.  In the following sections, we will explore chaincode through the eyes of\na blockchain network operator, Noah. For Noah\\'s interests, we will\nfocus on chaincode lifecycle operations; the process of packaging,\ninstalling, instantiating and upgrading the chaincode as a function of\nthe chaincode\\'s operational lifecycle within a blockchain network.", 
            "title": "What is Chaincode?"
        }, 
        {
            "location": "/chaincode4noah/#chaincode-lifecycle", 
            "text": "The Hyperledger Fabric API enables interaction with the various nodes in\na blockchain network - the peers, orderers and MSPs - and it also allows\none to package, install, instantiate and upgrade chaincode on the\nendorsing peer nodes. The Hyperledger Fabric language-specific SDKs\nabstract the specifics of the Hyperledger Fabric API to facilitate\napplication development, though it can be used to manage a chaincode\\'s\nlifecycle. Additionally, the Hyperledger Fabric API can be accessed\ndirectly via the CLI, which we will use in this document.  We provide four commands to manage a chaincode\\'s lifecycle:  package , install ,  instantiate , and  upgrade . In a future release, we are\nconsidering adding  stop  and  start  transactions to disable and\nre-enable a chaincode without having to actually uninstall it. After a\nchaincode has been successfully installed and instantiated, the\nchaincode is active (running) and can process transactions via the invoke  transaction. A chaincode may be upgraded any time after it has\nbeen installed.  ::: {#Package}\nPackaging   :::  The chaincode package consists of 3 parts:    the chaincode, as defined by  ChaincodeDeploymentSpec  or CDS. The\n    CDS defines the chaincode package in terms of the code and other\n    properties such as name and version,  an optional instantiation policy which can be syntactically\n    described by the same policy used for endorsement and described in\n    [endorsement-policies]{role=\"doc\"}, and  a set of signatures by the entities that \"own\" the chaincode.    The signatures serve the following purposes:    to establish an ownership of the chaincode,  to allow verification of the contents of the package, and  to allow detection of package tampering.    The creator of the instantiation transaction of the chaincode on a\nchannel is validated against the instantiation policy of the chaincode.", 
            "title": "Chaincode lifecycle"
        }, 
        {
            "location": "/chaincode4noah/#creating-the-package", 
            "text": "There are two approaches to packaging chaincode. One for when you want\nto have multiple owners of a chaincode, and hence need to have the\nchaincode package signed by multiple identities. This workflow requires\nthat we initially create a signed chaincode package (a  SignedCDS )\nwhich is subsequently passed serially to each of the other owners for\nsigning.  The simpler workflow is for when you are deploying a SignedCDS that has\nonly the signature of the identity of the node that is issuing the install  transaction.  We will address the more complex case first. However, you may skip ahead\nto the [Install]{role=\"ref\"} section below if you do not need to worry\nabout multiple owners just yet.  To create a signed chaincode package, use the following command:  ``` {.sourceCode .bash}\npeer chaincode package -n mycc -p github.com/hyperledger/fabric/examples/chaincode/go/chaincode_example02 -v 0 -s -S -i \"AND('OrgA.admin')\" ccpack.out  \nThe `-s` option creates a package that can be signed by multiple owners\nas opposed to simply creating a raw CDS. When `-s` is specified, the\n`-S` option must also be specified if other owners are going to need to\nsign. Otherwise, the process will create a SignedCDS that includes only\nthe instantiation policy in addition to the CDS.\n\nThe `-S` option directs the process to sign the package using the MSP\nidentified by the value of the `localMspid` property in `core.yaml`.\n\nThe `-S` option is optional. However if a package is created without a\nsignature, it cannot be signed by any other owner using the\n`signpackage` command.\n\nThe optional `-i` option allows one to specify an instantiation policy\nfor the chaincode. The instantiation policy has the same format as an\nendorsement policy and specifies which identities can instantiate the\nchaincode. In the example above, only the admin of OrgA is allowed to\ninstantiate the chaincode. If no policy is provided, the default policy\nis used, which only allows the admin identity of the peer\\'s MSP to\ninstantiate chaincode.\n\n### Package signing\n\nA chaincode package that was signed at creation can be handed over to\nother owners for inspection and signing. The workflow supports\nout-of-band signing of chaincode package.\n\nThe\n[ChaincodeDeploymentSpec](https://github.com/hyperledger/fabric/blob/master/protos/peer/chaincode.proto#L78)\nmay be optionally be signed by the collective owners to create a\n[SignedChaincodeDeploymentSpec](https://github.com/hyperledger/fabric/blob/master/protos/peer/signed_cc_dep_spec.proto#L26)\n(or SignedCDS). The SignedCDS contains 3 elements:  1.  The CDS contains the source code, the name, and version of the      chaincode.  2.  An instantiation policy of the chaincode, expressed as endorsement      policies.  3.  The list of chaincode owners, defined by means of      [Endorsement](https://github.com/hyperledger/fabric/blob/master/protos/peer/proposal_response.proto#L111).\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\nNote that this endorsement policy is determined out-of-band to\n\n:   provide proper MSP principals when the chaincode is instantiated on\n    some channels. If the instantiation policy is not specified, the\n    default policy is any MSP administrator of the channel.\n:::\n\nEach owner endorses the ChaincodeDeploymentSpec by combining it with\nthat owner\\'s identity (e.g. certificate) and signing the combined\nresult.\n\nA chaincode owner can sign a previously created signed package using the\nfollowing command:\n\n``` {.sourceCode .bash}\npeer chaincode signpackage ccpack.out signedccpack.out  Where  ccpack.out  and  signedccpack.out  are the input and output\npackages, respectively.  signedccpack.out  contains an additional\nsignature over the package signed using the Local MSP.  ::: {#Install}", 
            "title": "Creating the package"
        }, 
        {
            "location": "/chaincode4noah/#installing-chaincode", 
            "text": ":::  The  install  transaction packages a chaincode\\'s source code into a\nprescribed format called a  ChaincodeDeploymentSpec  (or CDS) and\ninstalls it on a peer node that will run that chaincode.  ::: {.note}\n::: {.admonition-title}\nNote\n:::  You must install the chaincode on  each  endorsing peer node  :   of a channel that will run your chaincode.\n:::  When the  install  API is given simply a  ChaincodeDeploymentSpec , it\nwill default the instantiation policy and include an empty owner list.  ::: {.note}\n::: {.admonition-title}\nNote\n:::  Chaincode should only be installed on endorsing peer nodes of the  :   owning members of the chaincode to protect the confidentiality of\n    the chaincode logic from other members on the network. Those members\n    without the chaincode, can\\'t be the endorsers of the chaincode\\'s\n    transactions; that is, they can\\'t execute the chaincode. However,\n    they can still validate and commit the transactions to the ledger.\n:::  To install a chaincode, send a SignedProposal \nto the  lifecycle system chaincode  (LSCC) described in the  System\nChaincode  section. For example, to install the sacc  sample chaincode described in section\n[simple asset chaincode]{role=\"ref\"} using the CLI, the command would\nlook like the following:  ``` {.sourceCode .bash}\npeer chaincode install -n asset_mgmt -v 1.0 -p sacc  \nThe CLI internally creates the SignedChaincodeDeploymentSpec for\n**sacc** and sends it to the local peer, which calls the `Install`\nmethod on the LSCC. The argument to the `-p` option specifies the path\nto the chaincode, which must be located within the source tree of the\nuser\\'s `GOPATH`, e.g. `$GOPATH/src/sacc`. See the [CLI](#cli) section\nfor a complete description of the command options.\n\nNote that in order to install on a peer, the signature of the\nSignedProposal must be from 1 of the peer\\'s local MSP administrators.\n\n::: {#Instantiate}\n### Instantiate\n:::\n\nThe `instantiate` transaction invokes the `lifecycle System Chaincode`\n(LSCC) to create and initialize a chaincode on a channel. This is a\nchaincode-channel binding process: a chaincode may be bound to any\nnumber of channels and operate on each channel individually and\nindependently. In other words, regardless of how many other channels on\nwhich a chaincode might be installed and instantiated, state is kept\nisolated to the channel to which a transaction is submitted.\n\nThe creator of an `instantiate` transaction must satisfy the\ninstantiation policy of the chaincode included in SignedCDS and must\nalso be a writer on the channel, which is configured as part of the\nchannel creation. This is important for the security of the channel to\nprevent rogue entities from deploying chaincodes or tricking members to\nexecute chaincodes on an unbound channel.\n\nFor example, recall that the default instantiation policy is any channel\nMSP administrator, so the creator of a chaincode instantiate transaction\nmust be a member of the channel administrators. When the transaction\nproposal arrives at the endorser, it verifies the creator\\'s signature\nagainst the instantiation policy. This is done again during the\ntransaction validation before committing it to the ledger.\n\nThe instantiate transaction also sets up the endorsement policy for that\nchaincode on the channel. The endorsement policy describes the\nattestation requirements for the transaction result to be accepted by\nmembers of the channel.\n\nFor example, using the CLI to instantiate the **sacc** chaincode and\ninitialize the state with `john` and `0`, the command would look like\nthe following:\n\n``` {.sourceCode .bash}\npeer chaincode instantiate -n sacc -v 1.0 -c '{ Args :[ john , 0 ]}' -P  OR ('Org1.member','Org2.member')   ::: {.note}\n::: {.admonition-title}\nNote\n:::  Note the endorsement policy (CLI uses polish notation), which requires an  :   endorsement from either member of Org1 or Org2 for all transactions\n    to  sacc . That is, either Org1 or Org2 must sign the result of\n    executing the Invoke on  sacc  for the transactions to be valid.\n:::  After being successfully instantiated, the chaincode enters the active\nstate on the channel and is ready to process any transaction proposals\nof type ENDORSER_TRANSACTION .\nThe transactions are processed concurrently as they arrive at the\nendorsing peer.  ::: {#Upgrade}", 
            "title": "Installing chaincode"
        }, 
        {
            "location": "/chaincode4noah/#upgrade", 
            "text": ":::  A chaincode may be upgraded any time by changing its version, which is\npart of the SignedCDS. Other parts, such as owners and instantiation\npolicy are optional. However, the chaincode name must be the same;\notherwise it would be considered as a totally different chaincode.  Prior to upgrade, the new version of the chaincode must be installed on\nthe required endorsers. Upgrade is a transaction similar to the\ninstantiate transaction, which binds the new version of the chaincode to\nthe channel. Other channels bound to the old version of the chaincode\nstill run with the old version. In other words, the  upgrade \ntransaction only affects one channel at a time, the channel to which the\ntransaction is submitted.  ::: {.note}\n::: {.admonition-title}\nNote\n:::  Note that since multiple versions of a chaincode may be active  :   simultaneously, the upgrade process doesn\\'t automatically remove\n    the old versions, so user must manage this for the time being.\n:::  There\\'s one subtle difference with the  instantiate  transaction: the upgrade  transaction is checked against the current chaincode\ninstantiation policy, not the new policy (if specified). This is to\nensure that only existing members specified in the current instantiation\npolicy may upgrade the chaincode.  ::: {.note}\n::: {.admonition-title}\nNote\n:::  Note that during upgrade, the chaincode  Init  function is called to  :   perform any data related updates or re-initialize it, so care must\n    be taken to avoid resetting states when upgrading chaincode.\n:::  ::: {#Stop-and-Start}", 
            "title": "Upgrade"
        }, 
        {
            "location": "/chaincode4noah/#stop-and-start", 
            "text": ":::  Note that  stop  and  start  lifecycle transactions have not yet been\nimplemented. However, you may stop a chaincode manually by removing the\nchaincode container and the SignedCDS package from each of the\nendorsers. This is done by deleting the chaincode\\'s container on each\nof the hosts or virtual machines on which the endorsing peer nodes are\nrunning, and then deleting the SignedCDS from each of the endorsing peer\nnodes:  ::: {.note}\n::: {.admonition-title}\nNote\n:::  TODO - in order to delete the CDS from the peer node, you would need  :   to enter the peer node\\'s container, first. We really need to\n    provide a utility script that can do this.\n:::  ``` {.sourceCode .bash}\ndocker rm -f  \nrm /var/hyperledger/production/chaincodes/ :  \nStop would be useful in the workflow for doing upgrade in controlled\nmanner, where a chaincode can be stopped on a channel on all peers\nbefore issuing an upgrade.\n\n::: {#CLI}\n### CLI\n:::\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\nWe are assessing the need to distribute platform-specific binaries\n\n:   for the Hyperledger Fabric `peer` binary. For the time being, you\n    can simply invoke the commands from within a running docker\n    container.\n:::\n\nTo view the currently available CLI commands, execute the following\ncommand from within a running `fabric-peer` Docker container:\n\n``` {.sourceCode .bash}\ndocker run -it hyperledger/fabric-peer bash\n# peer chaincode --help  Which shows output similar to the example below:  ``` {.sourceCode .bash}\nUsage:\n  peer chaincode [command]  Available Commands:\n  install     Package the specified chaincode into a deployment spec and save it on the peer's path.\n  instantiate Deploy the specified chaincode to the network.\n  invoke      Invoke the specified chaincode.\n  list        Get the instantiated chaincodes on a channel or installed chaincodes on a peer.\n  package     Package the specified chaincode into a deployment spec.\n  query       Query using the specified chaincode.\n  signpackage Sign the specified chaincode package\n  upgrade     Upgrade chaincode.  Flags:\n    --cafile string      Path to file containing PEM-encoded trusted certificate(s) for the ordering endpoint\n-h, --help               help for chaincode\n-o, --orderer string     Ordering service endpoint\n    --tls                Use TLS when communicating with the orderer endpoint\n    --transient string   Transient map of arguments in JSON encoding  \nGlobal Flags:\n\n:   \\--logging-level string Default logging level and overrides, see\n    core.yaml for full syntax \\--test.coverprofile string Done (default\n    \\ coverage.cov\\ )  -v, \\--version   Use \\ peer chaincode \\[command\\] \\--help\\  for more information about  a command.\n\nTo facilitate its use in scripted applications, the `peer` command\nalways produces a non-zero return code in the event of command failure.\n\nExample of chaincode commands:\n\n``` {.sourceCode .bash}\npeer chaincode install -n mycc -v 0 -p path/to/my/chaincode/v0\npeer chaincode instantiate -n mycc -v 0 -c '{ Args :[ a ,  b ,  c ]}' -C mychannel\npeer chaincode install -n mycc -v 1 -p path/to/my/chaincode/v1\npeer chaincode upgrade -n mycc -v 1 -c '{ Args :[ d ,  e ,  f ]}' -C mychannel\npeer chaincode query -C mychannel -n mycc -c '{ Args :[ query , e ]}'\npeer chaincode invoke -o orderer.example.com:7050  --tls --cafile $ORDERER_CA -C mychannel -n mycc -c '{ Args :[ invoke , a , b , 10 ]}'  ::: {#System Chaincode}\nSystem chaincode   :::  System chaincode has the same programming model except that it runs\nwithin the peer process rather than in an isolated container like normal\nchaincode. Therefore, system chaincode is built into the peer executable\nand doesn\\'t follow the same lifecycle described above. In particular, install ,  instantiate  and  upgrade  do not apply to system\nchaincodes.  The purpose of system chaincode is to shortcut gRPC communication cost\nbetween peer and chaincode, and tradeoff the flexibility in management.\nFor example, a system chaincode can only be upgraded with the peer\nbinary. It must also register with a  fixed set of\nparameters \ncompiled in and doesn\\'t have endorsement policies or endorsement policy\nfunctionality.  System chaincode is used in Hyperledger Fabric to implement a number of\nsystem behaviors so that they can be replaced or modified as appropriate\nby a system integrator.  The current list of system chaincodes:   LSCC \n    Lifecycle system chaincode handles lifecycle requests described\n    above.  CSCC \n    Configuration system chaincode handles channel configuration on the\n    peer side.  QSCC \n    Query system chaincode provides ledger query APIs such as getting\n    blocks and transactions.  ESCC \n    Endorsement system chaincode handles endorsement by signing the\n    transaction proposal response.  VSCC \n    Validation system chaincode handles the transaction validation,\n    including checking endorsement policy and multiversioning\n    concurrency control.   Care must be taken when modifying or replacing these system chaincodes,\nespecially LSCC, ESCC and VSCC since they are in the main transaction\nexecution path. It is worth noting that as VSCC validates a block before\ncommitting it to the ledger, it is important that all peers in the\nchannel compute the same validation to avoid ledger divergence\n(non-determinism). So special care is needed if VSCC is modified or\nreplaced.", 
            "title": "Stop and Start"
        }, 
        {
            "location": "/tbd/", 
            "text": "PLACEHOLDER", 
            "title": "DRIVENET Tutorial"
        }, 
        {
            "location": "/tbd/#placeholder", 
            "text": "", 
            "title": "PLACEHOLDER"
        }, 
        {
            "location": "/arch-deep-dive/", 
            "text": "Architecture Explained\n\n\nThe Hyperledger Fabric architecture delivers the following advantages:\n\n\n\n\nChaincode trust flexibility.\n The architecture separates \ntrust\n    assumptions\n for chaincodes (blockchain applications) from trust\n    assumptions for ordering. In other words, the ordering service may\n    be provided by one set of nodes (orderers) and tolerate some of them\n    to fail or misbehave, and the endorsers may be different for each\n    chaincode.\n\n\nScalability.\n As the endorser nodes responsible for particular\n    chaincode are orthogonal to the orderers, the system may \nscale\n\n    better than if these functions were done by the same nodes. In\n    particular, this results when different chaincodes specify disjoint\n    endorsers, which introduces a partitioning of chaincodes between\n    endorsers and allows parallel chaincode execution (endorsement).\n    Besides, chaincode execution, which can potentially be costly, is\n    removed from the critical path of the ordering service.\n\n\nConfidentiality.\n The architecture facilitates deployment of\n    chaincodes that have \nconfidentiality\n requirements with respect to\n    the content and state updates of its transactions.\n\n\nConsensus modularity.\n The architecture is \nmodular\n and allows\n    pluggable consensus (i.e., ordering service) implementations.\n\n\n\n\nPart I: Elements of the architecture relevant to Hyperledger Fabric\nv1\n\n\n\n\nSystem architecture\n\n\nBasic workflow of transaction endorsement\n\n\nEndorsement policies\n\n\n\n\nPart II: Post-v1 elements of the architecture\n\n\n\n\nLedger checkpointing (pruning)\n\n\nSystem architecture\n\n\n\n\n\n\nThe blockchain is a distributed system consisting of many nodes that\ncommunicate with each other. The blockchain runs programs called\nchaincode, holds state and ledger data, and executes transactions. The\nchaincode is the central element as transactions are operations invoked\non the chaincode. Transactions have to be \\\"endorsed\\\" and only endorsed\ntransactions may be committed and have an effect on the state. There may\nexist one or more special chaincodes for management functions and\nparameters, collectively called \nsystem chaincodes\n.\n\n\n1.1. Transactions\n\n\nTransactions may be of two types:\n\n\n\n\nDeploy transactions\n create new chaincode and take a program as\n    parameter. When a deploy transaction executes successfully, the\n    chaincode has been installed \\\"on\\\" the blockchain.\n\n\nInvoke transactions\n perform an operation in the context of\n    previously deployed chaincode. An invoke transaction refers to a\n    chaincode and to one of its provided functions. When successful, the\n    chaincode executes the specified function - which may involve\n    modifying the corresponding state, and returning an output.\n\n\n\n\nAs described later, deploy transactions are special cases of invoke\ntransactions, where a deploy transaction that creates new chaincode,\ncorresponds to an invoke transaction on a system chaincode.\n\n\nRemark:\n \nThis document currently assumes that a transaction either\ncreates new chaincode or invokes an operation provided by an already\ndeployed chaincode. This document does not yet describe: a)\noptimizations for query (read-only) transactions, b)\nsupport for cross-chaincode transactions.\n\n\n1.2. Blockchain data structures\n\n\n1.2.1. State\n\n\nThe latest state of the blockchain (or, simply, \nstate\n) is modeled as a\nversioned key/value store (KVS), where keys are names and values are\narbitrary blobs. These entries are manipulated by the chaincodes\n(applications) running on the blockchain through \nput\n and \nget\n\nKVS-operations. The state is stored persistently and updates to the\nstate are logged. Notice that versioned KVS is adopted as state model,\nan implementation may use actual KVSs, but also RDBMSs or any other\nsolution.\n\n\nMore formally, state \ns\n is modeled as an element of a mapping\n\nK -\n (V X N)\n, where:\n\n\n\n\nK\n is a set of keys\n\n\nV\n is a set of values\n\n\nN\n is an infinite ordered set of version numbers. Injective\n    function \nnext: N -\n N\n takes an element of \nN\n and returns the next\n    version number.\n\n\n\n\nBoth \nV\n and \nN\n contain a special element \n\\bot\n, which is in case of\n\nN\n the lowest element. Initially all keys are mapped to \n(\\bot,\\bot)\n.\nFor \ns(k)=(v,ver)\n we denote \nv\n by \ns(k).value\n, and \nver\n by\n\ns(k).version\n.\n\n\nKVS operations are modeled as follows:\n\n\n\n\nput(k,v)\n, for \nk\\in K\n and \nv\\in V\n, takes the blockchain state\n    \ns\n and changes it to \ns'\n such that \ns'(k)=(v,next(s(k).version))\n\n    with \ns'(k')=s(k')\n for all \nk'!=k\n.\n\n\nget(k)\n returns \ns(k)\n.\n\n\n\n\nState is maintained by peers, but not by orderers and clients.\n\n\nState partitioning.\n Keys in the KVS can be recognized from their\nname to belong to a particular chaincode, in the sense that only\ntransaction of a certain chaincode may modify the keys belonging to this\nchaincode. In principle, any chaincode can read the keys belonging to\nanother chaincode. \nSupport for cross-chaincode transactions, that modify\nthe state belonging to two or more chaincodes is a post-v1 feature.\n\n\n1.2.2 Ledger\n\n\nLedger provides a verifiable history of all successful state changes (we\ntalk about \nvalid\n transactions) and unsuccessful attempts to change\nstate (we talk about \ninvalid\n transactions), occurring during the\noperation of the system.\n\n\nLedger is constructed by the ordering service (see Sec 1.3.3) as a\ntotally ordered hashchain of \nblocks\n of (valid or invalid)\ntransactions. The hashchain imposes the total order of blocks in a\nledger and each block contains an array of totally ordered transactions.\nThis imposes total order across all transactions.\n\n\nLedger is kept at all peers and, optionally, at a subset of orderers. In\nthe context of an orderer we refer to the Ledger as to \nOrdererLedger\n,\nwhereas in the context of a peer we refer to the ledger as to\n\nPeerLedger\n. \nPeerLedger\n differs from the \nOrdererLedger\n in that\npeers locally maintain a bitmask that tells apart valid transactions\nfrom invalid ones (see Section XX for more details).\n\n\nPeers may prune \nPeerLedger\n as described in Section XX (post-v1\nfeature). Orderers maintain \nOrdererLedger\n for fault-tolerance and\navailability (of the \nPeerLedger\n) and may decide to prune it at\nanytime, provided that properties of the ordering service (see Sec.\n1.3.3) are maintained.\n\n\nThe ledger allows peers to replay the history of all transactions and to\nreconstruct the state. Therefore, state as described in Sec 1.2.1 is an\noptional datastructure.\n\n\n1.3. Nodes\n\n\nNodes are the communication entities of the blockchain. A \\\"node\\\" is\nonly a logical function in the sense that multiple nodes of different\ntypes can run on the same physical server. What counts is how nodes are\ngrouped in \\\"trust domains\\\" and associated to logical entities that\ncontrol them.\n\n\nThere are three types of nodes:\n\n\n\n\nClient\n or \nsubmitting-client\n: a client that submits an actual\n    transaction-invocation to the endorsers, and broadcasts\n    transaction-proposals to the ordering service.\n\n\nPeer\n: a node that commits transactions and maintains the state\n    and a copy of the ledger (see Sec, 1.2). Besides, peers can have a\n    special \nendorser\n role.\n\n\nOrdering-service-node\n or \norderer\n: a node running the\n    communication service that implements a delivery guarantee, such as\n    atomic or total order broadcast.\n\n\n\n\nThe types of nodes are explained next in more detail.\n\n\n1.3.1. Client\n\n\nThe client represents the entity that acts on behalf of an end-user. It\nmust connect to a peer for communicating with the blockchain. The client\nmay connect to any peer of its choice. Clients create and thereby invoke\ntransactions.\n\n\nAs detailed in Section 2, clients communicate with both peers and the\nordering service.\n\n\n1.3.2. Peer\n\n\nA peer receives ordered state updates in the form of \nblocks\n from the\nordering service and maintain the state and the ledger.\n\n\nPeers can additionally take up a special role of an \nendorsing peer\n,\nor an \nendorser\n. The special function of an \nendorsing peer\n occurs\nwith respect to a particular chaincode and consists in \nendorsing\n a\ntransaction before it is committed. Every chaincode may specify an\n\nendorsement policy\n that may refer to a set of endorsing peers. The\npolicy defines the necessary and sufficient conditions for a valid\ntransaction endorsement (typically a set of endorsers\\' signatures), as\ndescribed later in Sections 2 and 3. In the special case of deploy\ntransactions that install new chaincode the (deployment) endorsement\npolicy is specified as an endorsement policy of the system chaincode.\n\n\n1.3.3. Ordering service nodes (Orderers)\n\n\nThe \norderers\n form the \nordering service\n, i.e., a communication fabric\nthat provides delivery guarantees. The ordering service can be\nimplemented in different ways: ranging from a centralized service (used\ne.g., in development and testing) to distributed protocols that target\ndifferent network and node fault models.\n\n\nOrdering service provides a shared \ncommunication channel\n to clients\nand peers, offering a broadcast service for messages containing\ntransactions. Clients connect to the channel and may broadcast messages\non the channel which are then delivered to all peers. The channel\nsupports \natomic\n delivery of all messages, that is, message\ncommunication with total-order delivery and (implementation specific)\nreliability. In other words, the channel outputs the same messages to\nall connected peers and outputs them to all peers in the same logical\norder. This atomic communication guarantee is also called \ntotal-order\nbroadcast\n, \natomic broadcast\n, or \nconsensus\n in the context of\ndistributed systems. The communicated messages are the candidate\ntransactions for inclusion in the blockchain state.\n\n\nPartitioning (ordering service channels).\n Ordering service may\nsupport multiple \nchannels\n similar to the \ntopics\n of a\npublish/subscribe (pub/sub) messaging system. Clients can connect to a\ngiven channel and can then send messages and obtain the messages that\narrive. Channels can be thought of as partitions - clients connecting to\none channel are unaware of the existence of other channels, but clients\nmay connect to multiple channels. Even though some ordering service\nimplementations included with Hyperledger Fabric support multiple\nchannels, for simplicity of presentation, in the rest of this document,\nwe assume ordering service consists of a single channel/topic.\n\n\nOrdering service API.\n Peers connect to the channel provided by the\nordering service, via the interface provided by the ordering service.\nThe ordering service API consists of two basic operations (more\ngenerally \nasynchronous events\n):\n\n\nTODO\n add the part of the API for fetching particular blocks under\nclient/peer specified sequence numbers.\n\n\n\n\nbroadcast(blob)\n: a client calls this to broadcast an arbitrary\n    message \nblob\n for dissemination over the channel. This is also\n    called \nrequest(blob)\n in the BFT context, when sending a request to\n    a service.\n\n\ndeliver(seqno, prevhash, blob)\n: the ordering service calls this on\n    the peer to deliver the message \nblob\n with the specified\n    non-negative integer sequence number (\nseqno\n) and hash of the most\n    recently delivered blob (\nprevhash\n). In other words, it is an\n    output event from the ordering service. \ndeliver()\n is also\n    sometimes called \nnotify()\n in pub-sub systems or \ncommit()\n in BFT\n    systems.\n\n\n\n\nLedger and block formation.\n The ledger (see also Sec. 1.2.2)\ncontains all data output by the ordering service. In a nutshell, it is a\nsequence of \ndeliver(seqno, prevhash, blob)\n events, which form a hash\nchain according to the computation of \nprevhash\n described before.\n\n\nMost of the time, for efficiency reasons, instead of outputting\nindividual transactions (blobs), the ordering service will group (batch)\nthe blobs and output \nblocks\n within a single \ndeliver\n event. In this\ncase, the ordering service must impose and convey a deterministic\nordering of the blobs within each block. The number of blobs in a block\nmay be chosen dynamically by an ordering service implementation.\n\n\nIn the following, for ease of presentation, we define ordering service\nproperties (rest of this subsection) and explain the workflow of\ntransaction endorsement (Section 2) assuming one blob per \ndeliver\n\nevent. These are easily extended to blocks, assuming that a \ndeliver\n\nevent for a block corresponds to a sequence of individual \ndeliver\n\nevents for each blob within a block, according to the above mentioned\ndeterministic ordering of blobs within a blocs.\n\n\nOrdering service properties\n\n\nThe guarantees of the ordering service (or atomic-broadcast channel)\nstipulate what happens to a broadcasted message and what relations exist\namong delivered messages. These guarantees are as follows:\n\n\n\n\n\n\nSafety (consistency guarantees)\n: As long as peers are connected\n    for sufficiently long periods of time to the channel (they can\n    disconnect or crash, but will restart and reconnect), they will see\n    an \nidentical\n series of delivered \n(seqno, prevhash, blob)\n\n    messages. This means the outputs (\ndeliver()\n events) occur in the\n    \nsame order\n on all peers and according to sequence number and carry\n    \nidentical content\n (\nblob\n and \nprevhash\n) for the same sequence\n    number. Note this is only a \nlogical order\n, and a\n    \ndeliver(seqno, prevhash, blob)\n on one peer is not required to\n    occur in any real-time relation to \ndeliver(seqno, prevhash, blob)\n\n    that outputs the same message at another peer. Put differently,\n    given a particular \nseqno\n, \nno\n two correct peers deliver\n    \ndifferent\n \nprevhash\n or \nblob\n values. Moreover, no value \nblob\n\n    is delivered unless some client (peer) actually called\n    \nbroadcast(blob)\n and, preferably, every broadcasted blob is only\n    delivered \nonce\n.\n\n\nFurthermore, the \ndeliver()\n event contains the cryptographic hash\nof the data in the previous \ndeliver()\n event (\nprevhash\n). When the\nordering service implements atomic broadcast guarantees, \nprevhash\n\nis the cryptographic hash of the parameters from the \ndeliver()\n\nevent with sequence number \nseqno-1\n. This establishes a hash chain\nacross \ndeliver()\n events, which is used to help verify the\nintegrity of the ordering service output, as discussed in Sections 4\nand 5 later. In the special case of the first \ndeliver()\n event,\n\nprevhash\n has a default value.\n\n\n\n\n\n\nLiveness (delivery guarantee)\n: Liveness guarantees of the\n    ordering service are specified by a ordering service implementation.\n    The exact guarantees may depend on the network and node fault model.\n\n\nIn principle, if the submitting client does not fail, the ordering\nservice should guarantee that every correct peer that connects to\nthe ordering service eventually delivers every submitted\ntransaction.\n\n\n\n\n\n\nTo summarize, the ordering service ensures the following properties:\n\n\n\n\nAgreement.\n For any two events at correct peers\n    \ndeliver(seqno, prevhash0, blob0)\n and\n    \ndeliver(seqno, prevhash1, blob1)\n with the same \nseqno\n,\n    \nprevhash0==prevhash1\n and \nblob0==blob1\n;\n\n\nHashchain integrity.\n For any two events at correct peers\n    \ndeliver(seqno-1, prevhash0, blob0)\n and\n    \ndeliver(seqno, prevhash, blob)\n,\n    \nprevhash = HASH(seqno-1||prevhash0||blob0)\n.\n\n\nNo skipping\n. If an ordering service outputs\n    \ndeliver(seqno, prevhash, blob)\n at a correct peer \np\n, such that\n    \nseqno\n0\n, then \np\n already delivered an event\n    \ndeliver(seqno-1, prevhash0, blob0)\n.\n\n\nNo creation\n. Any event \ndeliver(seqno, prevhash, blob)\n at a\n    correct peer must be preceded by a \nbroadcast(blob)\n event at some\n    (possibly distinct) peer;\n\n\nNo duplication (optional, yet desirable)\n. For any two events\n    \nbroadcast(blob)\n and \nbroadcast(blob')\n, when two events\n    \ndeliver(seqno0, prevhash0, blob)\n and\n    \ndeliver(seqno1, prevhash1, blob')\n occur at correct peers and\n    \nblob == blob'\n, then \nseqno0==seqno1\n and \nprevhash0==prevhash1\n.\n\n\nLiveness\n. If a correct client invokes an event \nbroadcast(blob)\n\n    then every correct peer \\\"eventually\\\" issues an event\n    \ndeliver(*, *, blob)\n, where \n*\n denotes an arbitrary value.\n\n\n\n\n2. Basic workflow of transaction endorsement\n\n\nIn the following we outline the high-level request flow for a\ntransaction.\n\n\nRemark:\n \nNotice that the following protocol\ndoes not* assume that\nall transactions are deterministic, i.e., it allows for\nnon-deterministic transactions.*\n\n\n2.1. The client creates a transaction and sends it to endorsing peers of its choice\n\n\nTo invoke a transaction, the client sends a \nPROPOSE\n message to a set\nof endorsing peers of its choice (possibly not at the same time - see\nSections 2.1.2. and 2.3.). The set of endorsing peers for a given\n\nchaincodeID\n is made available to client via peer, which in turn knows\nthe set of endorsing peers from endorsement policy (see Section 3). For\nexample, the transaction could be sent to \nall\n endorsers of a given\n\nchaincodeID\n. That said, some endorsers could be offline, others may\nobject and choose not to endorse the transaction. The submitting client\ntries to satisfy the policy expression with the endorsers available.\n\n\nIn the following, we first detail \nPROPOSE\n message format and then\ndiscuss possible patterns of interaction between submitting client and\nendorsers.\n\n\n2.1.1. \nPROPOSE\n message format\n\n\nThe format of a \nPROPOSE\n message is \nPROPOSE,tx,[anchor]\n, where \ntx\n\nis a mandatory and \nanchor\n optional argument explained in the\nfollowing.\n\n\n\n\n\n\ntx=\nclientID,chaincodeID,txPayload,timestamp,clientSig\n, where\n\n\n\n\nclientID\n is an ID of the submitting client,\n\n\nchaincodeID\n refers to the chaincode to which the transaction\n    pertains,\n\n\ntxPayload\n is the payload containing the submitted transaction\n    itself,\n\n\ntimestamp\n is a monotonically increasing (for every new\n    transaction) integer maintained by the client,\n\n\nclientSig\n is signature of a client on other fields of \ntx\n.\n\n\n\n\nThe details of \ntxPayload\n will differ between invoke transactions\nand deploy transactions (i.e., invoke transactions referring to a\ndeploy-specific system chaincode). For an \ninvoke transaction\n,\n\ntxPayload\n would consist of two fields\n\n\n\n\ntxPayload = \noperation, metadata\n, where\n\n\noperation\n denotes the chaincode operation (function) and\n    arguments,\n\n\nmetadata\n denotes attributes related to the invocation.\n\n\n\n\n\n\n\n\nFor a \ndeploy transaction\n, \ntxPayload\n would consist of three\nfields\n\n\n\n\ntxPayload = \nsource, metadata, policies\n, where\n\n\nsource\n denotes the source code of the chaincode,\n\n\nmetadata\n denotes attributes related to the chaincode and\n    application,\n\n\npolicies\n contains policies related to the chaincode that\n    are accessible to all peers, such as the endorsement policy.\n    Note that endorsement policies are not supplied with\n    \ntxPayload\n in a \ndeploy\n transaction, but \ntxPayload\n of a\n    \ndeploy\n contains endorsement policy ID and its parameters\n    (see Section 3).\n\n\n\n\n\n\n\n\n\n\n\n\nanchor\n contains \nread version dependencies\n, or more specifically,\n    key-version pairs (i.e., \nanchor\n is a subset of \nKxN\n), that binds\n    or \\\"anchors\\\" the \nPROPOSE\n request to specified versions of keys\n    in a KVS (see Section 1.2.). If the client specifies the \nanchor\n\n    argument, an endorser endorses a transaction only upon \nread\n\n    version numbers of corresponding keys in its local KVS match\n    \nanchor\n (see Section 2.2. for more details).\n\n\n\n\n\n\nCryptographic hash of \ntx\n is used by all nodes as a unique transaction\nidentifier \ntid\n (i.e., \ntid=HASH(tx)\n). The client stores \ntid\n in\nmemory and waits for responses from endorsing peers.\n\n\n2.1.2. Message patterns\n\n\nThe client decides on the sequence of interaction with endorsers. For\nexample, a client would typically send \nPROPOSE, tx\n (i.e., without\nthe \nanchor\n argument) to a single endorser, which would then produce\nthe version dependencies (\nanchor\n) which the client can later on use as\nan argument of its \nPROPOSE\n message to other endorsers. As another\nexample, the client could directly send \nPROPOSE, tx\n (without\n\nanchor\n) to all endorsers of its choice. Different patterns of\ncommunication are possible and client is free to decide on those (see\nalso Section 2.3.).\n\n\n2.2. The endorsing peer simulates a transaction and produces an endorsement signature\n\n\nOn reception of a \nPROPOSE,tx,[anchor]\n message from a client, the\nendorsing peer \nepID\n first verifies the client\\'s signature \nclientSig\n\nand then simulates a transaction. If the client specifies \nanchor\n then\nendorsing peer simulates the transactions only upon read version numbers\n(i.e., \nreadset\n as defined below) of corresponding keys in its local\nKVS match those version numbers specified by \nanchor\n.\n\n\nSimulating a transaction involves endorsing peer tentatively \nexecuting\n\na transaction (\ntxPayload\n), by invoking the chaincode to which the\ntransaction refers (\nchaincodeID\n) and the copy of the state that the\nendorsing peer locally holds.\n\n\nAs a result of the execution, the endorsing peer computes \nread version\ndependencies\n (\nreadset\n) and \nstate updates\n (\nwriteset\n), also called\n\nMVCC+postimage info\n in DB language.\n\n\nRecall that the state consists of key/value (k/v) pairs. All k/v entries\nare versioned, that is, every entry contains ordered version\ninformation, which is incremented every time when the value stored under\na key is updated. The peer that interprets the transaction records all\nk/v pairs accessed by the chaincode, either for reading or for writing,\nbut the peer does not yet update its state. More specifically:\n\n\n\n\nGiven state \ns\n before an endorsing peer executes a transaction, for\n    every key \nk\n read by the transaction, pair \n(k,s(k).version)\n is\n    added to \nreadset\n.\n\n\nAdditionally, for every key \nk\n modified by the transaction to the\n    new value \nv'\n, pair \n(k,v')\n is added to \nwriteset\n. Alternatively,\n    \nv'\n could be the delta of the new value to previous value\n    (\ns(k).value\n).\n\n\n\n\nIf a client specifies \nanchor\n in the \nPROPOSE\n message then client\nspecified \nanchor\n must equal \nreadset\n produced by endorsing peer when\nsimulating the transaction.\n\n\nThen, the peer forwards internally \ntran-proposal\n (and possibly \ntx\n)\nto the part of its (peer\\'s) logic that endorses a transaction, referred\nto as \nendorsing logic\n. By default, endorsing logic at a peer accepts\nthe \ntran-proposal\n and simply signs the \ntran-proposal\n. However,\nendorsing logic may interpret arbitrary functionality, to, e.g.,\ninteract with legacy systems with \ntran-proposal\n and \ntx\n as inputs to\nreach the decision whether to endorse a transaction or not.\n\n\nIf endorsing logic decides to endorse a transaction, it sends\n\nTRANSACTION-ENDORSED, tid, tran-proposal,epSig\n message to the\nsubmitting client(\ntx.clientID\n), where:\n\n\n\n\n\n\ntran-proposal := (epID,tid,chaincodeID,txContentBlob,readset,writeset)\n,\n\n\nwhere \ntxContentBlob\n is chaincode/transaction specific information.\nThe intention is to have \ntxContentBlob\n used as some representation\nof \ntx\n (e.g., \ntxContentBlob=tx.txPayload\n).\n\n\n\n\n\n\nepSig\n is the endorsing peer\\'s signature on \ntran-proposal\n\n\n\n\n\n\nElse, in case the endorsing logic refuses to endorse the transaction, an\nendorser \nmay\n send a message \n(TRANSACTION-INVALID, tid, REJECTED)\n to\nthe submitting client.\n\n\nNotice that an endorser does not change its state in this step, the\nupdates produced by transaction simulation in the context of endorsement\ndo not affect the state!\n\n\n2.3. The submitting client collects an endorsement for a transaction and broadcasts it through ordering service\n\n\nThe submitting client waits until it receives \\\"enough\\\" messages and\nsignatures on \n(TRANSACTION-ENDORSED, tid, *, *)\n statements to conclude\nthat the transaction proposal is endorsed. As discussed in Section\n2.1.2., this may involve one or more round-trips of interaction with\nendorsers.\n\n\nThe exact number of \\\"enough\\\" depend on the chaincode endorsement\npolicy (see also Section 3). If the endorsement policy is satisfied, the\ntransaction has been \nendorsed\n; note that it is not yet committed. The\ncollection of signed \nTRANSACTION-ENDORSED\n messages from endorsing\npeers which establish that a transaction is endorsed is called an\n\nendorsement\n and denoted by \nendorsement\n.\n\n\nIf the submitting client does not manage to collect an endorsement for a\ntransaction proposal, it abandons this transaction with an option to\nretry later.\n\n\nFor transaction with a valid endorsement, we now start using the\nordering service. The submitting client invokes ordering service using\nthe \nbroadcast(blob)\n, where \nblob=endorsement\n. If the client does not\nhave capability of invoking ordering service directly, it may proxy its\nbroadcast through some peer of its choice. Such a peer must be trusted\nby the client not to remove any message from the \nendorsement\n or\notherwise the transaction may be deemed invalid. Notice that, however, a\nproxy peer may not fabricate a valid \nendorsement\n.\n\n\n2.4. The ordering service delivers a transactions to the peers\n\n\nWhen an event \ndeliver(seqno, prevhash, blob)\n occurs and a peer has\napplied all state updates for blobs with sequence number lower than\n\nseqno\n, a peer does the following:\n\n\n\n\nIt checks that the \nblob.endorsement\n is valid according to the\n    policy of the chaincode (\nblob.tran-proposal.chaincodeID\n) to which\n    it refers.\n\n\nIn a typical case, it also verifies that the dependencies\n    (\nblob.endorsement.tran-proposal.readset\n) have not been violated\n    meanwhile. In more complex use cases, \ntran-proposal\n fields in\n    endorsement may differ and in this case endorsement policy (Section\n    3)  specifies how the state evolves.\n\n\n\n\nVerification of dependencies can be implemented in different ways,\naccording to a consistency property or \\\"isolation guarantee\\\" that is\nchosen for the state updates. \nSerializability\n is a default isolation\nguarantee, unless chaincode endorsement policy specifies a different\none. Serializability can be provided by requiring the version associated\nwith \nevery\n key in the \nreadset\n to be equal to that key\\'s version in\nthe state, and rejecting transactions that do not satisfy this\nrequirement.\n\n\n\n\nIf all these checks pass, the transaction is deemed \nvalid\n or\n    \ncommitted\n. In this case, the peer marks the transaction with 1 in\n    the bitmask of the \nPeerLedger\n, applies\n    \nblob.endorsement.tran-proposal.writeset\n to blockchain state (if\n    \ntran-proposals\n are the same, otherwise endorsement policy logic\n    defines the function that takes \nblob.endorsement\n).\n\n\nIf the endorsement policy verification of \nblob.endorsement\n fails,\n    the transaction is invalid and the peer marks the transaction with 0\n    in the bitmask of the \nPeerLedger\n. It is important to note that\n    invalid transactions do not change the state.\n\n\n\n\nNote that this is sufficient to have all (correct) peers have the same\nstate after processing a deliver event (block) with a given sequence\nnumber. Namely, by the guarantees of the ordering service, all correct\npeers will receive an identical sequence of\n\ndeliver(seqno, prevhash, blob)\n events. As the evaluation of the\nendorsement policy and evaluation of version dependencies in \nreadset\n\nare deterministic, all correct peers will also come to the same\nconclusion whether a transaction contained in a blob is valid. Hence,\nall peers commit and apply the same sequence of transactions and update\ntheir state in the same way.\n\n\n\n\nFigure 1. Illustration of one possible transaction flow (common-case\npath).\n\n\n3. Endorsement policies\n\n\n3.1. Endorsement policy specification\n\n\nAn \nendorsement policy\n, is a condition on what \nendorses\n a\ntransaction. Blockchain peers have a pre-specified set of endorsement\npolicies, which are referenced by a \ndeploy\n transaction that installs\nspecific chaincode. Endorsement policies can be parametrized, and these\nparameters can be specified by a \ndeploy\n transaction.\n\n\nTo guarantee blockchain and security properties, the set of endorsement\npolicies \nshould be a set of proven policies\n with limited set of\nfunctions in order to ensure bounded execution time (termination),\ndeterminism, performance and security guarantees.\n\n\nDynamic addition of endorsement policies (e.g., by \ndeploy\n transaction\non chaincode deploy time) is very sensitive in terms of bounded policy\nevaluation time (termination), determinism, performance and security\nguarantees. Therefore, dynamic addition of endorsement policies is not\nallowed, but can be supported in future.\n\n\n3.2. Transaction evaluation against endorsement policy\n\n\nA transaction is declared valid only if it has been endorsed according\nto the policy. An invoke transaction for a chaincode will first have to\nobtain an \nendorsement\n that satisfies the chaincode\\'s policy or it\nwill not be committed. This takes place through the interaction between\nthe submitting client and endorsing peers as explained in Section 2.\n\n\nFormally the endorsement policy is a predicate on the endorsement, and\npotentially further state that evaluates to TRUE or FALSE. For deploy\ntransactions the endorsement is obtained according to a system-wide\npolicy (for example, from the system chaincode).\n\n\nAn endorsement policy predicate refers to certain variables. Potentially\nit may refer to:\n\n\n\n\nkeys or identities relating to the chaincode (found in the metadata\n    of the chaincode), for example, a set of endorsers;\n\n\nfurther metadata of the chaincode;\n\n\nelements of the \nendorsement\n and \nendorsement.tran-proposal\n;\n\n\nand potentially more.\n\n\n\n\nThe above list is ordered by increasing expressiveness and complexity,\nthat is, it will be relatively simple to support policies that only\nrefer to keys and identities of nodes.\n\n\nThe evaluation of an endorsement policy predicate must be\ndeterministic.\n An endorsement shall be evaluated locally by every peer\nsuch that a peer does \nnot\n need to interact with other peers, yet all\ncorrect peers evaluate the endorsement policy in the same way.\n\n\n3.3. Example endorsement policies\n\n\nThe predicate may contain logical expressions and evaluates to TRUE or\nFALSE. Typically the condition will use digital signatures on the\ntransaction invocation issued by endorsing peers for the chaincode.\n\n\nSuppose the chaincode specifies the endorser set\n\nE = {Alice, Bob, Charlie, Dave, Eve, Frank, George}\n. Some example\npolicies:\n\n\n\n\nA valid signature from on the same \ntran-proposal\n from all members\n    of E.\n\n\nA valid signature from any single member of E.\n\n\nValid signatures on the same \ntran-proposal\n from endorsing peers\n    according to the condition\n    \n(Alice OR Bob) AND (any two of: Charlie, Dave, Eve, Frank, George)\n.\n\n\nValid signatures on the same \ntran-proposal\n by any 5 out of the 7\n    endorsers. (More generally, for chaincode with \nn \n 3f\n endorsers,\n    valid signatures by any \n2f+1\n out of the \nn\n endorsers, or by any\n    group of \nmore\n than \n(n+f)/2\n endorsers.)\n\n\nSuppose there is an assignment of \\\"stake\\\" or \\\"weights\\\" to the\n    endorsers, like\n    \n{Alice=49, Bob=15, Charlie=15, Dave=10, Eve=7, Frank=3, George=1}\n,\n    where the total stake is 100: The policy requires valid signatures\n    from a set that has a majority of the stake (i.e., a group with\n    combined stake strictly more than 50), such as \n{Alice, X}\n with any\n    \nX\n different from George, or \n{everyone together except Alice}\n.\n    And so on.\n\n\nThe assignment of stake in the previous example condition could be\n    static (fixed in the metadata of the chaincode) or dynamic (e.g.,\n    dependent on the state of the chaincode and be modified during the\n    execution).\n\n\nValid signatures from (Alice OR Bob) on \ntran-proposal1\n and valid\n    signatures from \n(any two of: Charlie, Dave, Eve, Frank, George)\n on\n    \ntran-proposal2\n, where \ntran-proposal1\n and \ntran-proposal2\n differ\n    only in their endorsing peers and state updates.\n\n\n\n\nHow useful these policies are will depend on the application, on the\ndesired resilience of the solution against failures or misbehavior of\nendorsers, and on various other properties.\n\n\n4 (post-v1). Validated ledger and \nPeerLedger\n checkpointing (pruning)\n\n\n4.1. Validated ledger (VLedger)\n\n\nTo maintain the abstraction of a ledger that contains only valid and\ncommitted transactions (that appears in Bitcoin, for example), peers\nmay, in addition to state and Ledger, maintain the \nValidated Ledger (or\nVLedger)\n. This is a hash chain derived from the ledger by filtering out\ninvalid transactions.\n\n\nThe construction of the VLedger blocks (called here \nvBlocks\n) proceeds\nas follows. As the \nPeerLedger\n blocks may contain invalid transactions\n(i.e., transactions with invalid endorsement or with invalid version\ndependencies), such transactions are filtered out by peers before a\ntransaction from a block becomes added to a vBlock. Every peer does this\nby itself (e.g., by using the bitmask associated with \nPeerLedger\n). A\nvBlock is defined as a block without the invalid transactions, that have\nbeen filtered out. Such vBlocks are inherently dynamic in size and may\nbe empty. An illustration of vBlock construction is given in the figure\nbelow.\n\n\n\n\nFigure 2. Illustration of validated ledger block (vBlock) formation\nfrom ledger (PeerLedger) blocks.\n\n\nvBlocks are chained together to a hash chain by every peer. More\nspecifically, every block of a validated ledger contains:\n\n\n\n\nThe hash of the previous vBlock.\n\n\nvBlock number.\n\n\nAn ordered list of all valid transactions committed by the peers\n    since the last vBlock was computed (i.e., list of valid transactions\n    in a corresponding block).\n\n\nThe hash of the corresponding block (in \nPeerLedger\n) from which the\n    current vBlock is derived.\n\n\n\n\nAll this information is concatenated and hashed by a peer, producing the\nhash of the vBlock in the validated ledger.\n\n\n4.2. \nPeerLedger\n Checkpointing\n\n\nThe ledger contains invalid transactions, which may not necessarily be\nrecorded forever. However, peers cannot simply discard \nPeerLedger\n\nblocks and thereby prune \nPeerLedger\n once they establish the\ncorresponding vBlocks. Namely, in this case, if a new peer joins the\nnetwork, other peers could not transfer the discarded blocks (pertaining\nto \nPeerLedger\n) to the joining peer, nor convince the joining peer of\nthe validity of their vBlocks.\n\n\nTo facilitate pruning of the \nPeerLedger\n, this document describes a\n\ncheckpointing\n mechanism. This mechanism establishes the validity of\nthe vBlocks across the peer network and allows checkpointed vBlocks to\nreplace the discarded \nPeerLedger\n blocks. This, in turn, reduces\nstorage space, as there is no need to store invalid transactions. It\nalso reduces the work to reconstruct the state for new peers that join\nthe network (as they do not need to establish validity of individual\ntransactions when reconstructing the state by replaying \nPeerLedger\n,\nbut may simply replay the state updates contained in the validated\nledger).\n\n\n4.2.1. Checkpointing protocol\n\n\nCheckpointing is performed periodically by the peers every \nCHK\n blocks,\nwhere \nCHK\n is a configurable parameter. To initiate a checkpoint, the\npeers broadcast (e.g., gossip) to other peers message\n\nCHECKPOINT,blocknohash,blockno,stateHash,peerSig\n, where \nblockno\n is\nthe current blocknumber and \nblocknohash\n is its respective hash,\n\nstateHash\n is the hash of the latest state (produced by e.g., a Merkle\nhash) upon validation of block \nblockno\n and \npeerSig\n is peer\\'s\nsignature on \n(CHECKPOINT,blocknohash,blockno,stateHash)\n, referring to\nthe validated ledger.\n\n\nA peer collects \nCHECKPOINT\n messages until it obtains enough correctly\nsigned messages with matching \nblockno\n, \nblocknohash\n and \nstateHash\n\nto establish a \nvalid checkpoint\n (see Section 4.2.2.).\n\n\nUpon establishing a valid checkpoint for block number \nblockno\n with\n\nblocknohash\n, a peer:\n\n\n\n\nif \nblockno\nlatestValidCheckpoint.blockno\n, then a peer assigns\n    \nlatestValidCheckpoint=(blocknohash,blockno)\n,\n\n\nstores the set of respective peer signatures that constitute a valid\n    checkpoint into the set \nlatestValidCheckpointProof\n,\n\n\nstores the state corresponding to \nstateHash\n to\n    \nlatestValidCheckpointedState\n,\n\n\n(optionally) prunes its \nPeerLedger\n up to block number \nblockno\n\n    (inclusive).\n\n\n\n\n4.2.2. Valid checkpoints\n\n\nClearly, the checkpointing protocol raises the following questions:\n\nWhen can a peer prune its \nPeerLedger\n? How many \nCHECKPOINT\n messages\nare \\\"sufficiently many\\\"?\n. This is defined by a \ncheckpoint validity\npolicy\n, with (at least) two possible approaches, which may also be\ncombined:\n\n\n\n\nLocal (peer-specific) checkpoint validity policy (LCVP).\n A local\n    policy at a given peer \np\n may specify a set of peers which peer \np\n\n    trusts and whose \nCHECKPOINT\n messages are sufficient to establish a\n    valid checkpoint. For example, LCVP at peer \nAlice\n may define that\n    \nAlice\n needs to receive \nCHECKPOINT\n message from Bob, or from\n    \nboth\n \nCharlie\n and \nDave\n.\n\n\nGlobal checkpoint validity policy (GCVP).\n A checkpoint validity\n    policy may be specified globally. This is similar to a local peer\n    policy, except that it is stipulated at the system (blockchain)\n    granularity, rather than peer granularity. For instance, GCVP may\n    specify that:\n\n\neach peer may trust a checkpoint if confirmed by \n11\n different\n    peers.\n\n\nin a specific deployment in which every orderer is collocated\n    with a peer in the same machine (i.e., trust domain) and where\n    up to \nf\n orderers may be (Byzantine) faulty, each peer may\n    trust a checkpoint if confirmed by \nf+1\n different peers\n    collocated with orderers.", 
            "title": "Architecture Explained"
        }, 
        {
            "location": "/arch-deep-dive/#architecture-explained", 
            "text": "The Hyperledger Fabric architecture delivers the following advantages:   Chaincode trust flexibility.  The architecture separates  trust\n    assumptions  for chaincodes (blockchain applications) from trust\n    assumptions for ordering. In other words, the ordering service may\n    be provided by one set of nodes (orderers) and tolerate some of them\n    to fail or misbehave, and the endorsers may be different for each\n    chaincode.  Scalability.  As the endorser nodes responsible for particular\n    chaincode are orthogonal to the orderers, the system may  scale \n    better than if these functions were done by the same nodes. In\n    particular, this results when different chaincodes specify disjoint\n    endorsers, which introduces a partitioning of chaincodes between\n    endorsers and allows parallel chaincode execution (endorsement).\n    Besides, chaincode execution, which can potentially be costly, is\n    removed from the critical path of the ordering service.  Confidentiality.  The architecture facilitates deployment of\n    chaincodes that have  confidentiality  requirements with respect to\n    the content and state updates of its transactions.  Consensus modularity.  The architecture is  modular  and allows\n    pluggable consensus (i.e., ordering service) implementations.   Part I: Elements of the architecture relevant to Hyperledger Fabric\nv1   System architecture  Basic workflow of transaction endorsement  Endorsement policies   Part II: Post-v1 elements of the architecture   Ledger checkpointing (pruning)  System architecture    The blockchain is a distributed system consisting of many nodes that\ncommunicate with each other. The blockchain runs programs called\nchaincode, holds state and ledger data, and executes transactions. The\nchaincode is the central element as transactions are operations invoked\non the chaincode. Transactions have to be \\\"endorsed\\\" and only endorsed\ntransactions may be committed and have an effect on the state. There may\nexist one or more special chaincodes for management functions and\nparameters, collectively called  system chaincodes .", 
            "title": "Architecture Explained"
        }, 
        {
            "location": "/arch-deep-dive/#11-transactions", 
            "text": "Transactions may be of two types:   Deploy transactions  create new chaincode and take a program as\n    parameter. When a deploy transaction executes successfully, the\n    chaincode has been installed \\\"on\\\" the blockchain.  Invoke transactions  perform an operation in the context of\n    previously deployed chaincode. An invoke transaction refers to a\n    chaincode and to one of its provided functions. When successful, the\n    chaincode executes the specified function - which may involve\n    modifying the corresponding state, and returning an output.   As described later, deploy transactions are special cases of invoke\ntransactions, where a deploy transaction that creates new chaincode,\ncorresponds to an invoke transaction on a system chaincode.  Remark:   This document currently assumes that a transaction either\ncreates new chaincode or invokes an operation provided by an already\ndeployed chaincode. This document does not yet describe: a)\noptimizations for query (read-only) transactions, b)\nsupport for cross-chaincode transactions.", 
            "title": "1.1. Transactions"
        }, 
        {
            "location": "/arch-deep-dive/#12-blockchain-data-structures", 
            "text": "", 
            "title": "1.2. Blockchain data structures"
        }, 
        {
            "location": "/arch-deep-dive/#121-state", 
            "text": "The latest state of the blockchain (or, simply,  state ) is modeled as a\nversioned key/value store (KVS), where keys are names and values are\narbitrary blobs. These entries are manipulated by the chaincodes\n(applications) running on the blockchain through  put  and  get \nKVS-operations. The state is stored persistently and updates to the\nstate are logged. Notice that versioned KVS is adopted as state model,\nan implementation may use actual KVSs, but also RDBMSs or any other\nsolution.  More formally, state  s  is modeled as an element of a mapping K -  (V X N) , where:   K  is a set of keys  V  is a set of values  N  is an infinite ordered set of version numbers. Injective\n    function  next: N -  N  takes an element of  N  and returns the next\n    version number.   Both  V  and  N  contain a special element  \\bot , which is in case of N  the lowest element. Initially all keys are mapped to  (\\bot,\\bot) .\nFor  s(k)=(v,ver)  we denote  v  by  s(k).value , and  ver  by s(k).version .  KVS operations are modeled as follows:   put(k,v) , for  k\\in K  and  v\\in V , takes the blockchain state\n     s  and changes it to  s'  such that  s'(k)=(v,next(s(k).version)) \n    with  s'(k')=s(k')  for all  k'!=k .  get(k)  returns  s(k) .   State is maintained by peers, but not by orderers and clients.  State partitioning.  Keys in the KVS can be recognized from their\nname to belong to a particular chaincode, in the sense that only\ntransaction of a certain chaincode may modify the keys belonging to this\nchaincode. In principle, any chaincode can read the keys belonging to\nanother chaincode.  Support for cross-chaincode transactions, that modify\nthe state belonging to two or more chaincodes is a post-v1 feature.", 
            "title": "1.2.1. State"
        }, 
        {
            "location": "/arch-deep-dive/#122-ledger", 
            "text": "Ledger provides a verifiable history of all successful state changes (we\ntalk about  valid  transactions) and unsuccessful attempts to change\nstate (we talk about  invalid  transactions), occurring during the\noperation of the system.  Ledger is constructed by the ordering service (see Sec 1.3.3) as a\ntotally ordered hashchain of  blocks  of (valid or invalid)\ntransactions. The hashchain imposes the total order of blocks in a\nledger and each block contains an array of totally ordered transactions.\nThis imposes total order across all transactions.  Ledger is kept at all peers and, optionally, at a subset of orderers. In\nthe context of an orderer we refer to the Ledger as to  OrdererLedger ,\nwhereas in the context of a peer we refer to the ledger as to PeerLedger .  PeerLedger  differs from the  OrdererLedger  in that\npeers locally maintain a bitmask that tells apart valid transactions\nfrom invalid ones (see Section XX for more details).  Peers may prune  PeerLedger  as described in Section XX (post-v1\nfeature). Orderers maintain  OrdererLedger  for fault-tolerance and\navailability (of the  PeerLedger ) and may decide to prune it at\nanytime, provided that properties of the ordering service (see Sec.\n1.3.3) are maintained.  The ledger allows peers to replay the history of all transactions and to\nreconstruct the state. Therefore, state as described in Sec 1.2.1 is an\noptional datastructure.", 
            "title": "1.2.2 Ledger"
        }, 
        {
            "location": "/arch-deep-dive/#13-nodes", 
            "text": "Nodes are the communication entities of the blockchain. A \\\"node\\\" is\nonly a logical function in the sense that multiple nodes of different\ntypes can run on the same physical server. What counts is how nodes are\ngrouped in \\\"trust domains\\\" and associated to logical entities that\ncontrol them.  There are three types of nodes:   Client  or  submitting-client : a client that submits an actual\n    transaction-invocation to the endorsers, and broadcasts\n    transaction-proposals to the ordering service.  Peer : a node that commits transactions and maintains the state\n    and a copy of the ledger (see Sec, 1.2). Besides, peers can have a\n    special  endorser  role.  Ordering-service-node  or  orderer : a node running the\n    communication service that implements a delivery guarantee, such as\n    atomic or total order broadcast.   The types of nodes are explained next in more detail.", 
            "title": "1.3. Nodes"
        }, 
        {
            "location": "/arch-deep-dive/#131-client", 
            "text": "The client represents the entity that acts on behalf of an end-user. It\nmust connect to a peer for communicating with the blockchain. The client\nmay connect to any peer of its choice. Clients create and thereby invoke\ntransactions.  As detailed in Section 2, clients communicate with both peers and the\nordering service.", 
            "title": "1.3.1. Client"
        }, 
        {
            "location": "/arch-deep-dive/#132-peer", 
            "text": "A peer receives ordered state updates in the form of  blocks  from the\nordering service and maintain the state and the ledger.  Peers can additionally take up a special role of an  endorsing peer ,\nor an  endorser . The special function of an  endorsing peer  occurs\nwith respect to a particular chaincode and consists in  endorsing  a\ntransaction before it is committed. Every chaincode may specify an endorsement policy  that may refer to a set of endorsing peers. The\npolicy defines the necessary and sufficient conditions for a valid\ntransaction endorsement (typically a set of endorsers\\' signatures), as\ndescribed later in Sections 2 and 3. In the special case of deploy\ntransactions that install new chaincode the (deployment) endorsement\npolicy is specified as an endorsement policy of the system chaincode.", 
            "title": "1.3.2. Peer"
        }, 
        {
            "location": "/arch-deep-dive/#133-ordering-service-nodes-orderers", 
            "text": "The  orderers  form the  ordering service , i.e., a communication fabric\nthat provides delivery guarantees. The ordering service can be\nimplemented in different ways: ranging from a centralized service (used\ne.g., in development and testing) to distributed protocols that target\ndifferent network and node fault models.  Ordering service provides a shared  communication channel  to clients\nand peers, offering a broadcast service for messages containing\ntransactions. Clients connect to the channel and may broadcast messages\non the channel which are then delivered to all peers. The channel\nsupports  atomic  delivery of all messages, that is, message\ncommunication with total-order delivery and (implementation specific)\nreliability. In other words, the channel outputs the same messages to\nall connected peers and outputs them to all peers in the same logical\norder. This atomic communication guarantee is also called  total-order\nbroadcast ,  atomic broadcast , or  consensus  in the context of\ndistributed systems. The communicated messages are the candidate\ntransactions for inclusion in the blockchain state.  Partitioning (ordering service channels).  Ordering service may\nsupport multiple  channels  similar to the  topics  of a\npublish/subscribe (pub/sub) messaging system. Clients can connect to a\ngiven channel and can then send messages and obtain the messages that\narrive. Channels can be thought of as partitions - clients connecting to\none channel are unaware of the existence of other channels, but clients\nmay connect to multiple channels. Even though some ordering service\nimplementations included with Hyperledger Fabric support multiple\nchannels, for simplicity of presentation, in the rest of this document,\nwe assume ordering service consists of a single channel/topic.  Ordering service API.  Peers connect to the channel provided by the\nordering service, via the interface provided by the ordering service.\nThe ordering service API consists of two basic operations (more\ngenerally  asynchronous events ):  TODO  add the part of the API for fetching particular blocks under\nclient/peer specified sequence numbers.   broadcast(blob) : a client calls this to broadcast an arbitrary\n    message  blob  for dissemination over the channel. This is also\n    called  request(blob)  in the BFT context, when sending a request to\n    a service.  deliver(seqno, prevhash, blob) : the ordering service calls this on\n    the peer to deliver the message  blob  with the specified\n    non-negative integer sequence number ( seqno ) and hash of the most\n    recently delivered blob ( prevhash ). In other words, it is an\n    output event from the ordering service.  deliver()  is also\n    sometimes called  notify()  in pub-sub systems or  commit()  in BFT\n    systems.   Ledger and block formation.  The ledger (see also Sec. 1.2.2)\ncontains all data output by the ordering service. In a nutshell, it is a\nsequence of  deliver(seqno, prevhash, blob)  events, which form a hash\nchain according to the computation of  prevhash  described before.  Most of the time, for efficiency reasons, instead of outputting\nindividual transactions (blobs), the ordering service will group (batch)\nthe blobs and output  blocks  within a single  deliver  event. In this\ncase, the ordering service must impose and convey a deterministic\nordering of the blobs within each block. The number of blobs in a block\nmay be chosen dynamically by an ordering service implementation.  In the following, for ease of presentation, we define ordering service\nproperties (rest of this subsection) and explain the workflow of\ntransaction endorsement (Section 2) assuming one blob per  deliver \nevent. These are easily extended to blocks, assuming that a  deliver \nevent for a block corresponds to a sequence of individual  deliver \nevents for each blob within a block, according to the above mentioned\ndeterministic ordering of blobs within a blocs.  Ordering service properties  The guarantees of the ordering service (or atomic-broadcast channel)\nstipulate what happens to a broadcasted message and what relations exist\namong delivered messages. These guarantees are as follows:    Safety (consistency guarantees) : As long as peers are connected\n    for sufficiently long periods of time to the channel (they can\n    disconnect or crash, but will restart and reconnect), they will see\n    an  identical  series of delivered  (seqno, prevhash, blob) \n    messages. This means the outputs ( deliver()  events) occur in the\n     same order  on all peers and according to sequence number and carry\n     identical content  ( blob  and  prevhash ) for the same sequence\n    number. Note this is only a  logical order , and a\n     deliver(seqno, prevhash, blob)  on one peer is not required to\n    occur in any real-time relation to  deliver(seqno, prevhash, blob) \n    that outputs the same message at another peer. Put differently,\n    given a particular  seqno ,  no  two correct peers deliver\n     different   prevhash  or  blob  values. Moreover, no value  blob \n    is delivered unless some client (peer) actually called\n     broadcast(blob)  and, preferably, every broadcasted blob is only\n    delivered  once .  Furthermore, the  deliver()  event contains the cryptographic hash\nof the data in the previous  deliver()  event ( prevhash ). When the\nordering service implements atomic broadcast guarantees,  prevhash \nis the cryptographic hash of the parameters from the  deliver() \nevent with sequence number  seqno-1 . This establishes a hash chain\nacross  deliver()  events, which is used to help verify the\nintegrity of the ordering service output, as discussed in Sections 4\nand 5 later. In the special case of the first  deliver()  event, prevhash  has a default value.    Liveness (delivery guarantee) : Liveness guarantees of the\n    ordering service are specified by a ordering service implementation.\n    The exact guarantees may depend on the network and node fault model.  In principle, if the submitting client does not fail, the ordering\nservice should guarantee that every correct peer that connects to\nthe ordering service eventually delivers every submitted\ntransaction.    To summarize, the ordering service ensures the following properties:   Agreement.  For any two events at correct peers\n     deliver(seqno, prevhash0, blob0)  and\n     deliver(seqno, prevhash1, blob1)  with the same  seqno ,\n     prevhash0==prevhash1  and  blob0==blob1 ;  Hashchain integrity.  For any two events at correct peers\n     deliver(seqno-1, prevhash0, blob0)  and\n     deliver(seqno, prevhash, blob) ,\n     prevhash = HASH(seqno-1||prevhash0||blob0) .  No skipping . If an ordering service outputs\n     deliver(seqno, prevhash, blob)  at a correct peer  p , such that\n     seqno 0 , then  p  already delivered an event\n     deliver(seqno-1, prevhash0, blob0) .  No creation . Any event  deliver(seqno, prevhash, blob)  at a\n    correct peer must be preceded by a  broadcast(blob)  event at some\n    (possibly distinct) peer;  No duplication (optional, yet desirable) . For any two events\n     broadcast(blob)  and  broadcast(blob') , when two events\n     deliver(seqno0, prevhash0, blob)  and\n     deliver(seqno1, prevhash1, blob')  occur at correct peers and\n     blob == blob' , then  seqno0==seqno1  and  prevhash0==prevhash1 .  Liveness . If a correct client invokes an event  broadcast(blob) \n    then every correct peer \\\"eventually\\\" issues an event\n     deliver(*, *, blob) , where  *  denotes an arbitrary value.", 
            "title": "1.3.3. Ordering service nodes (Orderers)"
        }, 
        {
            "location": "/arch-deep-dive/#2-basic-workflow-of-transaction-endorsement", 
            "text": "In the following we outline the high-level request flow for a\ntransaction.  Remark:   Notice that the following protocol does not* assume that\nall transactions are deterministic, i.e., it allows for\nnon-deterministic transactions.*", 
            "title": "2. Basic workflow of transaction endorsement"
        }, 
        {
            "location": "/arch-deep-dive/#21-the-client-creates-a-transaction-and-sends-it-to-endorsing-peers-of-its-choice", 
            "text": "To invoke a transaction, the client sends a  PROPOSE  message to a set\nof endorsing peers of its choice (possibly not at the same time - see\nSections 2.1.2. and 2.3.). The set of endorsing peers for a given chaincodeID  is made available to client via peer, which in turn knows\nthe set of endorsing peers from endorsement policy (see Section 3). For\nexample, the transaction could be sent to  all  endorsers of a given chaincodeID . That said, some endorsers could be offline, others may\nobject and choose not to endorse the transaction. The submitting client\ntries to satisfy the policy expression with the endorsers available.  In the following, we first detail  PROPOSE  message format and then\ndiscuss possible patterns of interaction between submitting client and\nendorsers.", 
            "title": "2.1. The client creates a transaction and sends it to endorsing peers of its choice"
        }, 
        {
            "location": "/arch-deep-dive/#211-propose-message-format", 
            "text": "The format of a  PROPOSE  message is  PROPOSE,tx,[anchor] , where  tx \nis a mandatory and  anchor  optional argument explained in the\nfollowing.    tx= clientID,chaincodeID,txPayload,timestamp,clientSig , where   clientID  is an ID of the submitting client,  chaincodeID  refers to the chaincode to which the transaction\n    pertains,  txPayload  is the payload containing the submitted transaction\n    itself,  timestamp  is a monotonically increasing (for every new\n    transaction) integer maintained by the client,  clientSig  is signature of a client on other fields of  tx .   The details of  txPayload  will differ between invoke transactions\nand deploy transactions (i.e., invoke transactions referring to a\ndeploy-specific system chaincode). For an  invoke transaction , txPayload  would consist of two fields   txPayload =  operation, metadata , where  operation  denotes the chaincode operation (function) and\n    arguments,  metadata  denotes attributes related to the invocation.     For a  deploy transaction ,  txPayload  would consist of three\nfields   txPayload =  source, metadata, policies , where  source  denotes the source code of the chaincode,  metadata  denotes attributes related to the chaincode and\n    application,  policies  contains policies related to the chaincode that\n    are accessible to all peers, such as the endorsement policy.\n    Note that endorsement policies are not supplied with\n     txPayload  in a  deploy  transaction, but  txPayload  of a\n     deploy  contains endorsement policy ID and its parameters\n    (see Section 3).       anchor  contains  read version dependencies , or more specifically,\n    key-version pairs (i.e.,  anchor  is a subset of  KxN ), that binds\n    or \\\"anchors\\\" the  PROPOSE  request to specified versions of keys\n    in a KVS (see Section 1.2.). If the client specifies the  anchor \n    argument, an endorser endorses a transaction only upon  read \n    version numbers of corresponding keys in its local KVS match\n     anchor  (see Section 2.2. for more details).    Cryptographic hash of  tx  is used by all nodes as a unique transaction\nidentifier  tid  (i.e.,  tid=HASH(tx) ). The client stores  tid  in\nmemory and waits for responses from endorsing peers.", 
            "title": "2.1.1. PROPOSE message format"
        }, 
        {
            "location": "/arch-deep-dive/#212-message-patterns", 
            "text": "The client decides on the sequence of interaction with endorsers. For\nexample, a client would typically send  PROPOSE, tx  (i.e., without\nthe  anchor  argument) to a single endorser, which would then produce\nthe version dependencies ( anchor ) which the client can later on use as\nan argument of its  PROPOSE  message to other endorsers. As another\nexample, the client could directly send  PROPOSE, tx  (without anchor ) to all endorsers of its choice. Different patterns of\ncommunication are possible and client is free to decide on those (see\nalso Section 2.3.).", 
            "title": "2.1.2. Message patterns"
        }, 
        {
            "location": "/arch-deep-dive/#22-the-endorsing-peer-simulates-a-transaction-and-produces-an-endorsement-signature", 
            "text": "On reception of a  PROPOSE,tx,[anchor]  message from a client, the\nendorsing peer  epID  first verifies the client\\'s signature  clientSig \nand then simulates a transaction. If the client specifies  anchor  then\nendorsing peer simulates the transactions only upon read version numbers\n(i.e.,  readset  as defined below) of corresponding keys in its local\nKVS match those version numbers specified by  anchor .  Simulating a transaction involves endorsing peer tentatively  executing \na transaction ( txPayload ), by invoking the chaincode to which the\ntransaction refers ( chaincodeID ) and the copy of the state that the\nendorsing peer locally holds.  As a result of the execution, the endorsing peer computes  read version\ndependencies  ( readset ) and  state updates  ( writeset ), also called MVCC+postimage info  in DB language.  Recall that the state consists of key/value (k/v) pairs. All k/v entries\nare versioned, that is, every entry contains ordered version\ninformation, which is incremented every time when the value stored under\na key is updated. The peer that interprets the transaction records all\nk/v pairs accessed by the chaincode, either for reading or for writing,\nbut the peer does not yet update its state. More specifically:   Given state  s  before an endorsing peer executes a transaction, for\n    every key  k  read by the transaction, pair  (k,s(k).version)  is\n    added to  readset .  Additionally, for every key  k  modified by the transaction to the\n    new value  v' , pair  (k,v')  is added to  writeset . Alternatively,\n     v'  could be the delta of the new value to previous value\n    ( s(k).value ).   If a client specifies  anchor  in the  PROPOSE  message then client\nspecified  anchor  must equal  readset  produced by endorsing peer when\nsimulating the transaction.  Then, the peer forwards internally  tran-proposal  (and possibly  tx )\nto the part of its (peer\\'s) logic that endorses a transaction, referred\nto as  endorsing logic . By default, endorsing logic at a peer accepts\nthe  tran-proposal  and simply signs the  tran-proposal . However,\nendorsing logic may interpret arbitrary functionality, to, e.g.,\ninteract with legacy systems with  tran-proposal  and  tx  as inputs to\nreach the decision whether to endorse a transaction or not.  If endorsing logic decides to endorse a transaction, it sends TRANSACTION-ENDORSED, tid, tran-proposal,epSig  message to the\nsubmitting client( tx.clientID ), where:    tran-proposal := (epID,tid,chaincodeID,txContentBlob,readset,writeset) ,  where  txContentBlob  is chaincode/transaction specific information.\nThe intention is to have  txContentBlob  used as some representation\nof  tx  (e.g.,  txContentBlob=tx.txPayload ).    epSig  is the endorsing peer\\'s signature on  tran-proposal    Else, in case the endorsing logic refuses to endorse the transaction, an\nendorser  may  send a message  (TRANSACTION-INVALID, tid, REJECTED)  to\nthe submitting client.  Notice that an endorser does not change its state in this step, the\nupdates produced by transaction simulation in the context of endorsement\ndo not affect the state!", 
            "title": "2.2. The endorsing peer simulates a transaction and produces an endorsement signature"
        }, 
        {
            "location": "/arch-deep-dive/#23-the-submitting-client-collects-an-endorsement-for-a-transaction-and-broadcasts-it-through-ordering-service", 
            "text": "The submitting client waits until it receives \\\"enough\\\" messages and\nsignatures on  (TRANSACTION-ENDORSED, tid, *, *)  statements to conclude\nthat the transaction proposal is endorsed. As discussed in Section\n2.1.2., this may involve one or more round-trips of interaction with\nendorsers.  The exact number of \\\"enough\\\" depend on the chaincode endorsement\npolicy (see also Section 3). If the endorsement policy is satisfied, the\ntransaction has been  endorsed ; note that it is not yet committed. The\ncollection of signed  TRANSACTION-ENDORSED  messages from endorsing\npeers which establish that a transaction is endorsed is called an endorsement  and denoted by  endorsement .  If the submitting client does not manage to collect an endorsement for a\ntransaction proposal, it abandons this transaction with an option to\nretry later.  For transaction with a valid endorsement, we now start using the\nordering service. The submitting client invokes ordering service using\nthe  broadcast(blob) , where  blob=endorsement . If the client does not\nhave capability of invoking ordering service directly, it may proxy its\nbroadcast through some peer of its choice. Such a peer must be trusted\nby the client not to remove any message from the  endorsement  or\notherwise the transaction may be deemed invalid. Notice that, however, a\nproxy peer may not fabricate a valid  endorsement .", 
            "title": "2.3. The submitting client collects an endorsement for a transaction and broadcasts it through ordering service"
        }, 
        {
            "location": "/arch-deep-dive/#24-the-ordering-service-delivers-a-transactions-to-the-peers", 
            "text": "When an event  deliver(seqno, prevhash, blob)  occurs and a peer has\napplied all state updates for blobs with sequence number lower than seqno , a peer does the following:   It checks that the  blob.endorsement  is valid according to the\n    policy of the chaincode ( blob.tran-proposal.chaincodeID ) to which\n    it refers.  In a typical case, it also verifies that the dependencies\n    ( blob.endorsement.tran-proposal.readset ) have not been violated\n    meanwhile. In more complex use cases,  tran-proposal  fields in\n    endorsement may differ and in this case endorsement policy (Section\n    3)  specifies how the state evolves.   Verification of dependencies can be implemented in different ways,\naccording to a consistency property or \\\"isolation guarantee\\\" that is\nchosen for the state updates.  Serializability  is a default isolation\nguarantee, unless chaincode endorsement policy specifies a different\none. Serializability can be provided by requiring the version associated\nwith  every  key in the  readset  to be equal to that key\\'s version in\nthe state, and rejecting transactions that do not satisfy this\nrequirement.   If all these checks pass, the transaction is deemed  valid  or\n     committed . In this case, the peer marks the transaction with 1 in\n    the bitmask of the  PeerLedger , applies\n     blob.endorsement.tran-proposal.writeset  to blockchain state (if\n     tran-proposals  are the same, otherwise endorsement policy logic\n    defines the function that takes  blob.endorsement ).  If the endorsement policy verification of  blob.endorsement  fails,\n    the transaction is invalid and the peer marks the transaction with 0\n    in the bitmask of the  PeerLedger . It is important to note that\n    invalid transactions do not change the state.   Note that this is sufficient to have all (correct) peers have the same\nstate after processing a deliver event (block) with a given sequence\nnumber. Namely, by the guarantees of the ordering service, all correct\npeers will receive an identical sequence of deliver(seqno, prevhash, blob)  events. As the evaluation of the\nendorsement policy and evaluation of version dependencies in  readset \nare deterministic, all correct peers will also come to the same\nconclusion whether a transaction contained in a blob is valid. Hence,\nall peers commit and apply the same sequence of transactions and update\ntheir state in the same way.   Figure 1. Illustration of one possible transaction flow (common-case\npath).", 
            "title": "2.4. The ordering service delivers a transactions to the peers"
        }, 
        {
            "location": "/arch-deep-dive/#3-endorsement-policies", 
            "text": "", 
            "title": "3. Endorsement policies"
        }, 
        {
            "location": "/arch-deep-dive/#31-endorsement-policy-specification", 
            "text": "An  endorsement policy , is a condition on what  endorses  a\ntransaction. Blockchain peers have a pre-specified set of endorsement\npolicies, which are referenced by a  deploy  transaction that installs\nspecific chaincode. Endorsement policies can be parametrized, and these\nparameters can be specified by a  deploy  transaction.  To guarantee blockchain and security properties, the set of endorsement\npolicies  should be a set of proven policies  with limited set of\nfunctions in order to ensure bounded execution time (termination),\ndeterminism, performance and security guarantees.  Dynamic addition of endorsement policies (e.g., by  deploy  transaction\non chaincode deploy time) is very sensitive in terms of bounded policy\nevaluation time (termination), determinism, performance and security\nguarantees. Therefore, dynamic addition of endorsement policies is not\nallowed, but can be supported in future.", 
            "title": "3.1. Endorsement policy specification"
        }, 
        {
            "location": "/arch-deep-dive/#32-transaction-evaluation-against-endorsement-policy", 
            "text": "A transaction is declared valid only if it has been endorsed according\nto the policy. An invoke transaction for a chaincode will first have to\nobtain an  endorsement  that satisfies the chaincode\\'s policy or it\nwill not be committed. This takes place through the interaction between\nthe submitting client and endorsing peers as explained in Section 2.  Formally the endorsement policy is a predicate on the endorsement, and\npotentially further state that evaluates to TRUE or FALSE. For deploy\ntransactions the endorsement is obtained according to a system-wide\npolicy (for example, from the system chaincode).  An endorsement policy predicate refers to certain variables. Potentially\nit may refer to:   keys or identities relating to the chaincode (found in the metadata\n    of the chaincode), for example, a set of endorsers;  further metadata of the chaincode;  elements of the  endorsement  and  endorsement.tran-proposal ;  and potentially more.   The above list is ordered by increasing expressiveness and complexity,\nthat is, it will be relatively simple to support policies that only\nrefer to keys and identities of nodes.  The evaluation of an endorsement policy predicate must be\ndeterministic.  An endorsement shall be evaluated locally by every peer\nsuch that a peer does  not  need to interact with other peers, yet all\ncorrect peers evaluate the endorsement policy in the same way.", 
            "title": "3.2. Transaction evaluation against endorsement policy"
        }, 
        {
            "location": "/arch-deep-dive/#33-example-endorsement-policies", 
            "text": "The predicate may contain logical expressions and evaluates to TRUE or\nFALSE. Typically the condition will use digital signatures on the\ntransaction invocation issued by endorsing peers for the chaincode.  Suppose the chaincode specifies the endorser set E = {Alice, Bob, Charlie, Dave, Eve, Frank, George} . Some example\npolicies:   A valid signature from on the same  tran-proposal  from all members\n    of E.  A valid signature from any single member of E.  Valid signatures on the same  tran-proposal  from endorsing peers\n    according to the condition\n     (Alice OR Bob) AND (any two of: Charlie, Dave, Eve, Frank, George) .  Valid signatures on the same  tran-proposal  by any 5 out of the 7\n    endorsers. (More generally, for chaincode with  n   3f  endorsers,\n    valid signatures by any  2f+1  out of the  n  endorsers, or by any\n    group of  more  than  (n+f)/2  endorsers.)  Suppose there is an assignment of \\\"stake\\\" or \\\"weights\\\" to the\n    endorsers, like\n     {Alice=49, Bob=15, Charlie=15, Dave=10, Eve=7, Frank=3, George=1} ,\n    where the total stake is 100: The policy requires valid signatures\n    from a set that has a majority of the stake (i.e., a group with\n    combined stake strictly more than 50), such as  {Alice, X}  with any\n     X  different from George, or  {everyone together except Alice} .\n    And so on.  The assignment of stake in the previous example condition could be\n    static (fixed in the metadata of the chaincode) or dynamic (e.g.,\n    dependent on the state of the chaincode and be modified during the\n    execution).  Valid signatures from (Alice OR Bob) on  tran-proposal1  and valid\n    signatures from  (any two of: Charlie, Dave, Eve, Frank, George)  on\n     tran-proposal2 , where  tran-proposal1  and  tran-proposal2  differ\n    only in their endorsing peers and state updates.   How useful these policies are will depend on the application, on the\ndesired resilience of the solution against failures or misbehavior of\nendorsers, and on various other properties.", 
            "title": "3.3. Example endorsement policies"
        }, 
        {
            "location": "/arch-deep-dive/#4-post-v1-validated-ledger-and-peerledger-checkpointing-pruning", 
            "text": "", 
            "title": "4 (post-v1). Validated ledger and PeerLedger checkpointing (pruning)"
        }, 
        {
            "location": "/arch-deep-dive/#41-validated-ledger-vledger", 
            "text": "To maintain the abstraction of a ledger that contains only valid and\ncommitted transactions (that appears in Bitcoin, for example), peers\nmay, in addition to state and Ledger, maintain the  Validated Ledger (or\nVLedger) . This is a hash chain derived from the ledger by filtering out\ninvalid transactions.  The construction of the VLedger blocks (called here  vBlocks ) proceeds\nas follows. As the  PeerLedger  blocks may contain invalid transactions\n(i.e., transactions with invalid endorsement or with invalid version\ndependencies), such transactions are filtered out by peers before a\ntransaction from a block becomes added to a vBlock. Every peer does this\nby itself (e.g., by using the bitmask associated with  PeerLedger ). A\nvBlock is defined as a block without the invalid transactions, that have\nbeen filtered out. Such vBlocks are inherently dynamic in size and may\nbe empty. An illustration of vBlock construction is given in the figure\nbelow.   Figure 2. Illustration of validated ledger block (vBlock) formation\nfrom ledger (PeerLedger) blocks.  vBlocks are chained together to a hash chain by every peer. More\nspecifically, every block of a validated ledger contains:   The hash of the previous vBlock.  vBlock number.  An ordered list of all valid transactions committed by the peers\n    since the last vBlock was computed (i.e., list of valid transactions\n    in a corresponding block).  The hash of the corresponding block (in  PeerLedger ) from which the\n    current vBlock is derived.   All this information is concatenated and hashed by a peer, producing the\nhash of the vBlock in the validated ledger.", 
            "title": "4.1. Validated ledger (VLedger)"
        }, 
        {
            "location": "/arch-deep-dive/#42-peerledger-checkpointing", 
            "text": "The ledger contains invalid transactions, which may not necessarily be\nrecorded forever. However, peers cannot simply discard  PeerLedger \nblocks and thereby prune  PeerLedger  once they establish the\ncorresponding vBlocks. Namely, in this case, if a new peer joins the\nnetwork, other peers could not transfer the discarded blocks (pertaining\nto  PeerLedger ) to the joining peer, nor convince the joining peer of\nthe validity of their vBlocks.  To facilitate pruning of the  PeerLedger , this document describes a checkpointing  mechanism. This mechanism establishes the validity of\nthe vBlocks across the peer network and allows checkpointed vBlocks to\nreplace the discarded  PeerLedger  blocks. This, in turn, reduces\nstorage space, as there is no need to store invalid transactions. It\nalso reduces the work to reconstruct the state for new peers that join\nthe network (as they do not need to establish validity of individual\ntransactions when reconstructing the state by replaying  PeerLedger ,\nbut may simply replay the state updates contained in the validated\nledger).", 
            "title": "4.2. PeerLedger Checkpointing"
        }, 
        {
            "location": "/arch-deep-dive/#421-checkpointing-protocol", 
            "text": "Checkpointing is performed periodically by the peers every  CHK  blocks,\nwhere  CHK  is a configurable parameter. To initiate a checkpoint, the\npeers broadcast (e.g., gossip) to other peers message CHECKPOINT,blocknohash,blockno,stateHash,peerSig , where  blockno  is\nthe current blocknumber and  blocknohash  is its respective hash, stateHash  is the hash of the latest state (produced by e.g., a Merkle\nhash) upon validation of block  blockno  and  peerSig  is peer\\'s\nsignature on  (CHECKPOINT,blocknohash,blockno,stateHash) , referring to\nthe validated ledger.  A peer collects  CHECKPOINT  messages until it obtains enough correctly\nsigned messages with matching  blockno ,  blocknohash  and  stateHash \nto establish a  valid checkpoint  (see Section 4.2.2.).  Upon establishing a valid checkpoint for block number  blockno  with blocknohash , a peer:   if  blockno latestValidCheckpoint.blockno , then a peer assigns\n     latestValidCheckpoint=(blocknohash,blockno) ,  stores the set of respective peer signatures that constitute a valid\n    checkpoint into the set  latestValidCheckpointProof ,  stores the state corresponding to  stateHash  to\n     latestValidCheckpointedState ,  (optionally) prunes its  PeerLedger  up to block number  blockno \n    (inclusive).", 
            "title": "4.2.1. Checkpointing protocol"
        }, 
        {
            "location": "/arch-deep-dive/#422-valid-checkpoints", 
            "text": "Clearly, the checkpointing protocol raises the following questions: When can a peer prune its  PeerLedger ? How many  CHECKPOINT  messages\nare \\\"sufficiently many\\\"? . This is defined by a  checkpoint validity\npolicy , with (at least) two possible approaches, which may also be\ncombined:   Local (peer-specific) checkpoint validity policy (LCVP).  A local\n    policy at a given peer  p  may specify a set of peers which peer  p \n    trusts and whose  CHECKPOINT  messages are sufficient to establish a\n    valid checkpoint. For example, LCVP at peer  Alice  may define that\n     Alice  needs to receive  CHECKPOINT  message from Bob, or from\n     both   Charlie  and  Dave .  Global checkpoint validity policy (GCVP).  A checkpoint validity\n    policy may be specified globally. This is similar to a local peer\n    policy, except that it is stipulated at the system (blockchain)\n    granularity, rather than peer granularity. For instance, GCVP may\n    specify that:  each peer may trust a checkpoint if confirmed by  11  different\n    peers.  in a specific deployment in which every orderer is collocated\n    with a peer in the same machine (i.e., trust domain) and where\n    up to  f  orderers may be (Byzantine) faulty, each peer may\n    trust a checkpoint if confirmed by  f+1  different peers\n    collocated with orderers.", 
            "title": "4.2.2. Valid checkpoints"
        }, 
        {
            "location": "/capabilities/", 
            "text": "Hyperledger Fabric Capabilities\n\n\nHyperledger Fabric is a unique implementation of distributed ledger\ntechnology (DLT) that delivers enterprise-ready network security,\nscalability, confidentiality and performance, in a modular blockchain\narchitecture. Hyperledger Fabric delivers the following blockchain\nnetwork capabilities:\n\n\nIdentity management\n\n\nTo enable permissioned networks, Hyperledger Fabric provides a\nmembership identity service that manages user IDs and authenticates all\nparticipants on the network. Access control lists can be used to provide\nadditional layers of permission through authorization of specific\nnetwork operations. For example, a specific user ID could be permitted\nto invoke a chaincode application, but blocked from deploying new\nchaincode. One truism about Hyperledger Fabric networks is that members\nknow each other (identity), but they do not know what each other are\ndoing (privacy and confidentiality).\n\n\nPrivacy and confidentiality\n\n\nHyperledger Fabric enables competing business interests, and any groups\nthat require private, confidential transactions, to coexist on the same\npermissioned network. Private \nchannels\n are restricted messaging\npaths that can be used to provide transaction privacy and\nconfidentiality for specific subsets of network members. All data,\nincluding transaction, member and channel information, on a channel are\ninvisible and inaccessible to any network members not explicitly granted\naccess to that channel.\n\n\nEfficient processing\n\n\nHyperledger Fabric assigns network roles by node type. To provide\nconcurrency and parallelism to the network, transaction execution is\nseparated from transaction ordering and commitment. Executing\ntransactions prior to ordering them enables each peer node to process\nmultiple transactions simultaneously. This concurrent execution\nincreases processing efficiency on each peer and accelerates delivery of\ntransactions to the ordering service.\n\n\nIn addition to enabling parallel processing, the division of labor\nunburdens ordering nodes from the demands of transaction execution and\nledger maintenance, while peer nodes are freed from ordering (consensus)\nworkloads. This bifurcation of roles also limits the processing required\nfor authorization and authentication; all peer nodes do not have to\ntrust all ordering nodes, and vice versa, so processes on one can run\nindependently of verification by the other.\n\n\nChaincode functionality\n\n\nChaincode applications encode logic that is invoked by specific types of\ntransactions on the channel. Chaincode that defines parameters for a\nchange of asset ownership, for example, ensures that all transactions\nthat transfer ownership are subject to the same rules and requirements.\n\nSystem chaincode\n is distinguished as chaincode that defines\noperating parameters for the entire channel. Lifecycle and configuration\nsystem chaincode defines the rules for the channel; endorsement and\nvalidation system chaincode defines the requirements for endorsing and\nvalidating transactions.\n\n\nModular design\n\n\nHyperledger Fabric implements a modular architecture to provide\nfunctional choice to network designers. Specific algorithms for\nidentity, ordering (consensus) and encryption, for example, can be\nplugged in to any Hyperledger Fabric network. The result is a universal\nblockchain architecture that any industry or public domain can adopt,\nwith the assurance that its networks will be interoperable across\nmarket, regulatory and geographic boundaries. By contrast, current\nalternatives to Hyperledger Fabric are largely partisan, constrained and\nindustry-specific.", 
            "title": "Capabilities"
        }, 
        {
            "location": "/capabilities/#hyperledger-fabric-capabilities", 
            "text": "Hyperledger Fabric is a unique implementation of distributed ledger\ntechnology (DLT) that delivers enterprise-ready network security,\nscalability, confidentiality and performance, in a modular blockchain\narchitecture. Hyperledger Fabric delivers the following blockchain\nnetwork capabilities:", 
            "title": "Hyperledger Fabric Capabilities"
        }, 
        {
            "location": "/capabilities/#identity-management", 
            "text": "To enable permissioned networks, Hyperledger Fabric provides a\nmembership identity service that manages user IDs and authenticates all\nparticipants on the network. Access control lists can be used to provide\nadditional layers of permission through authorization of specific\nnetwork operations. For example, a specific user ID could be permitted\nto invoke a chaincode application, but blocked from deploying new\nchaincode. One truism about Hyperledger Fabric networks is that members\nknow each other (identity), but they do not know what each other are\ndoing (privacy and confidentiality).", 
            "title": "Identity management"
        }, 
        {
            "location": "/capabilities/#privacy-and-confidentiality", 
            "text": "Hyperledger Fabric enables competing business interests, and any groups\nthat require private, confidential transactions, to coexist on the same\npermissioned network. Private  channels  are restricted messaging\npaths that can be used to provide transaction privacy and\nconfidentiality for specific subsets of network members. All data,\nincluding transaction, member and channel information, on a channel are\ninvisible and inaccessible to any network members not explicitly granted\naccess to that channel.", 
            "title": "Privacy and confidentiality"
        }, 
        {
            "location": "/capabilities/#efficient-processing", 
            "text": "Hyperledger Fabric assigns network roles by node type. To provide\nconcurrency and parallelism to the network, transaction execution is\nseparated from transaction ordering and commitment. Executing\ntransactions prior to ordering them enables each peer node to process\nmultiple transactions simultaneously. This concurrent execution\nincreases processing efficiency on each peer and accelerates delivery of\ntransactions to the ordering service.  In addition to enabling parallel processing, the division of labor\nunburdens ordering nodes from the demands of transaction execution and\nledger maintenance, while peer nodes are freed from ordering (consensus)\nworkloads. This bifurcation of roles also limits the processing required\nfor authorization and authentication; all peer nodes do not have to\ntrust all ordering nodes, and vice versa, so processes on one can run\nindependently of verification by the other.", 
            "title": "Efficient processing"
        }, 
        {
            "location": "/capabilities/#chaincode-functionality", 
            "text": "Chaincode applications encode logic that is invoked by specific types of\ntransactions on the channel. Chaincode that defines parameters for a\nchange of asset ownership, for example, ensures that all transactions\nthat transfer ownership are subject to the same rules and requirements. System chaincode  is distinguished as chaincode that defines\noperating parameters for the entire channel. Lifecycle and configuration\nsystem chaincode defines the rules for the channel; endorsement and\nvalidation system chaincode defines the requirements for endorsing and\nvalidating transactions.", 
            "title": "Chaincode functionality"
        }, 
        {
            "location": "/capabilities/#modular-design", 
            "text": "Hyperledger Fabric implements a modular architecture to provide\nfunctional choice to network designers. Specific algorithms for\nidentity, ordering (consensus) and encryption, for example, can be\nplugged in to any Hyperledger Fabric network. The result is a universal\nblockchain architecture that any industry or public domain can adopt,\nwith the assurance that its networks will be interoperable across\nmarket, regulatory and geographic boundaries. By contrast, current\nalternatives to Hyperledger Fabric are largely partisan, constrained and\nindustry-specific.", 
            "title": "Modular design"
        }, 
        {
            "location": "/fabric_model/", 
            "text": "Hyperledger Fabric Model\n\n\nThis section outlines the key design features woven into Hyperledger\nFabric that fulfill its promise of a comprehensive, yet customizable,\nenterprise blockchain solution:\n\n\n\n\n[Assets]{role=\"ref\"} - Asset definitions enable the exchange of\n    almost anything with monetary value over the network, from whole\n    foods to antique cars to currency futures.\n\n\n[Chaincode]{role=\"ref\"} - Chaincode execution is partitioned from\n    transaction ordering, limiting the required levels of trust and\n    verification across node types, and optimizing network scalability\n    and performance.\n\n\n[Ledger-Features]{role=\"ref\"} - The immutable, shared ledger encodes\n    the entire transaction history for each channel, and includes\n    SQL-like query capability for efficient auditing and dispute\n    resolution.\n\n\n[Privacy-through-Channels]{role=\"ref\"} - Channels enable\n    multi-lateral transactions with the high degrees of privacy and\n    confidentiality required by competing businesses and regulated\n    industries that exchange assets on a common network.\n\n\n[Security-Membership-Services]{role=\"ref\"} - Permissioned membership\n    provides a trusted blockchain network, where participants know that\n    all transactions can be detected and traced by authorized regulators\n    and auditors.\n\n\n[Consensus]{role=\"ref\"} - a unique approach to consensus enables the\n    flexibility and scalability needed for the enterprise.\n\n\n\n\n::: {#Assets}\nAssets\n\n\n\n\n:::\n\n\nAssets can range from the tangible (real estate and hardware) to the\nintangible (contracts and intellectual property). Hyperledger Fabric\nprovides the ability to modify assets using chaincode transactions.\n\n\nAssets are represented in Hyperledger Fabric as a collection of\nkey-value pairs, with state changes recorded as transactions on a\n[Channel]{role=\"ref\"} ledger. Assets can be represented in binary and/or\nJSON form.\n\n\nYou can easily define and use assets in your Hyperledger Fabric\napplications using the \nHyperledger\nComposer\n tool.\n\n\n::: {#Chaincode}\nChaincode\n\n\n\n\n:::\n\n\nChaincode is software defining an asset or assets, and the transaction\ninstructions for modifying the asset(s). In other words, it\\'s the\nbusiness logic. Chaincode enforces the rules for reading or altering key\nvalue pairs or other state database information. Chaincode functions\nexecute against the ledger\\'s current state database and are initiated\nthrough a transaction proposal. Chaincode execution results in a set of\nkey value writes (write set) that can be submitted to the network and\napplied to the ledger on all peers.\n\n\n::: {#Ledger-Features}\nLedger Features\n\n\n\n\n:::\n\n\nThe ledger is the sequenced, tamper-resistant record of all state\ntransitions in the fabric. State transitions are a result of chaincode\ninvocations (\\'transactions\\') submitted by participating parties. Each\ntransaction results in a set of asset key-value pairs that are committed\nto the ledger as creates, updates, or deletes.\n\n\nThe ledger is comprised of a blockchain (\\'chain\\') to store the\nimmutable, sequenced record in blocks, as well as a state database to\nmaintain current fabric state. There is one ledger per channel. Each\npeer maintains a copy of the ledger for each channel of which they are a\nmember.\n\n\n\n\nQuery and update ledger using key-based lookups, range queries, and\n    composite key queries\n\n\nRead-only queries using a rich query language (if using CouchDB as\n    state database)\n\n\nRead-only history queries - Query ledger history for a key, enabling\n    data provenance scenarios\n\n\nTransactions consist of the versions of keys/values that were read\n    in chaincode (read set) and keys/values that were written in\n    chaincode (write set)\n\n\nTransactions contain signatures of every endorsing peer and are\n    submitted to ordering service\n\n\nTransactions are ordered into blocks and are \\\"delivered\\\" from an\n    ordering service to peers on a channel\n\n\nPeers validate transactions against endorsement policies and enforce\n    the policies\n\n\nPrior to appending a block, a versioning check is performed to\n    ensure that states for assets that were read have not changed since\n    chaincode execution time\n\n\nThere is immutability once a transaction is validated and committed\n\n\nA channel\\'s ledger contains a configuration block defining\n    policies, access control lists, and other pertinent information\n\n\nChannel\\'s contain [MSP]{role=\"ref\"} instances allowing for crypto\n    materials to be derived from different certificate authorities\n\n\n\n\nSee the [ledger]{role=\"doc\"} topic for a deeper dive on the databases,\nstorage structure, and \\\"query-ability.\\\"\n\n\n::: {#Privacy-through-Channels}\nPrivacy through Channels\n\n\n\n\n:::\n\n\nHyperledger Fabric employs an immutable ledger on a per-channel basis,\nas well as chaincodes that can manipulate and modify the current state\nof assets (i.e. update key value pairs). A ledger exists in the scope of\na channel - it can be shared across the entire network (assuming every\nparticipant is operating on one common channel) - or it can be\nprivatized to only include a specific set of participants.\n\n\nIn the latter scenario, these participants would create a separate\nchannel and thereby isolate/segregate their transactions and ledger. In\norder to solve scenarios that want to bridge the gap between total\ntransparency and privacy, chaincode can be installed only on peers that\nneed to access the asset states to perform reads and writes (in other\nwords, if a chaincode is not installed on a peer, it will not be able to\nproperly interface with the ledger).\n\n\nTo further obfuscate the data, values within chaincode can be encrypted\n(in part or in total) using common cryptographic algorithms such as AES\nbefore sending transactions to the ordering service and appending blocks\nto the ledger. Once encrypted data has been written to the ledger, it\ncan only be decrypted by a user in possession of the corresponding key\nthat was used to generate the cipher text. For further details on\nchaincode encryption, see the [chaincode4ade]{role=\"doc\"} topic.\n\n\n::: {#Security-Membership-Services}\nSecurity \n Membership Services\n\n\n\n\n:::\n\n\nHyperledger Fabric underpins a transactional network where all\nparticipants have known identities. Public Key Infrastructure is used to\ngenerate cryptographic certificates which are tied to organizations,\nnetwork components, and end users or client applications. As a result,\ndata access control can be manipulated and governed on the broader\nnetwork and on channel levels. This \\\"permissioned\\\" notion of\nHyperledger Fabric, coupled with the existence and capabilities of\nchannels, helps address scenarios where privacy and confidentiality are\nparamount concerns.\n\n\nSee the [msp]{role=\"doc\"} topic to better understand cryptographic\nimplementations, and the sign, verify, authenticate approach used in\nHyperledger Fabric.\n\n\n::: {#Consensus}\nConsensus\n\n\n\n\n:::\n\n\nIn distributed ledger technology, consensus has recently become\nsynonymous with a specific algorithm, within a single function. However,\nconsensus encompasses more than simply agreeing upon the order of\ntransactions, and this differentiation is highlighted in Hyperledger\nFabric through its fundamental role in the entire transaction flow, from\nproposal and endorsement, to ordering, validation and commitment. In a\nnutshell, consensus is defined as the full-circle verification of the\ncorrectness of a set of transactions comprising a block.\n\n\nConsensus is ultimately achieved when the order and results of a\nblock\\'s transactions have met the explicit policy criteria checks.\nThese checks and balances take place during the lifecycle of a\ntransaction, and include the usage of endorsement policies to dictate\nwhich specific members must endorse a certain transaction class, as well\nas system chaincodes to ensure that these policies are enforced and\nupheld. Prior to commitment, the peers will employ these system\nchaincodes to make sure that enough endorsements are present, and that\nthey were derived from the appropriate entities. Moreover, a versioning\ncheck will take place during which the current state of the ledger is\nagreed or consented upon, before any blocks containing transactions are\nappended to the ledger. This final check provides protection against\ndouble spend operations and other threats that might compromise data\nintegrity, and allows for functions to be executed against non-static\nvariables.\n\n\nIn addition to the multitude of endorsement, validity and versioning\nchecks that take place, there are also ongoing identity verifications\nhappening in all directions of the transaction flow. Access control\nlists are implemented on hierarchal layers of the network (ordering\nservice down to channels), and payloads are repeatedly signed, verified\nand authenticated as a transaction proposal passes through the different\narchitectural components. To conclude, consensus is not merely limited\nto the agreed upon order of a batch of transactions, but rather, it is\nan overarching characterization that is achieved as a byproduct of the\nongoing verifications that take place during a transaction\\'s journey\nfrom proposal to commitment.\n\n\nCheck out the [txflow]{role=\"doc\"} diagram for a visual representation\nof consensus.", 
            "title": "Fabric Model"
        }, 
        {
            "location": "/fabric_model/#hyperledger-fabric-model", 
            "text": "This section outlines the key design features woven into Hyperledger\nFabric that fulfill its promise of a comprehensive, yet customizable,\nenterprise blockchain solution:   [Assets]{role=\"ref\"} - Asset definitions enable the exchange of\n    almost anything with monetary value over the network, from whole\n    foods to antique cars to currency futures.  [Chaincode]{role=\"ref\"} - Chaincode execution is partitioned from\n    transaction ordering, limiting the required levels of trust and\n    verification across node types, and optimizing network scalability\n    and performance.  [Ledger-Features]{role=\"ref\"} - The immutable, shared ledger encodes\n    the entire transaction history for each channel, and includes\n    SQL-like query capability for efficient auditing and dispute\n    resolution.  [Privacy-through-Channels]{role=\"ref\"} - Channels enable\n    multi-lateral transactions with the high degrees of privacy and\n    confidentiality required by competing businesses and regulated\n    industries that exchange assets on a common network.  [Security-Membership-Services]{role=\"ref\"} - Permissioned membership\n    provides a trusted blockchain network, where participants know that\n    all transactions can be detected and traced by authorized regulators\n    and auditors.  [Consensus]{role=\"ref\"} - a unique approach to consensus enables the\n    flexibility and scalability needed for the enterprise.   ::: {#Assets}\nAssets   :::  Assets can range from the tangible (real estate and hardware) to the\nintangible (contracts and intellectual property). Hyperledger Fabric\nprovides the ability to modify assets using chaincode transactions.  Assets are represented in Hyperledger Fabric as a collection of\nkey-value pairs, with state changes recorded as transactions on a\n[Channel]{role=\"ref\"} ledger. Assets can be represented in binary and/or\nJSON form.  You can easily define and use assets in your Hyperledger Fabric\napplications using the  Hyperledger\nComposer  tool.  ::: {#Chaincode}\nChaincode   :::  Chaincode is software defining an asset or assets, and the transaction\ninstructions for modifying the asset(s). In other words, it\\'s the\nbusiness logic. Chaincode enforces the rules for reading or altering key\nvalue pairs or other state database information. Chaincode functions\nexecute against the ledger\\'s current state database and are initiated\nthrough a transaction proposal. Chaincode execution results in a set of\nkey value writes (write set) that can be submitted to the network and\napplied to the ledger on all peers.  ::: {#Ledger-Features}\nLedger Features   :::  The ledger is the sequenced, tamper-resistant record of all state\ntransitions in the fabric. State transitions are a result of chaincode\ninvocations (\\'transactions\\') submitted by participating parties. Each\ntransaction results in a set of asset key-value pairs that are committed\nto the ledger as creates, updates, or deletes.  The ledger is comprised of a blockchain (\\'chain\\') to store the\nimmutable, sequenced record in blocks, as well as a state database to\nmaintain current fabric state. There is one ledger per channel. Each\npeer maintains a copy of the ledger for each channel of which they are a\nmember.   Query and update ledger using key-based lookups, range queries, and\n    composite key queries  Read-only queries using a rich query language (if using CouchDB as\n    state database)  Read-only history queries - Query ledger history for a key, enabling\n    data provenance scenarios  Transactions consist of the versions of keys/values that were read\n    in chaincode (read set) and keys/values that were written in\n    chaincode (write set)  Transactions contain signatures of every endorsing peer and are\n    submitted to ordering service  Transactions are ordered into blocks and are \\\"delivered\\\" from an\n    ordering service to peers on a channel  Peers validate transactions against endorsement policies and enforce\n    the policies  Prior to appending a block, a versioning check is performed to\n    ensure that states for assets that were read have not changed since\n    chaincode execution time  There is immutability once a transaction is validated and committed  A channel\\'s ledger contains a configuration block defining\n    policies, access control lists, and other pertinent information  Channel\\'s contain [MSP]{role=\"ref\"} instances allowing for crypto\n    materials to be derived from different certificate authorities   See the [ledger]{role=\"doc\"} topic for a deeper dive on the databases,\nstorage structure, and \\\"query-ability.\\\"  ::: {#Privacy-through-Channels}\nPrivacy through Channels   :::  Hyperledger Fabric employs an immutable ledger on a per-channel basis,\nas well as chaincodes that can manipulate and modify the current state\nof assets (i.e. update key value pairs). A ledger exists in the scope of\na channel - it can be shared across the entire network (assuming every\nparticipant is operating on one common channel) - or it can be\nprivatized to only include a specific set of participants.  In the latter scenario, these participants would create a separate\nchannel and thereby isolate/segregate their transactions and ledger. In\norder to solve scenarios that want to bridge the gap between total\ntransparency and privacy, chaincode can be installed only on peers that\nneed to access the asset states to perform reads and writes (in other\nwords, if a chaincode is not installed on a peer, it will not be able to\nproperly interface with the ledger).  To further obfuscate the data, values within chaincode can be encrypted\n(in part or in total) using common cryptographic algorithms such as AES\nbefore sending transactions to the ordering service and appending blocks\nto the ledger. Once encrypted data has been written to the ledger, it\ncan only be decrypted by a user in possession of the corresponding key\nthat was used to generate the cipher text. For further details on\nchaincode encryption, see the [chaincode4ade]{role=\"doc\"} topic.  ::: {#Security-Membership-Services}\nSecurity   Membership Services   :::  Hyperledger Fabric underpins a transactional network where all\nparticipants have known identities. Public Key Infrastructure is used to\ngenerate cryptographic certificates which are tied to organizations,\nnetwork components, and end users or client applications. As a result,\ndata access control can be manipulated and governed on the broader\nnetwork and on channel levels. This \\\"permissioned\\\" notion of\nHyperledger Fabric, coupled with the existence and capabilities of\nchannels, helps address scenarios where privacy and confidentiality are\nparamount concerns.  See the [msp]{role=\"doc\"} topic to better understand cryptographic\nimplementations, and the sign, verify, authenticate approach used in\nHyperledger Fabric.  ::: {#Consensus}\nConsensus   :::  In distributed ledger technology, consensus has recently become\nsynonymous with a specific algorithm, within a single function. However,\nconsensus encompasses more than simply agreeing upon the order of\ntransactions, and this differentiation is highlighted in Hyperledger\nFabric through its fundamental role in the entire transaction flow, from\nproposal and endorsement, to ordering, validation and commitment. In a\nnutshell, consensus is defined as the full-circle verification of the\ncorrectness of a set of transactions comprising a block.  Consensus is ultimately achieved when the order and results of a\nblock\\'s transactions have met the explicit policy criteria checks.\nThese checks and balances take place during the lifecycle of a\ntransaction, and include the usage of endorsement policies to dictate\nwhich specific members must endorse a certain transaction class, as well\nas system chaincodes to ensure that these policies are enforced and\nupheld. Prior to commitment, the peers will employ these system\nchaincodes to make sure that enough endorsements are present, and that\nthey were derived from the appropriate entities. Moreover, a versioning\ncheck will take place during which the current state of the ledger is\nagreed or consented upon, before any blocks containing transactions are\nappended to the ledger. This final check provides protection against\ndouble spend operations and other threats that might compromise data\nintegrity, and allows for functions to be executed against non-static\nvariables.  In addition to the multitude of endorsement, validity and versioning\nchecks that take place, there are also ongoing identity verifications\nhappening in all directions of the transaction flow. Access control\nlists are implemented on hierarchal layers of the network (ordering\nservice down to channels), and payloads are repeatedly signed, verified\nand authenticated as a transaction proposal passes through the different\narchitectural components. To conclude, consensus is not merely limited\nto the agreed upon order of a batch of transactions, but rather, it is\nan overarching characterization that is achieved as a byproduct of the\nongoing verifications that take place during a transaction\\'s journey\nfrom proposal to commitment.  Check out the [txflow]{role=\"doc\"} diagram for a visual representation\nof consensus.", 
            "title": "Hyperledger Fabric Model"
        }, 
        {
            "location": "/channels/", 
            "text": "Channels\n\n\nA Hyperledger Fabric \nchannel\n is a private \\\"subnet\\\" of\ncommunication between two or more specific network members, for the\npurpose of conducting private and confidential transactions. A channel\nis defined by members (organizations), anchor peers per member, the\nshared ledger, chaincode application(s) and the ordering service\nnode(s). Each transaction on the network is executed on a channel, where\neach party must be authenticated and authorized to transact on that\nchannel. Each peer that joins a channel, has its own identity given by a\nmembership services provider (MSP), which authenticates each peer to its\nchannel peers and services.\n\n\nTo create a new channel, the client SDK calls configuration system\nchaincode and references properties such as \nanchor peer\ns, and\nmembers (organizations). This request creates a \ngenesis block\n for\nthe channel ledger, which stores configuration information about the\nchannel policies, members and anchor peers. When adding a new member to\nan existing channel, either this genesis block, or if applicable, a more\nrecent reconfiguration block, is shared with the new member.\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nSee the [configtx]{role=\"doc\"} section for more more details on the properties\n\n\n:   and proto structures of config transactions.\n:::\n\n\nThe election of a \nleading peer\n for each member on a channel\ndetermines which peer communicates with the ordering service on behalf\nof the member. If no leader is identified, an algorithm can be used to\nidentify the leader. The consensus service orders transactions and\ndelivers them, in a block, to each leading peer, which then distributes\nthe block to its member peers, and across the channel, using the\n\ngossip\n protocol.\n\n\nAlthough any one anchor peer can belong to multiple channels, and\ntherefore maintain multiple ledgers, no ledger data can pass from one\nchannel to another. This separation of ledgers, by channel, is defined\nand implemented by configuration chaincode, the identity membership\nservice and the gossip data dissemination protocol. The dissemination of\ndata, which includes information on transactions, ledger state and\nchannel membership, is restricted to peers with verifiable membership on\nthe channel. This isolation of peers and ledger data, by channel, allows\nnetwork members that require private and confidential transactions to\ncoexist with business competitors and other restricted members, on the\nsame blockchain network.", 
            "title": "Channels"
        }, 
        {
            "location": "/channels/#channels", 
            "text": "A Hyperledger Fabric  channel  is a private \\\"subnet\\\" of\ncommunication between two or more specific network members, for the\npurpose of conducting private and confidential transactions. A channel\nis defined by members (organizations), anchor peers per member, the\nshared ledger, chaincode application(s) and the ordering service\nnode(s). Each transaction on the network is executed on a channel, where\neach party must be authenticated and authorized to transact on that\nchannel. Each peer that joins a channel, has its own identity given by a\nmembership services provider (MSP), which authenticates each peer to its\nchannel peers and services.  To create a new channel, the client SDK calls configuration system\nchaincode and references properties such as  anchor peer s, and\nmembers (organizations). This request creates a  genesis block  for\nthe channel ledger, which stores configuration information about the\nchannel policies, members and anchor peers. When adding a new member to\nan existing channel, either this genesis block, or if applicable, a more\nrecent reconfiguration block, is shared with the new member.  ::: {.note}\n::: {.admonition-title}\nNote\n:::  See the [configtx]{role=\"doc\"} section for more more details on the properties  :   and proto structures of config transactions.\n:::  The election of a  leading peer  for each member on a channel\ndetermines which peer communicates with the ordering service on behalf\nof the member. If no leader is identified, an algorithm can be used to\nidentify the leader. The consensus service orders transactions and\ndelivers them, in a block, to each leading peer, which then distributes\nthe block to its member peers, and across the channel, using the gossip  protocol.  Although any one anchor peer can belong to multiple channels, and\ntherefore maintain multiple ledgers, no ledger data can pass from one\nchannel to another. This separation of ledgers, by channel, is defined\nand implemented by configuration chaincode, the identity membership\nservice and the gossip data dissemination protocol. The dissemination of\ndata, which includes information on transactions, ledger state and\nchannel membership, is restricted to peers with verifiable membership on\nthe channel. This isolation of peers and ledger data, by channel, allows\nnetwork members that require private and confidential transactions to\ncoexist with business competitors and other restricted members, on the\nsame blockchain network.", 
            "title": "Channels"
        }, 
        {
            "location": "/gossip/", 
            "text": "Gossip data dissemination protocol\n\n\nHyperledger Fabric optimizes blockchain network performance, security\nand scalability by dividing workload across transaction execution\n(endorsing and committing) peers and transaction ordering nodes. This\ndecoupling of network operations requires a secure, reliable and\nscalable data dissemination protocol to ensure data integrity and\nconsistency. To meet these requirements, Hyperledger Fabric implements a\n\ngossip data dissemination protocol\n.\n\n\nGossip protocol\n\n\nPeers leverage gossip to broadcast ledger and channel data in a scalable\nfashion. Gossip messaging is continuous, and each peer on a channel is\nconstantly receiving current and consistent ledger data, from multiple\npeers. Each gossiped message is signed, thereby allowing Byzantine\nparticipants sending faked messages to be easily identified and the\ndistribution of the message(s) to unwanted targets to be prevented.\nPeers affected by delays, network partitions or other causations\nresulting in missed blocks, will eventually be synced up to the current\nledger state by contacting peers in possession of these missing blocks.\n\n\nThe gossip-based data dissemination protocol performs three primary\nfunctions on a Hyperledger Fabric network:\n\n\n\n\nManages peer discovery and channel membership, by continually\n    identifying available member peers, and eventually detecting peers\n    that have gone offline.\n\n\nDisseminates ledger data across all peers on a channel. Any peer\n    with data that is out of sync with the rest of the channel\n    identifies the missing blocks and syncs itself by copying the\n    correct data.\n\n\nBring newly connected peers up to speed by allowing peer-to-peer\n    state transfer update of ledger data.\n\n\n\n\nGossip-based broadcasting operates by peers receiving messages from\nother peers on the channel, and then forwarding these messages to a\nnumber of randomly-selected peers on the channel, where this number is a\nconfigurable constant. Peers can also exercise a pull mechanism, rather\nthan waiting for delivery of a message. This cycle repeats, with the\nresult of channel membership, ledger and state information continually\nbeing kept current and in sync. For dissemination of new blocks, the\n\nleader\n peer on the channel pulls the data from the ordering service\nand initiates gossip dissemination to peers.\n\n\nGossip messaging\n\n\nOnline peers indicate their availability by continually broadcasting\n\\\"alive\\\" messages, with each containing the \npublic key infrastructure\n(PKI)\n ID and the signature of the sender over the message. Peers\nmaintain channel membership by collecting these alive messages; if no\npeer receives an alive message from a specific peer, this \\\"dead\\\" peer\nis eventually purged from channel membership. Because \\\"alive\\\" messages\nare cryptographically signed, malicious peers can never impersonate\nother peers, as they lack a signing key authorized by a root certificate\nauthority (CA).\n\n\nIn addition to the automatic forwarding of received messages, a state\nreconciliation process synchronizes \nworld state\n across peers on each\nchannel. Each peer continually pulls blocks from other peers on the\nchannel, in order to repair its own state if discrepancies are\nidentified. Because fixed connectivity is not required to maintain\ngossip-based data dissemination, the process reliably provides data\nconsistency and integrity to the shared ledger, including tolerance for\nnode crashes.\n\n\nBecause channels are segregated, peers on one channel cannot message or\nshare information on any other channel. Though any peer can belong to\nmultiple channels, partitioned messaging prevents blocks from being\ndisseminated to peers that are not in the channel by applying message\nrouting policies based on peers\\' channel subscriptions.\n\n\n| \nNotes:\n\n| 1. Security of point-to-point messages are handled by the peer TLS\n  layer, and do not require signatures. Peers are authenticated by their\n  certificates, which are assigned by a CA. Although TLS certs are also\n  used, it is the peer certificates that are authenticated in the gossip\n  layer. Ledger blocks are signed by the ordering service, and then\n  delivered to the leader peers on a channel. 2. Authentication is\n  governed by the membership service provider for the peer. When the\n  peer connects to the channel for the first time, the TLS session binds\n  with the membership identity. This essentially authenticates each peer\n  to the connecting peer, with respect to membership in the network and\n  channel.", 
            "title": "Gossip"
        }, 
        {
            "location": "/gossip/#gossip-data-dissemination-protocol", 
            "text": "Hyperledger Fabric optimizes blockchain network performance, security\nand scalability by dividing workload across transaction execution\n(endorsing and committing) peers and transaction ordering nodes. This\ndecoupling of network operations requires a secure, reliable and\nscalable data dissemination protocol to ensure data integrity and\nconsistency. To meet these requirements, Hyperledger Fabric implements a gossip data dissemination protocol .", 
            "title": "Gossip data dissemination protocol"
        }, 
        {
            "location": "/gossip/#gossip-protocol", 
            "text": "Peers leverage gossip to broadcast ledger and channel data in a scalable\nfashion. Gossip messaging is continuous, and each peer on a channel is\nconstantly receiving current and consistent ledger data, from multiple\npeers. Each gossiped message is signed, thereby allowing Byzantine\nparticipants sending faked messages to be easily identified and the\ndistribution of the message(s) to unwanted targets to be prevented.\nPeers affected by delays, network partitions or other causations\nresulting in missed blocks, will eventually be synced up to the current\nledger state by contacting peers in possession of these missing blocks.  The gossip-based data dissemination protocol performs three primary\nfunctions on a Hyperledger Fabric network:   Manages peer discovery and channel membership, by continually\n    identifying available member peers, and eventually detecting peers\n    that have gone offline.  Disseminates ledger data across all peers on a channel. Any peer\n    with data that is out of sync with the rest of the channel\n    identifies the missing blocks and syncs itself by copying the\n    correct data.  Bring newly connected peers up to speed by allowing peer-to-peer\n    state transfer update of ledger data.   Gossip-based broadcasting operates by peers receiving messages from\nother peers on the channel, and then forwarding these messages to a\nnumber of randomly-selected peers on the channel, where this number is a\nconfigurable constant. Peers can also exercise a pull mechanism, rather\nthan waiting for delivery of a message. This cycle repeats, with the\nresult of channel membership, ledger and state information continually\nbeing kept current and in sync. For dissemination of new blocks, the leader  peer on the channel pulls the data from the ordering service\nand initiates gossip dissemination to peers.", 
            "title": "Gossip protocol"
        }, 
        {
            "location": "/gossip/#gossip-messaging", 
            "text": "Online peers indicate their availability by continually broadcasting\n\\\"alive\\\" messages, with each containing the  public key infrastructure\n(PKI)  ID and the signature of the sender over the message. Peers\nmaintain channel membership by collecting these alive messages; if no\npeer receives an alive message from a specific peer, this \\\"dead\\\" peer\nis eventually purged from channel membership. Because \\\"alive\\\" messages\nare cryptographically signed, malicious peers can never impersonate\nother peers, as they lack a signing key authorized by a root certificate\nauthority (CA).  In addition to the automatic forwarding of received messages, a state\nreconciliation process synchronizes  world state  across peers on each\nchannel. Each peer continually pulls blocks from other peers on the\nchannel, in order to repair its own state if discrepancies are\nidentified. Because fixed connectivity is not required to maintain\ngossip-based data dissemination, the process reliably provides data\nconsistency and integrity to the shared ledger, including tolerance for\nnode crashes.  Because channels are segregated, peers on one channel cannot message or\nshare information on any other channel. Though any peer can belong to\nmultiple channels, partitioned messaging prevents blocks from being\ndisseminated to peers that are not in the channel by applying message\nrouting policies based on peers\\' channel subscriptions.  |  Notes: \n| 1. Security of point-to-point messages are handled by the peer TLS\n  layer, and do not require signatures. Peers are authenticated by their\n  certificates, which are assigned by a CA. Although TLS certs are also\n  used, it is the peer certificates that are authenticated in the gossip\n  layer. Ledger blocks are signed by the ordering service, and then\n  delivered to the leader peers on a channel. 2. Authentication is\n  governed by the membership service provider for the peer. When the\n  peer connects to the channel for the first time, the TLS session binds\n  with the membership identity. This essentially authenticates each peer\n  to the connecting peer, with respect to membership in the network and\n  channel.", 
            "title": "Gossip messaging"
        }, 
        {
            "location": "/glossary/", 
            "text": "Needs Review\n\n\nGlossary\n\n\nTerminology is important, so that all Hyperledger Fabric users and\ndevelopers agree on what we mean by each specific term. What is\nchaincode, for example. The documentation will reference the glossary as\nneeded, but feel free to read the entire thing in one sitting if you\nlike; it\\'s pretty enlightening!\n\n\n::: {#Anchor-Peer}\nAnchor Peer\n\n\n\n\n:::\n\n\nA peer node on a channel that all other peers can discover and\ncommunicate with. Each \nMember\n on a channel has an anchor peer\n(or multiple anchor peers to prevent single point of failure), allowing\nfor peers belonging to different Members to discover all existing peers\non a channel.\n\n\n::: {#Block}\nBlock\n\n\n\n\n:::\n\n\nAn ordered set of transactions that is cryptographically linked to the\npreceding block(s) on a channel.\n\n\n::: {#Chain}\nChain\n\n\n\n\n:::\n\n\nThe ledger\\'s chain is a transaction log structured as hash-linked\nblocks of transactions. Peers receive blocks of transactions from the\nordering service, mark the block\\'s transactions as valid or invalid\nbased on endorsement policies and concurrency violations, and append the\nblock to the hash chain on the peer\\'s file system.\n\n\n::: {#chaincode}\nChaincode\n\n\n\n\n:::\n\n\nChaincode is software, running on a ledger, to encode assets and the\ntransaction instructions (business logic) for modifying the assets.\n\n\n::: {#Channel}\nChannel\n\n\n\n\n:::\n\n\nA channel is a private blockchain overlay which allows for data\nisolation and confidentiality. A channel-specific ledger is shared\nacross the peers in the channel, and transacting parties must be\nproperly authenticated to a channel in order to interact with it.\nChannels are defined by a \nConfiguration-Block\n.\n\n\n::: {#Commitment}\nCommitment\n\n\n\n\n:::\n\n\nEach \nPeer\n on a channel validates ordered blocks of transactions\nand then commits (writes/appends) the blocks to its replica of the\nchannel \nLedger\n. Peers also mark each transaction in each\nblock as valid or invalid.\n\n\n::: {#Concurrency-Control-Version-Check}\nConcurrency Control Version Check\n\n\n\n\n:::\n\n\nConcurrency Control Version Check is a method of keeping state in sync\nacross peers on a channel. Peers execute transactions in parallel, and\nbefore commitment to the ledger, peers check that the data read at\nexecution time has not changed. If the data read for the transaction has\nchanged between execution time and commitment time, then a Concurrency\nControl Version Check violation has occurred, and the transaction is\nmarked as invalid on the ledger and values are not updated in the state\ndatabase.\n\n\n::: {#Configuration-Block}\nConfiguration Block\n\n\n\n\n:::\n\n\nContains the configuration data defining members and policies for a\nsystem chain (ordering service) or channel. Any configuration\nmodifications to a channel or overall network (e.g. a member leaving or\njoining) will result in a new configuration block being appended to the\nappropriate chain. This block will contain the contents of the genesis\nblock, plus the delta.\n\n\nConsensus\n\n\nA broader term overarching the entire transactional flow, which serves\nto generate an agreement on the order and to confirm the correctness of\nthe set of transactions constituting a block.\n\n\n::: {#Current-State}\nCurrent State\n\n\n\n\n:::\n\n\nThe current state of the ledger represents the latest values for all\nkeys ever included in its chain transaction log. Peers commit the latest\nvalues to ledger current state for each valid transaction included in a\nprocessed block. Since current state represents all latest key values\nknown to the channel, it is sometimes referred to as World State.\nChaincode executes transaction proposals against current state data.\n\n\n::: {#Dynamic-Membership}\nDynamic Membership\n\n\n\n\n:::\n\n\nHyperledger Fabric supports the addition/removal of members, peers, and\nordering service nodes, without compromising the operationality of the\noverall network. Dynamic membership is critical when business\nrelationships adjust and entities need to be added/removed for various\nreasons.\n\n\n::: {#Endorsement}\nEndorsement\n\n\n\n\n:::\n\n\nRefers to the process where specific peer nodes execute a chaincode\ntransaction and return a proposal response to the client application.\nThe proposal response includes the chaincode execution response message,\nresults (read set and write set), and events, as well as a signature to\nserve as proof of the peer\\'s chaincode execution. Chaincode\napplications have corresponding endorsement policies, in which the\nendorsing peers are specified.\n\n\n::: {#Endorsement-policy}\nEndorsement policy\n\n\n\n\n:::\n\n\nDefines the peer nodes on a channel that must execute transactions\nattached to a specific chaincode application, and the required\ncombination of responses (endorsements). A policy could require that a\ntransaction be endorsed by a minimum number of endorsing peers, a\nminimum percentage of endorsing peers, or by all endorsing peers that\nare assigned to a specific chaincode application. Policies can be\ncurated based on the application and the desired level of resilience\nagainst misbehavior (deliberate or not) by the endorsing peers. A\ntransaction that is submitted must satisfy the endorsement policy before\nbeing marked as valid by committing peers. A distinct endorsement policy\nfor install and instantiate transactions is also required.\n\n\n::: {#Fabric-ca}\nHyperledger Fabric CA\n\n\n\n\n:::\n\n\nHyperledger Fabric CA is the default Certificate Authority component,\nwhich issues PKI-based certificates to network member organizations and\ntheir users. The CA issues one root certificate (rootCert) to each\nmember and one enrollment certificate (ECert) to each authorized user.\n\n\n::: {#Genesis-Block}\nGenesis Block\n\n\n\n\n:::\n\n\nThe configuration block that initializes a blockchain network or\nchannel, and also serves as the first block on a chain.\n\n\n::: {#Gossip-Protocol}\nGossip Protocol\n\n\n\n\n:::\n\n\nThe gossip data dissemination protocol performs three functions: 1)\nmanages peer discovery and channel membership; 2) disseminates ledger\ndata across all peers on the channel; 3) syncs ledger state across all\npeers on the channel. Refer to the [Gossip \\\ngossip>]{role=\"doc\"} topic\nfor more details.\n\n\n::: {#Initialize}\nInitialize\n\n\n\n\n:::\n\n\nA method to initialize a chaincode application.\n\n\nInstall\n\n\nThe process of placing a chaincode on a peer\\'s file system.\n\n\nInstantiate\n\n\nThe process of starting and initializing a chaincode application on a\nspecific channel. After instantiation, peers that have the chaincode\ninstalled can accept chaincode invocations.\n\n\n::: {#Invoke}\nInvoke\n\n\n\n\n:::\n\n\nUsed to call chaincode functions. A client application invokes chaincode\nby sending a transaction proposal to a peer. The peer will execute the\nchaincode and return an endorsed proposal response to the client\napplication. The client application will gather enough proposal\nresponses to satisfy an endorsement policy, and will then submit the\ntransaction results for ordering, validation, and commit. The client\napplication may choose not to submit the transaction results. For\nexample if the invoke only queried the ledger, the client application\ntypically would not submit the read-only transaction, unless there is\ndesire to log the read on the ledger for audit purpose. The invoke\nincludes a channel identifier, the chaincode function to invoke, and an\narray of arguments.\n\n\n::: {#Leading-Peer}\nLeading Peer\n\n\n\n\n:::\n\n\nEach \nMember\n can own multiple peers on each channel that it\nsubscribes to. One of these peers is serves as the leading peer for the\nchannel, in order to communicate with the network ordering service on\nbehalf of the member. The ordering service \\\"delivers\\\" blocks to the\nleading peer(s) on a channel, who then distribute them to other peers\nwithin the same member cluster.\n\n\n::: {#Ledger}\nLedger\n\n\n\n\n:::\n\n\nA ledger is a channel\\'s chain and current state data which is\nmaintained by each peer on the channel.\n\n\n::: {#Member}\nMember\n\n\n\n\n:::\n\n\nA legally separate entity that owns a unique root certificate for the\nnetwork. Network components such as peer nodes and application clients\nwill be linked to a member.\n\n\n::: {#MSP}\nMembership Service Provider\n\n\n\n\n:::\n\n\nThe Membership Service Provider (MSP) refers to an abstract component of\nthe system that provides credentials to clients, and peers for them to\nparticipate in a Hyperledger Fabric network. Clients use these\ncredentials to authenticate their transactions, and peers use these\ncredentials to authenticate transaction processing results\n(endorsements). While strongly connected to the transaction processing\ncomponents of the systems, this interface aims to have membership\nservices components defined, in such a way that alternate\nimplementations of this can be smoothly plugged in without modifying the\ncore of transaction processing components of the system.\n\n\n::: {#Membership-Services}\nMembership Services\n\n\n\n\n:::\n\n\nMembership Services authenticates, authorizes, and manages identities on\na permissioned blockchain network. The membership services code that\nruns in peers and orderers both authenticates and authorizes blockchain\noperations. It is a PKI-based implementation of the Membership Services\nProvider (MSP) abstraction.\n\n\n::: {#Ordering-Service}\nOrdering Service\n\n\n\n\n:::\n\n\nA defined collective of nodes that orders transactions into a block. The\nordering service exists independent of the peer processes and orders\ntransactions on a first-come-first-serve basis for all channel\\'s on the\nnetwork. The ordering service is designed to support pluggable\nimplementations beyond the out-of-the-box SOLO and Kafka varieties. The\nordering service is a common binding for the overall network; it\ncontains the cryptographic identity material tied to each\n\nMember\n.\n\n\n::: {#Peer}\nPeer\n\n\n\n\n:::\n\n\nA network entity that maintains a ledger and runs chaincode containers\nin order to perform read/write operations to the ledger. Peers are owned\nand maintained by members.\n\n\n::: {#Policy}\nPolicy\n\n\n\n\n:::\n\n\nThere are policies for endorsement, validation, chaincode management and\nnetwork/channel management.\n\n\n::: {#Proposal}\nProposal\n\n\n\n\n:::\n\n\nA request for endorsement that is aimed at specific peers on a channel.\nEach proposal is either an instantiate or an invoke (read/write)\nrequest.\n\n\n::: {#Query}\nQuery\n\n\n\n\n:::\n\n\nA query is a chaincode invocation which reads the ledger current state\nbut does not write to the ledger. The chaincode function may query\ncertain keys on the ledger, or may query for a set of keys on the\nledger. Since queries do not change ledger state, the client application\nwill typically not submit these read-only transactions for ordering,\nvalidation, and commit. Although not typical, the client application can\nchoose to submit the read-only transaction for ordering, validation, and\ncommit, for example if the client wants auditable proof on the ledger\nchain that it had knowledge of specific ledger state at a certain point\nin time.\n\n\n::: {#SDK}\nSoftware Development Kit (SDK)\n\n\n\n\n:::\n\n\nThe Hyperledger Fabric client SDK provides a structured environment of\nlibraries for developers to write and test chaincode applications. The\nSDK is fully configurable and extensible through a standard interface.\nComponents, including cryptographic algorithms for signatures, logging\nframeworks and state stores, are easily swapped in and out of the SDK.\nThe SDK provides APIs for transaction processing, membership services,\nnode traversal and event handling. The SDK comes in multiple flavors:\nNode.js, Java. and Python.\n\n\n::: {#State-DB}\nState Database\n\n\n\n\n:::\n\n\nCurrent state data is stored in a state database for efficient reads and\nqueries from chaincode. Supported databases include levelDB and couchDB.\n\n\n::: {#System-Chain}\nSystem Chain\n\n\n\n\n:::\n\n\nContains a configuration block defining the network at a system level.\nThe system chain lives within the ordering service, and similar to a\nchannel, has an initial configuration containing information such as:\nMSP information, policies, and configuration details. Any change to the\noverall network (e.g. a new org joining or a new ordering node being\nadded) will result in a new configuration block being added to the\nsystem chain.\n\n\nThe system chain can be thought of as the common binding for a channel\nor group of channels. For instance, a collection of financial\ninstitutions may form a consortium (represented through the system\nchain), and then proceed to create channels relative to their aligned\nand varying business agendas.\n\n\n::: {#Transaction}\nTransaction\n\n\n\n\n:::\n\n\nInvoke or instantiate results that are submitted for ordering,\nvalidation, and commit. Invokes are requests to read/write data from the\nledger. Instantiate is a request to start and initialize a chaincode on\na channel. Application clients gather invoke or instantiate responses\nfrom endorsing peers and package the results and endorsements into a\ntransaction that is submitted for ordering, validation, and commit.", 
            "title": "Glossary"
        }, 
        {
            "location": "/glossary/#glossary", 
            "text": "Terminology is important, so that all Hyperledger Fabric users and\ndevelopers agree on what we mean by each specific term. What is\nchaincode, for example. The documentation will reference the glossary as\nneeded, but feel free to read the entire thing in one sitting if you\nlike; it\\'s pretty enlightening!  ::: {#Anchor-Peer}\nAnchor Peer   :::  A peer node on a channel that all other peers can discover and\ncommunicate with. Each  Member  on a channel has an anchor peer\n(or multiple anchor peers to prevent single point of failure), allowing\nfor peers belonging to different Members to discover all existing peers\non a channel.  ::: {#Block}\nBlock   :::  An ordered set of transactions that is cryptographically linked to the\npreceding block(s) on a channel.  ::: {#Chain}\nChain   :::  The ledger\\'s chain is a transaction log structured as hash-linked\nblocks of transactions. Peers receive blocks of transactions from the\nordering service, mark the block\\'s transactions as valid or invalid\nbased on endorsement policies and concurrency violations, and append the\nblock to the hash chain on the peer\\'s file system.  ::: {#chaincode}\nChaincode   :::  Chaincode is software, running on a ledger, to encode assets and the\ntransaction instructions (business logic) for modifying the assets.  ::: {#Channel}\nChannel   :::  A channel is a private blockchain overlay which allows for data\nisolation and confidentiality. A channel-specific ledger is shared\nacross the peers in the channel, and transacting parties must be\nproperly authenticated to a channel in order to interact with it.\nChannels are defined by a  Configuration-Block .  ::: {#Commitment}\nCommitment   :::  Each  Peer  on a channel validates ordered blocks of transactions\nand then commits (writes/appends) the blocks to its replica of the\nchannel  Ledger . Peers also mark each transaction in each\nblock as valid or invalid.  ::: {#Concurrency-Control-Version-Check}\nConcurrency Control Version Check   :::  Concurrency Control Version Check is a method of keeping state in sync\nacross peers on a channel. Peers execute transactions in parallel, and\nbefore commitment to the ledger, peers check that the data read at\nexecution time has not changed. If the data read for the transaction has\nchanged between execution time and commitment time, then a Concurrency\nControl Version Check violation has occurred, and the transaction is\nmarked as invalid on the ledger and values are not updated in the state\ndatabase.  ::: {#Configuration-Block}\nConfiguration Block   :::  Contains the configuration data defining members and policies for a\nsystem chain (ordering service) or channel. Any configuration\nmodifications to a channel or overall network (e.g. a member leaving or\njoining) will result in a new configuration block being appended to the\nappropriate chain. This block will contain the contents of the genesis\nblock, plus the delta.", 
            "title": "Glossary"
        }, 
        {
            "location": "/glossary/#consensus", 
            "text": "A broader term overarching the entire transactional flow, which serves\nto generate an agreement on the order and to confirm the correctness of\nthe set of transactions constituting a block.  ::: {#Current-State}\nCurrent State   :::  The current state of the ledger represents the latest values for all\nkeys ever included in its chain transaction log. Peers commit the latest\nvalues to ledger current state for each valid transaction included in a\nprocessed block. Since current state represents all latest key values\nknown to the channel, it is sometimes referred to as World State.\nChaincode executes transaction proposals against current state data.  ::: {#Dynamic-Membership}\nDynamic Membership   :::  Hyperledger Fabric supports the addition/removal of members, peers, and\nordering service nodes, without compromising the operationality of the\noverall network. Dynamic membership is critical when business\nrelationships adjust and entities need to be added/removed for various\nreasons.  ::: {#Endorsement}\nEndorsement   :::  Refers to the process where specific peer nodes execute a chaincode\ntransaction and return a proposal response to the client application.\nThe proposal response includes the chaincode execution response message,\nresults (read set and write set), and events, as well as a signature to\nserve as proof of the peer\\'s chaincode execution. Chaincode\napplications have corresponding endorsement policies, in which the\nendorsing peers are specified.  ::: {#Endorsement-policy}\nEndorsement policy   :::  Defines the peer nodes on a channel that must execute transactions\nattached to a specific chaincode application, and the required\ncombination of responses (endorsements). A policy could require that a\ntransaction be endorsed by a minimum number of endorsing peers, a\nminimum percentage of endorsing peers, or by all endorsing peers that\nare assigned to a specific chaincode application. Policies can be\ncurated based on the application and the desired level of resilience\nagainst misbehavior (deliberate or not) by the endorsing peers. A\ntransaction that is submitted must satisfy the endorsement policy before\nbeing marked as valid by committing peers. A distinct endorsement policy\nfor install and instantiate transactions is also required.  ::: {#Fabric-ca}\nHyperledger Fabric CA   :::  Hyperledger Fabric CA is the default Certificate Authority component,\nwhich issues PKI-based certificates to network member organizations and\ntheir users. The CA issues one root certificate (rootCert) to each\nmember and one enrollment certificate (ECert) to each authorized user.  ::: {#Genesis-Block}\nGenesis Block   :::  The configuration block that initializes a blockchain network or\nchannel, and also serves as the first block on a chain.  ::: {#Gossip-Protocol}\nGossip Protocol   :::  The gossip data dissemination protocol performs three functions: 1)\nmanages peer discovery and channel membership; 2) disseminates ledger\ndata across all peers on the channel; 3) syncs ledger state across all\npeers on the channel. Refer to the [Gossip \\ gossip>]{role=\"doc\"} topic\nfor more details.  ::: {#Initialize}\nInitialize   :::  A method to initialize a chaincode application.", 
            "title": "Consensus"
        }, 
        {
            "location": "/glossary/#install", 
            "text": "The process of placing a chaincode on a peer\\'s file system.", 
            "title": "Install"
        }, 
        {
            "location": "/glossary/#instantiate", 
            "text": "The process of starting and initializing a chaincode application on a\nspecific channel. After instantiation, peers that have the chaincode\ninstalled can accept chaincode invocations.  ::: {#Invoke}\nInvoke   :::  Used to call chaincode functions. A client application invokes chaincode\nby sending a transaction proposal to a peer. The peer will execute the\nchaincode and return an endorsed proposal response to the client\napplication. The client application will gather enough proposal\nresponses to satisfy an endorsement policy, and will then submit the\ntransaction results for ordering, validation, and commit. The client\napplication may choose not to submit the transaction results. For\nexample if the invoke only queried the ledger, the client application\ntypically would not submit the read-only transaction, unless there is\ndesire to log the read on the ledger for audit purpose. The invoke\nincludes a channel identifier, the chaincode function to invoke, and an\narray of arguments.  ::: {#Leading-Peer}\nLeading Peer   :::  Each  Member  can own multiple peers on each channel that it\nsubscribes to. One of these peers is serves as the leading peer for the\nchannel, in order to communicate with the network ordering service on\nbehalf of the member. The ordering service \\\"delivers\\\" blocks to the\nleading peer(s) on a channel, who then distribute them to other peers\nwithin the same member cluster.  ::: {#Ledger}\nLedger   :::  A ledger is a channel\\'s chain and current state data which is\nmaintained by each peer on the channel.  ::: {#Member}\nMember   :::  A legally separate entity that owns a unique root certificate for the\nnetwork. Network components such as peer nodes and application clients\nwill be linked to a member.  ::: {#MSP}\nMembership Service Provider   :::  The Membership Service Provider (MSP) refers to an abstract component of\nthe system that provides credentials to clients, and peers for them to\nparticipate in a Hyperledger Fabric network. Clients use these\ncredentials to authenticate their transactions, and peers use these\ncredentials to authenticate transaction processing results\n(endorsements). While strongly connected to the transaction processing\ncomponents of the systems, this interface aims to have membership\nservices components defined, in such a way that alternate\nimplementations of this can be smoothly plugged in without modifying the\ncore of transaction processing components of the system.  ::: {#Membership-Services}\nMembership Services   :::  Membership Services authenticates, authorizes, and manages identities on\na permissioned blockchain network. The membership services code that\nruns in peers and orderers both authenticates and authorizes blockchain\noperations. It is a PKI-based implementation of the Membership Services\nProvider (MSP) abstraction.  ::: {#Ordering-Service}\nOrdering Service   :::  A defined collective of nodes that orders transactions into a block. The\nordering service exists independent of the peer processes and orders\ntransactions on a first-come-first-serve basis for all channel\\'s on the\nnetwork. The ordering service is designed to support pluggable\nimplementations beyond the out-of-the-box SOLO and Kafka varieties. The\nordering service is a common binding for the overall network; it\ncontains the cryptographic identity material tied to each Member .  ::: {#Peer}\nPeer   :::  A network entity that maintains a ledger and runs chaincode containers\nin order to perform read/write operations to the ledger. Peers are owned\nand maintained by members.  ::: {#Policy}\nPolicy   :::  There are policies for endorsement, validation, chaincode management and\nnetwork/channel management.  ::: {#Proposal}\nProposal   :::  A request for endorsement that is aimed at specific peers on a channel.\nEach proposal is either an instantiate or an invoke (read/write)\nrequest.  ::: {#Query}\nQuery   :::  A query is a chaincode invocation which reads the ledger current state\nbut does not write to the ledger. The chaincode function may query\ncertain keys on the ledger, or may query for a set of keys on the\nledger. Since queries do not change ledger state, the client application\nwill typically not submit these read-only transactions for ordering,\nvalidation, and commit. Although not typical, the client application can\nchoose to submit the read-only transaction for ordering, validation, and\ncommit, for example if the client wants auditable proof on the ledger\nchain that it had knowledge of specific ledger state at a certain point\nin time.  ::: {#SDK}\nSoftware Development Kit (SDK)   :::  The Hyperledger Fabric client SDK provides a structured environment of\nlibraries for developers to write and test chaincode applications. The\nSDK is fully configurable and extensible through a standard interface.\nComponents, including cryptographic algorithms for signatures, logging\nframeworks and state stores, are easily swapped in and out of the SDK.\nThe SDK provides APIs for transaction processing, membership services,\nnode traversal and event handling. The SDK comes in multiple flavors:\nNode.js, Java. and Python.  ::: {#State-DB}\nState Database   :::  Current state data is stored in a state database for efficient reads and\nqueries from chaincode. Supported databases include levelDB and couchDB.  ::: {#System-Chain}\nSystem Chain   :::  Contains a configuration block defining the network at a system level.\nThe system chain lives within the ordering service, and similar to a\nchannel, has an initial configuration containing information such as:\nMSP information, policies, and configuration details. Any change to the\noverall network (e.g. a new org joining or a new ordering node being\nadded) will result in a new configuration block being added to the\nsystem chain.  The system chain can be thought of as the common binding for a channel\nor group of channels. For instance, a collection of financial\ninstitutions may form a consortium (represented through the system\nchain), and then proceed to create channels relative to their aligned\nand varying business agendas.  ::: {#Transaction}\nTransaction   :::  Invoke or instantiate results that are submitted for ordering,\nvalidation, and commit. Invokes are requests to read/write data from the\nledger. Instantiate is a request to start and initialize a chaincode on\na channel. Application clients gather invoke or instantiate responses\nfrom endorsing peers and package the results and endorsements into a\ntransaction that is submitted for ordering, validation, and commit.", 
            "title": "Instantiate"
        }, 
        {
            "location": "/kafka/", 
            "text": "Bringing up a Kafka-based Ordering Service\n\n\nCaveat emptor\n\n\nThis document assumes that the reader generally knows how to set up a\nKafka cluster and a ZooKeeper ensemble. The purpose of this guide is to\nidentify the steps you need to take so as to have a set of Hyperledger\nFabric ordering service nodes (OSNs) use your Kafka cluster and provide\nan ordering service to your blockchain network.\n\n\nBig picture\n\n\nEach channel maps to a separate single-partition topic in Kafka. When an\nOSN receives transactions via the \nBroadcast\n RPC, it checks to make\nsure that the broadcasting client has permissions to write on the\nchannel, then relays (i.e. produces) those transactions to the\nappropriate partition in Kafka. This partition is also consumed by the\nOSN which groups the received transactions into blocks locally, persists\nthem in its local ledger, and serves them to receiving clients via the\n\nDeliver\n RPC. For low-level details, refer to \nthe document that\ndescribes how we came to this\ndesign\n\n--- Figure 8 is a schematic representation of the process described\nabove.\n\n\nSteps\n\n\nLet \nK\n and \nZ\n be the number of nodes in the Kafka cluster and the\nZooKeeper ensemble respectively:\n\n\n\n\nAt a minimum, \nK\n should be set to 4. (As we will explain in Step 4\n    below, this is the minimum number of nodes necessary in order to\n    exhibit crash fault tolerance, i.e. with 4 brokers, you can have 1\n    broker go down, all channels will continue to be writeable and\n    readable, and new channels can be created.)\n\n\nZ\n will either be 3, 5, or 7. It has to be an odd number to avoid\n    split-brain scenarios, and larger than 1 in order to avoid single\n    point of failures. Anything beyond 7 ZooKeeper servers is considered\n    an overkill.\n\n\n\n\nThen proceed as follows:\n\n\n\n\nOrderers: \nEncode the Kafka-related information in the network\\'s\n    genesis block.\n If you are using \nconfigtxgen\n, edit\n    \nconfigtx.yaml\n ---or pick a preset profile for the system\n    channel\\'s genesis block--- so that:\n\n\nOrderer.OrdererType\n is set to \nkafka\n.\n\n\nOrderer.Kafka.Brokers\n contains the address of \nat least two\n\n    of the Kafka brokers in your cluster in \nIP:port\n notation. The\n    list does not need to be exhaustive. (These are your bootstrap\n    brokers.)\n\n\n\n\n\n\nOrderers: \nSet the maximum block size.\n Each block will have at\n    most Orderer.AbsoluteMaxBytes bytes (not including headers), a value\n    that you can set in \nconfigtx.yaml\n. Let the value you pick here be\n    \nA\n and make note of it --- it will affect how you configure your\n    Kafka brokers in Step 6.\n\n\nOrderers: \nCreate the genesis block.\n Use \nconfigtxgen\n. The\n    settings you picked in Steps 3 and 4 above are system-wide settings,\n    i.e. they apply across the network for all the OSNs. Make note of\n    the genesis block\\'s location.\n\n\n\n\nKafka cluster: \nConfigure your Kafka brokers appropriately.\n\n    Ensure that every Kafka broker has these keys configured:\n\n\n\n\nunclean.leader.election.enable = false\n --- Data consistency is\n    key in a blockchain environment. We cannot have a channel leader\n    chosen outside of the in-sync replica set, or we run the risk of\n    overwriting the offsets that the previous leader produced, and\n    ---as a result--- rewrite the blockchain that the orderers\n    produce.\n\n\nmin.insync.replicas = M\n --- Where you pick a value \nM\n such\n    that \n1 \n M \n N\n (see \ndefault.replication.factor\n below). Data\n    is considered committed when it is written to at least \nM\n\n    replicas (which are then considered in-sync and belong to the\n    in-sync replica set, or ISR). In any other case, the write\n    operation returns an error. Then:\n\n\nIf up to \nN-M\n replicas ---out of the \nN\n that the channel\n    data is written to--- become unavailable, operations proceed\n    normally.\n\n\nIf more replicas become unavailable, Kafka cannot maintain\n    an ISR set of \nM,\n so it stops accepting writes. Reads work\n    without issues. The channel becomes writeable again when \nM\n\n    replicas get in-sync.\n\n\n\n\n\n\n\n\ndefault.replication.factor = N\n --- Where you pick a value \nN\n\n    such that \nN \n K\n. A replication factor of \nN\n means that each\n    channel will have its data replicated to \nN\n brokers. These are\n    the candidates for the ISR set of a channel. As we noted in the\n    \nmin.insync.replicas section\n above, not all of these brokers\n    have to be available all the time. \nN\n should be set \nstrictly\n    smaller\n to \nK\n because channel creations cannot go forward if\n    less than \nN\n brokers are up. So if you set \nN = K\n, a single\n    broker going down means that no new channels can be created on\n    the blockchain network --- the crash fault tolerance of the\n    ordering service is non-existent.\n\n\nBased on what we\\'ve described above, the minimum allowed values\nfor \nM\n and \nN\n are 2 and 3 respectively. This configuration\nallows for the creation of new channels to go forward, and for\nall channels to continue to be writeable.\n\n\n\n\n\n\nmessage.max.bytes\n and \nreplica.fetch.max.bytes\n should be set\n    to a value larger than \nA\n, the value you picked in\n    \nOrderer.AbsoluteMaxBytes\n in Step 4 above. Add some buffer to\n    account for headers --- 1 MiB is more than enough. The following\n    condition applies:\n\n\nOrderer.AbsoluteMaxBytes \n replica.fetch.max.bytes \n= message.max.bytes\n\n\n\n(For completeness, we note that \nmessage.max.bytes\n should be\nstrictly smaller to \nsocket.request.max.bytes\n which is set by\ndefault to 100 MiB. If you wish to have blocks larger than 100\nMiB you will need to edit the hard-coded value in\n\nbrokerConfig.Producer.MaxMessageBytes\n in\n\nfabric/orderer/kafka/config.go\n and rebuild the binary from\nsource. This is not advisable.)\n\n\n\n\n\n\nlog.retention.ms = -1\n. Until the ordering service adds support\n    for pruning of the Kafka logs, you should disable time-based\n    retention and prevent segments from expiring. (Size-based\n    retention ---see \nlog.retention.bytes\n--- is disabled by default\n    in Kafka at the time of this writing, so there\\'s no need to set\n    it explicitly.)\n\n\n\n\n\n\n\n\n\n\nOrderers: \nPoint each OSN to the genesis block.\n Edit\n    \nGeneral.GenesisFile\n in \norderer.yaml\n so that it points to the\n    genesis block created in Step 5 above. (While at it, ensure all\n    other keys in that YAML file are set appropriately.)\n\n\n\n\n\n\nOrderers: \nAdjust polling intervals and timeouts.\n (Optional\n    step.)\n\n\n\n\nThe \nKafka.Retry\n section in the \norderer.yaml\n file allows you\n    to adjust the frequency of the metadata/producer/consumer\n    requests, as well as the socket timeouts. (These are all\n    settings you would expect to see in a Kafka producer or\n    consumer.)\n\n\n\n\nAdditionally, when a new channel is created, or when an existing\n    channel is reloaded (in case of a just-restarted orderer), the\n    orderer interacts with the Kafka cluster in the following ways:\n\n\n\n\nIt creates a Kafka producer (writer) for the Kafka partition\n    that corresponds to the channel.\n\n\nIt uses that producer to post a no-op \nCONNECT\n message to\n    that partition.\n\n\nIt creates a Kafka consumer (reader) for that partition.\n\n\n\n\nIf any of these steps fail, you can adjust the frequency with\nwhich they are repeated. Specifically they will be re-attempted\nevery \nKafka.Retry.ShortInterval\n for a total of\n\nKafka.Retry.ShortTotal\n, and then every\n\nKafka.Retry.LongInterval\n for a total of\n\nKafka.Retry.LongTotal\n until they succeed. Note that the\norderer will be unable to write to or read from a channel until\nall of the steps above have been completed successfully.\n\n\n\n\n\n\n\n\n\n\nSet up the OSNs and Kafka cluster so that they communicate over\n    SSL.\n (Optional step, but highly recommended.) Refer to \nthe\n    Confluent guide\n for\n    the Kafka cluster side of the equation, and set the keys under\n    \nKafka.TLS\n in \norderer.yaml\n on every OSN accordingly.\n\n\n\n\nBring up the nodes in the following order: ZooKeeper ensemble,\n    Kafka cluster, ordering service nodes.\n\n\n\n\nAdditional considerations\n\n\n\n\nPreferred message size.\n In Step 4 above (see \nSteps\n\n    section) you can also set the preferred size of blocks by setting\n    the \nOrderer.Batchsize.PreferredMaxBytes\n key. Kafka offers higher\n    throughput when dealing with relatively small messages; aim for a\n    value no bigger than 1 MiB.\n\n\nUsing environment variables to override settings.\n When using the\n    sample Kafka and Zookeeper Docker images provided with Fabric (see\n    \nimages/kafka\n and \nimages/zookeeper\n respectively), you can\n    override a Kafka broker or a ZooKeeper server\\'s settings by using\n    environment variables. Replace the dots of the configuration key\n    with underscores --- e.g.\n    \nKAFKA_UNCLEAN_LEADER_ELECTION_ENABLE=false\n will allow you to\n    override the default value of \nunclean.leader.election.enable\n. The\n    same applies to the OSNs for their \nlocal\n configuration, i.e. what\n    can be set in \norderer.yaml\n. For example\n    \nORDERER_KAFKA_RETRY_SHORTINTERVAL=1s\n allows you to override the\n    default value for \nOrderer.Kafka.Retry.ShortInterval\n.\n\n\n\n\nSupported Kafka versions and upgrading\n\n\nFabric uses the \nsarama client\nlibrary\n and vendors a version of it\nthat supports the following Kafka client versions:\n\n\n\n\nVersion: 0.9.0\n\n\nVersion: 0.10.0\n\n\nVersion: 0.10.1\n\n\nVersion: 0.10.2\n\n\n\n\nThe sample Kafka server image provided by Fabric contains Kafka server\nversion \n0.10.2\n. Out of the box, Fabric\\'s ordering service nodes\ndefault to configuring their embedded Kafka client to match this\nversion. If you are not using the sample Kafka server image provided by\nFabric, ensure that you configure a Kafka client version that is\ncompatible with your Kafka server using the \nKafka.Version\n key in\n\norderer.yaml\n.\n\n\nDebugging\n\n\nSet \nGeneral.LogLevel\n to \nDEBUG\n and \nKafka.Verbose\n in \norderer.yaml\n\nto \ntrue\n.\n\n\nExample\n\n\nSample Docker Compose configuration files inline with the recommended\nsettings above can be found under the \nfabric/bddtests\n directory. Look\nfor \ndc-orderer-kafka-base.yml\n and \ndc-orderer-kafka.yml\n.", 
            "title": "Kafka"
        }, 
        {
            "location": "/kafka/#bringing-up-a-kafka-based-ordering-service", 
            "text": "", 
            "title": "Bringing up a Kafka-based Ordering Service"
        }, 
        {
            "location": "/kafka/#caveat-emptor", 
            "text": "This document assumes that the reader generally knows how to set up a\nKafka cluster and a ZooKeeper ensemble. The purpose of this guide is to\nidentify the steps you need to take so as to have a set of Hyperledger\nFabric ordering service nodes (OSNs) use your Kafka cluster and provide\nan ordering service to your blockchain network.", 
            "title": "Caveat emptor"
        }, 
        {
            "location": "/kafka/#big-picture", 
            "text": "Each channel maps to a separate single-partition topic in Kafka. When an\nOSN receives transactions via the  Broadcast  RPC, it checks to make\nsure that the broadcasting client has permissions to write on the\nchannel, then relays (i.e. produces) those transactions to the\nappropriate partition in Kafka. This partition is also consumed by the\nOSN which groups the received transactions into blocks locally, persists\nthem in its local ledger, and serves them to receiving clients via the Deliver  RPC. For low-level details, refer to  the document that\ndescribes how we came to this\ndesign \n--- Figure 8 is a schematic representation of the process described\nabove.", 
            "title": "Big picture"
        }, 
        {
            "location": "/kafka/#steps", 
            "text": "Let  K  and  Z  be the number of nodes in the Kafka cluster and the\nZooKeeper ensemble respectively:   At a minimum,  K  should be set to 4. (As we will explain in Step 4\n    below, this is the minimum number of nodes necessary in order to\n    exhibit crash fault tolerance, i.e. with 4 brokers, you can have 1\n    broker go down, all channels will continue to be writeable and\n    readable, and new channels can be created.)  Z  will either be 3, 5, or 7. It has to be an odd number to avoid\n    split-brain scenarios, and larger than 1 in order to avoid single\n    point of failures. Anything beyond 7 ZooKeeper servers is considered\n    an overkill.   Then proceed as follows:   Orderers:  Encode the Kafka-related information in the network\\'s\n    genesis block.  If you are using  configtxgen , edit\n     configtx.yaml  ---or pick a preset profile for the system\n    channel\\'s genesis block--- so that:  Orderer.OrdererType  is set to  kafka .  Orderer.Kafka.Brokers  contains the address of  at least two \n    of the Kafka brokers in your cluster in  IP:port  notation. The\n    list does not need to be exhaustive. (These are your bootstrap\n    brokers.)    Orderers:  Set the maximum block size.  Each block will have at\n    most Orderer.AbsoluteMaxBytes bytes (not including headers), a value\n    that you can set in  configtx.yaml . Let the value you pick here be\n     A  and make note of it --- it will affect how you configure your\n    Kafka brokers in Step 6.  Orderers:  Create the genesis block.  Use  configtxgen . The\n    settings you picked in Steps 3 and 4 above are system-wide settings,\n    i.e. they apply across the network for all the OSNs. Make note of\n    the genesis block\\'s location.   Kafka cluster:  Configure your Kafka brokers appropriately. \n    Ensure that every Kafka broker has these keys configured:   unclean.leader.election.enable = false  --- Data consistency is\n    key in a blockchain environment. We cannot have a channel leader\n    chosen outside of the in-sync replica set, or we run the risk of\n    overwriting the offsets that the previous leader produced, and\n    ---as a result--- rewrite the blockchain that the orderers\n    produce.  min.insync.replicas = M  --- Where you pick a value  M  such\n    that  1   M   N  (see  default.replication.factor  below). Data\n    is considered committed when it is written to at least  M \n    replicas (which are then considered in-sync and belong to the\n    in-sync replica set, or ISR). In any other case, the write\n    operation returns an error. Then:  If up to  N-M  replicas ---out of the  N  that the channel\n    data is written to--- become unavailable, operations proceed\n    normally.  If more replicas become unavailable, Kafka cannot maintain\n    an ISR set of  M,  so it stops accepting writes. Reads work\n    without issues. The channel becomes writeable again when  M \n    replicas get in-sync.     default.replication.factor = N  --- Where you pick a value  N \n    such that  N   K . A replication factor of  N  means that each\n    channel will have its data replicated to  N  brokers. These are\n    the candidates for the ISR set of a channel. As we noted in the\n     min.insync.replicas section  above, not all of these brokers\n    have to be available all the time.  N  should be set  strictly\n    smaller  to  K  because channel creations cannot go forward if\n    less than  N  brokers are up. So if you set  N = K , a single\n    broker going down means that no new channels can be created on\n    the blockchain network --- the crash fault tolerance of the\n    ordering service is non-existent.  Based on what we\\'ve described above, the minimum allowed values\nfor  M  and  N  are 2 and 3 respectively. This configuration\nallows for the creation of new channels to go forward, and for\nall channels to continue to be writeable.    message.max.bytes  and  replica.fetch.max.bytes  should be set\n    to a value larger than  A , the value you picked in\n     Orderer.AbsoluteMaxBytes  in Step 4 above. Add some buffer to\n    account for headers --- 1 MiB is more than enough. The following\n    condition applies:  Orderer.AbsoluteMaxBytes   replica.fetch.max.bytes  = message.max.bytes  (For completeness, we note that  message.max.bytes  should be\nstrictly smaller to  socket.request.max.bytes  which is set by\ndefault to 100 MiB. If you wish to have blocks larger than 100\nMiB you will need to edit the hard-coded value in brokerConfig.Producer.MaxMessageBytes  in fabric/orderer/kafka/config.go  and rebuild the binary from\nsource. This is not advisable.)    log.retention.ms = -1 . Until the ordering service adds support\n    for pruning of the Kafka logs, you should disable time-based\n    retention and prevent segments from expiring. (Size-based\n    retention ---see  log.retention.bytes --- is disabled by default\n    in Kafka at the time of this writing, so there\\'s no need to set\n    it explicitly.)      Orderers:  Point each OSN to the genesis block.  Edit\n     General.GenesisFile  in  orderer.yaml  so that it points to the\n    genesis block created in Step 5 above. (While at it, ensure all\n    other keys in that YAML file are set appropriately.)    Orderers:  Adjust polling intervals and timeouts.  (Optional\n    step.)   The  Kafka.Retry  section in the  orderer.yaml  file allows you\n    to adjust the frequency of the metadata/producer/consumer\n    requests, as well as the socket timeouts. (These are all\n    settings you would expect to see in a Kafka producer or\n    consumer.)   Additionally, when a new channel is created, or when an existing\n    channel is reloaded (in case of a just-restarted orderer), the\n    orderer interacts with the Kafka cluster in the following ways:   It creates a Kafka producer (writer) for the Kafka partition\n    that corresponds to the channel.  It uses that producer to post a no-op  CONNECT  message to\n    that partition.  It creates a Kafka consumer (reader) for that partition.   If any of these steps fail, you can adjust the frequency with\nwhich they are repeated. Specifically they will be re-attempted\nevery  Kafka.Retry.ShortInterval  for a total of Kafka.Retry.ShortTotal , and then every Kafka.Retry.LongInterval  for a total of Kafka.Retry.LongTotal  until they succeed. Note that the\norderer will be unable to write to or read from a channel until\nall of the steps above have been completed successfully.      Set up the OSNs and Kafka cluster so that they communicate over\n    SSL.  (Optional step, but highly recommended.) Refer to  the\n    Confluent guide  for\n    the Kafka cluster side of the equation, and set the keys under\n     Kafka.TLS  in  orderer.yaml  on every OSN accordingly.   Bring up the nodes in the following order: ZooKeeper ensemble,\n    Kafka cluster, ordering service nodes.", 
            "title": "Steps"
        }, 
        {
            "location": "/kafka/#additional-considerations", 
            "text": "Preferred message size.  In Step 4 above (see  Steps \n    section) you can also set the preferred size of blocks by setting\n    the  Orderer.Batchsize.PreferredMaxBytes  key. Kafka offers higher\n    throughput when dealing with relatively small messages; aim for a\n    value no bigger than 1 MiB.  Using environment variables to override settings.  When using the\n    sample Kafka and Zookeeper Docker images provided with Fabric (see\n     images/kafka  and  images/zookeeper  respectively), you can\n    override a Kafka broker or a ZooKeeper server\\'s settings by using\n    environment variables. Replace the dots of the configuration key\n    with underscores --- e.g.\n     KAFKA_UNCLEAN_LEADER_ELECTION_ENABLE=false  will allow you to\n    override the default value of  unclean.leader.election.enable . The\n    same applies to the OSNs for their  local  configuration, i.e. what\n    can be set in  orderer.yaml . For example\n     ORDERER_KAFKA_RETRY_SHORTINTERVAL=1s  allows you to override the\n    default value for  Orderer.Kafka.Retry.ShortInterval .", 
            "title": "Additional considerations"
        }, 
        {
            "location": "/kafka/#supported-kafka-versions-and-upgrading", 
            "text": "Fabric uses the  sarama client\nlibrary  and vendors a version of it\nthat supports the following Kafka client versions:   Version: 0.9.0  Version: 0.10.0  Version: 0.10.1  Version: 0.10.2   The sample Kafka server image provided by Fabric contains Kafka server\nversion  0.10.2 . Out of the box, Fabric\\'s ordering service nodes\ndefault to configuring their embedded Kafka client to match this\nversion. If you are not using the sample Kafka server image provided by\nFabric, ensure that you configure a Kafka client version that is\ncompatible with your Kafka server using the  Kafka.Version  key in orderer.yaml .", 
            "title": "Supported Kafka versions and upgrading"
        }, 
        {
            "location": "/kafka/#debugging", 
            "text": "Set  General.LogLevel  to  DEBUG  and  Kafka.Verbose  in  orderer.yaml \nto  true .", 
            "title": "Debugging"
        }, 
        {
            "location": "/kafka/#example", 
            "text": "Sample Docker Compose configuration files inline with the recommended\nsettings above can be found under the  fabric/bddtests  directory. Look\nfor  dc-orderer-kafka-base.yml  and  dc-orderer-kafka.yml .", 
            "title": "Example"
        }, 
        {
            "location": "/ledger/", 
            "text": "Ledger\n\n\nThe ledger is the sequenced, tamper-resistant record of all state\ntransitions. State transitions are a result of chaincode invocations\n(\\'transactions\\') submitted by participating parties. Each transaction\nresults in a set of asset key-value pairs that are committed to the\nledger as creates, updates, or deletes.\n\n\nThe ledger is comprised of a blockchain (\\'chain\\') to store the\nimmutable, sequenced record in blocks, as well as a state database to\nmaintain current state. There is one ledger per channel. Each peer\nmaintains a copy of the ledger for each channel of which they are a\nmember.\n\n\nChain\n\n\nThe chain is a transaction log, structured as hash-linked blocks, where\neach block contains a sequence of N transactions. The block header\nincludes a hash of the block\\'s transactions, as well as a hash of the\nprior block\\'s header. In this way, all transactions on the ledger are\nsequenced and cryptographically linked together. In other words, it is\nnot possible to tamper with the ledger data, without breaking the hash\nlinks. The hash of the latest block represents every transaction that\nhas come before, making it possible to ensure that all peers are in a\nconsistent and trusted state.\n\n\nThe chain is stored on the peer file system (either local or attached\nstorage), efficiently supporting the append-only nature of the\nblockchain workload.\n\n\nState Database\n\n\nThe ledger\\'s current state data represents the latest values for all\nkeys ever included in the chain transaction log. Since current state\nrepresents all latest key values known to the channel, it is sometimes\nreferred to as World State.\n\n\nChaincode invocations execute transactions against the current state\ndata. To make these chaincode interactions extremely efficient, the\nlatest values of all keys are stored in a state database. The state\ndatabase is simply an indexed view into the chain\\'s transaction log, it\ncan therefore be regenerated from the chain at any time. The state\ndatabase will automatically get recovered (or generated if needed) upon\npeer startup, before transactions are accepted.\n\n\nTransaction Flow\n\n\nAt a high level, the transaction flow consists of a transaction proposal\nsent by an application client to specific endorsing peers. The endorsing\npeers verify the client signature, and execute a chaincode function to\nsimulate the transaction. The output is the chaincode results, a set of\nkey/value versions that were read in the chaincode (read set), and the\nset of keys/values that were written in chaincode (write set). The\nproposal response gets sent back to the client along with an endorsement\nsignature.\n\n\nThe client assembles the endorsements into a transaction payload and\nbroadcasts it to an ordering service. The ordering service delivers\nordered transactions as blocks to all peers on a channel.\n\n\nBefore committal, peers will validate the transactions. First, they will\ncheck the endorsement policy to ensure that the correct allotment of the\nspecified peers have signed the results, and they will authenticate the\nsignatures against the transaction payload.\n\n\nSecondly, peers will perform a versioning check against the transaction\nread set, to ensure data integrity and protect against threats such as\ndouble-spending. Hyperledger Fabric has concurrency control whereby\ntransactions execute in parallel (by endorsers) to increase throughput,\nand upon commit (by all peers) each transaction is verified to ensure\nthat no other transaction has modified data it has read. In other words,\nit ensures that the data that was read during chaincode execution has\nnot changed since execution (endorsement) time, and therefore the\nexecution results are still valid and can be committed to the ledger\nstate database. If the data that was read has been changed by another\ntransaction, then the transaction in the block is marked as invalid and\nis not applied to the ledger state database. The client application is\nalerted, and can handle the error or retry as appropriate.\n\n\nSee the [txflow]{role=\"doc\"} and [readwrite]{role=\"doc\"} topics for a\ndeeper dive on transaction structure, concurrency control, and the state\nDB.\n\n\nState Database options\n\n\nState database options include LevelDB and CouchDB. LevelDB is the\ndefault key/value state database embedded in the peer process. CouchDB\nis an optional alternative external state database. Like the LevelDB\nkey/value store, CouchDB can store any binary data that is modeled in\nchaincode (CouchDB attachment functionality is used internally for\nnon-JSON binary data). But as a JSON document store, CouchDB\nadditionally enables rich query against the chaincode data, when\nchaincode values (e.g. assets) are modeled as JSON data.\n\n\nBoth LevelDB and CouchDB support core chaincode operations such as\ngetting and setting a key (asset), and querying based on keys. Keys can\nbe queried by range, and composite keys can be modeled to enable\nequivalence queries against multiple parameters. For example a composite\nkey of (owner,asset_id) can be used to query all assets owned by a\ncertain entity. These key-based queries can be used for read-only\nqueries against the ledger, as well as in transactions that update the\nledger.\n\n\nIf you model assets as JSON and use CouchDB, you can also perform\ncomplex rich queries against the chaincode data values, using the\nCouchDB JSON query language within chaincode. These types of queries are\nexcellent for understanding what is on the ledger. Proposal responses\nfor these types of queries are typically useful to the client\napplication, but are not typically submitted as transactions to the\nordering service. In fact, there is no guarantee the result set is\nstable between chaincode execution and commit time for rich queries, and\ntherefore rich queries are not appropriate for use in update\ntransactions, unless your application can guarantee the result set is\nstable between chaincode execution time and commit time, or can handle\npotential changes in subsequent transactions. For example, if you\nperform a rich query for all assets owned by Alice and transfer them to\nBob, a new asset may be assigned to Alice by another transaction between\nchaincode execution time and commit time, and you would miss this\n\\'phantom\\' item.\n\n\nCouchDB runs as a separate database process alongside the peer,\ntherefore there are additional considerations in terms of setup,\nmanagement, and operations. You may consider starting with the default\nembedded LevelDB, and move to CouchDB if you require the additional\ncomplex rich queries. It is a good practice to model chaincode asset\ndata as JSON, so that you have the option to perform complex rich\nqueries if needed in the future.\n\n\nCouchDB Configuration\n\n\nCouchDB is enabled as the state database by changing the stateDatabase\nconfiguration option from goleveldb to CouchDB. Additionally, the\n\ncouchDBAddress\n needs to configured to point to the CouchDB to be used\nby the peer. The username and password properties should be populated\nwith an admin username and password if CouchDB is configured with a\nusername and password. Additional options are provided in the\n\ncouchDBConfig\n section and are documented in place. Changes to the\n\ncore.yaml\n will be effective immediately after restarting the peer.\n\n\nYou can also pass in docker environment variables to override core.yaml\nvalues, for example \nCORE_LEDGER_STATE_STATEDATABASE\n and\n\nCORE_LEDGER_STATE_COUCHDBCONFIG_COUCHDBADDRESS\n.\n\n\nBelow is the \nstateDatabase\n section from \ncore.yaml\n:\n\n\n{.sourceCode .bash}\nstate:\n  # stateDatabase - options are \"goleveldb\", \"CouchDB\"\n  # goleveldb - default state database stored in goleveldb.\n  # CouchDB - store state database in CouchDB\n  stateDatabase: goleveldb\n  couchDBConfig:\n     # It is recommended to run CouchDB on the same server as the peer, and\n     # not map the CouchDB container port to a server port in docker-compose.\n     # Otherwise proper security must be provided on the connection between\n     # CouchDB client (on the peer) and server.\n     couchDBAddress: couchdb:5984\n     # This username must have read and write authority on CouchDB\n     username:\n     # The password is recommended to pass as an environment variable\n     # during start up (e.g. LEDGER_COUCHDBCONFIG_PASSWORD).\n     # If it is stored here, the file must be access control protected\n     # to prevent unintended users from discovering the password.\n     password:\n     # Number of retries for CouchDB errors\n     maxRetries: 3\n     # Number of retries for CouchDB errors during peer startup\n     maxRetriesOnStartup: 10\n     # CouchDB request timeout (unit: duration, e.g. 20s)\n     requestTimeout: 35s\n     # Limit on the number of records to return per query\n     queryLimit: 10000\n\n\nCouchDB hosted in docker containers supplied with Hyperledger Fabric\nhave the capability of setting the CouchDB username and password with\nenvironment variables passed in with the \nCOUCHDB_USER\n and\n\nCOUCHDB_PASSWORD\n environment variables using Docker Compose scripting.\n\n\nFor CouchDB installations outside of the docker images supplied with\nFabric, the \nlocal.ini\n file must be edited to set the admin username\nand password.\n\n\nDocker compose scripts only set the username and password at the\ncreation of the container. The \nlocal.ini\n file must be edited if the\nusername or password is to be changed after creation of the container.\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nCouchDB peer options are read on each peer startup.\n:::", 
            "title": "Ledger"
        }, 
        {
            "location": "/ledger/#ledger", 
            "text": "The ledger is the sequenced, tamper-resistant record of all state\ntransitions. State transitions are a result of chaincode invocations\n(\\'transactions\\') submitted by participating parties. Each transaction\nresults in a set of asset key-value pairs that are committed to the\nledger as creates, updates, or deletes.  The ledger is comprised of a blockchain (\\'chain\\') to store the\nimmutable, sequenced record in blocks, as well as a state database to\nmaintain current state. There is one ledger per channel. Each peer\nmaintains a copy of the ledger for each channel of which they are a\nmember.", 
            "title": "Ledger"
        }, 
        {
            "location": "/ledger/#chain", 
            "text": "The chain is a transaction log, structured as hash-linked blocks, where\neach block contains a sequence of N transactions. The block header\nincludes a hash of the block\\'s transactions, as well as a hash of the\nprior block\\'s header. In this way, all transactions on the ledger are\nsequenced and cryptographically linked together. In other words, it is\nnot possible to tamper with the ledger data, without breaking the hash\nlinks. The hash of the latest block represents every transaction that\nhas come before, making it possible to ensure that all peers are in a\nconsistent and trusted state.  The chain is stored on the peer file system (either local or attached\nstorage), efficiently supporting the append-only nature of the\nblockchain workload.", 
            "title": "Chain"
        }, 
        {
            "location": "/ledger/#state-database", 
            "text": "The ledger\\'s current state data represents the latest values for all\nkeys ever included in the chain transaction log. Since current state\nrepresents all latest key values known to the channel, it is sometimes\nreferred to as World State.  Chaincode invocations execute transactions against the current state\ndata. To make these chaincode interactions extremely efficient, the\nlatest values of all keys are stored in a state database. The state\ndatabase is simply an indexed view into the chain\\'s transaction log, it\ncan therefore be regenerated from the chain at any time. The state\ndatabase will automatically get recovered (or generated if needed) upon\npeer startup, before transactions are accepted.", 
            "title": "State Database"
        }, 
        {
            "location": "/ledger/#transaction-flow", 
            "text": "At a high level, the transaction flow consists of a transaction proposal\nsent by an application client to specific endorsing peers. The endorsing\npeers verify the client signature, and execute a chaincode function to\nsimulate the transaction. The output is the chaincode results, a set of\nkey/value versions that were read in the chaincode (read set), and the\nset of keys/values that were written in chaincode (write set). The\nproposal response gets sent back to the client along with an endorsement\nsignature.  The client assembles the endorsements into a transaction payload and\nbroadcasts it to an ordering service. The ordering service delivers\nordered transactions as blocks to all peers on a channel.  Before committal, peers will validate the transactions. First, they will\ncheck the endorsement policy to ensure that the correct allotment of the\nspecified peers have signed the results, and they will authenticate the\nsignatures against the transaction payload.  Secondly, peers will perform a versioning check against the transaction\nread set, to ensure data integrity and protect against threats such as\ndouble-spending. Hyperledger Fabric has concurrency control whereby\ntransactions execute in parallel (by endorsers) to increase throughput,\nand upon commit (by all peers) each transaction is verified to ensure\nthat no other transaction has modified data it has read. In other words,\nit ensures that the data that was read during chaincode execution has\nnot changed since execution (endorsement) time, and therefore the\nexecution results are still valid and can be committed to the ledger\nstate database. If the data that was read has been changed by another\ntransaction, then the transaction in the block is marked as invalid and\nis not applied to the ledger state database. The client application is\nalerted, and can handle the error or retry as appropriate.  See the [txflow]{role=\"doc\"} and [readwrite]{role=\"doc\"} topics for a\ndeeper dive on transaction structure, concurrency control, and the state\nDB.", 
            "title": "Transaction Flow"
        }, 
        {
            "location": "/ledger/#state-database-options", 
            "text": "State database options include LevelDB and CouchDB. LevelDB is the\ndefault key/value state database embedded in the peer process. CouchDB\nis an optional alternative external state database. Like the LevelDB\nkey/value store, CouchDB can store any binary data that is modeled in\nchaincode (CouchDB attachment functionality is used internally for\nnon-JSON binary data). But as a JSON document store, CouchDB\nadditionally enables rich query against the chaincode data, when\nchaincode values (e.g. assets) are modeled as JSON data.  Both LevelDB and CouchDB support core chaincode operations such as\ngetting and setting a key (asset), and querying based on keys. Keys can\nbe queried by range, and composite keys can be modeled to enable\nequivalence queries against multiple parameters. For example a composite\nkey of (owner,asset_id) can be used to query all assets owned by a\ncertain entity. These key-based queries can be used for read-only\nqueries against the ledger, as well as in transactions that update the\nledger.  If you model assets as JSON and use CouchDB, you can also perform\ncomplex rich queries against the chaincode data values, using the\nCouchDB JSON query language within chaincode. These types of queries are\nexcellent for understanding what is on the ledger. Proposal responses\nfor these types of queries are typically useful to the client\napplication, but are not typically submitted as transactions to the\nordering service. In fact, there is no guarantee the result set is\nstable between chaincode execution and commit time for rich queries, and\ntherefore rich queries are not appropriate for use in update\ntransactions, unless your application can guarantee the result set is\nstable between chaincode execution time and commit time, or can handle\npotential changes in subsequent transactions. For example, if you\nperform a rich query for all assets owned by Alice and transfer them to\nBob, a new asset may be assigned to Alice by another transaction between\nchaincode execution time and commit time, and you would miss this\n\\'phantom\\' item.  CouchDB runs as a separate database process alongside the peer,\ntherefore there are additional considerations in terms of setup,\nmanagement, and operations. You may consider starting with the default\nembedded LevelDB, and move to CouchDB if you require the additional\ncomplex rich queries. It is a good practice to model chaincode asset\ndata as JSON, so that you have the option to perform complex rich\nqueries if needed in the future.", 
            "title": "State Database options"
        }, 
        {
            "location": "/ledger/#couchdb-configuration", 
            "text": "CouchDB is enabled as the state database by changing the stateDatabase\nconfiguration option from goleveldb to CouchDB. Additionally, the couchDBAddress  needs to configured to point to the CouchDB to be used\nby the peer. The username and password properties should be populated\nwith an admin username and password if CouchDB is configured with a\nusername and password. Additional options are provided in the couchDBConfig  section and are documented in place. Changes to the core.yaml  will be effective immediately after restarting the peer.  You can also pass in docker environment variables to override core.yaml\nvalues, for example  CORE_LEDGER_STATE_STATEDATABASE  and CORE_LEDGER_STATE_COUCHDBCONFIG_COUCHDBADDRESS .  Below is the  stateDatabase  section from  core.yaml :  {.sourceCode .bash}\nstate:\n  # stateDatabase - options are \"goleveldb\", \"CouchDB\"\n  # goleveldb - default state database stored in goleveldb.\n  # CouchDB - store state database in CouchDB\n  stateDatabase: goleveldb\n  couchDBConfig:\n     # It is recommended to run CouchDB on the same server as the peer, and\n     # not map the CouchDB container port to a server port in docker-compose.\n     # Otherwise proper security must be provided on the connection between\n     # CouchDB client (on the peer) and server.\n     couchDBAddress: couchdb:5984\n     # This username must have read and write authority on CouchDB\n     username:\n     # The password is recommended to pass as an environment variable\n     # during start up (e.g. LEDGER_COUCHDBCONFIG_PASSWORD).\n     # If it is stored here, the file must be access control protected\n     # to prevent unintended users from discovering the password.\n     password:\n     # Number of retries for CouchDB errors\n     maxRetries: 3\n     # Number of retries for CouchDB errors during peer startup\n     maxRetriesOnStartup: 10\n     # CouchDB request timeout (unit: duration, e.g. 20s)\n     requestTimeout: 35s\n     # Limit on the number of records to return per query\n     queryLimit: 10000  CouchDB hosted in docker containers supplied with Hyperledger Fabric\nhave the capability of setting the CouchDB username and password with\nenvironment variables passed in with the  COUCHDB_USER  and COUCHDB_PASSWORD  environment variables using Docker Compose scripting.  For CouchDB installations outside of the docker images supplied with\nFabric, the  local.ini  file must be edited to set the admin username\nand password.  Docker compose scripts only set the username and password at the\ncreation of the container. The  local.ini  file must be edited if the\nusername or password is to be changed after creation of the container.  ::: {.note}\n::: {.admonition-title}\nNote\n:::  CouchDB peer options are read on each peer startup.\n:::", 
            "title": "CouchDB Configuration"
        }, 
        {
            "location": "/fabric-FAQ/", 
            "text": "Hyperledger Fabric FAQ\n\n\nEndorsement\n\n\nEndorsement architecture\n:\n\n\nQ.  How many peers in the network need to endorse a transaction?\n\n\nA. The number of peers required to endorse a transaction is driven by\nthe endorsement policy that is specified at chaincode deployment time.\n\n\nQ.  Does an application client need to connect to all peers?\n\n\nA. Clients only need to connect to as many peers as are required by the\nendorsement policy for the chaincode.\n\n\nSecurity \n Access Control\n\n\nData Privacy and Access Control\n:\n\n\nQ.  How do I ensure data privacy?\n\n\nA. There are various aspects to data privacy. First, you can segregate\nyour network into channels, where each channel represents a subset of\nparticipants that are authorized to see the data for the chaincodes that\nare deployed to that channel. Second, within a channel you can restrict\nthe input data to chaincode to the set of endorsers only, by using\nvisibility settings. The visibility setting will determine whether input\nand output chaincode data is included in the submitted transaction,\nversus just output data. Third, you can hash or encrypt the data before\ncalling chaincode. If you hash the data then you will need to provide a\nmeans to share the source data. If you encrypt the data then you will\nneed to provide a means to share the decryption keys. Fourth, you can\nrestrict data access to certain roles in your organization, by building\naccess control into the chaincode logic. Fifth, ledger data at rest can\nbe encrypted via file system encryption on the peer, and data in-transit\nis encrypted via TLS.\n\n\nQ.  Do the orderers see the transaction data?\n\n\nA. No, the orderers only order transactions, they do not open the\ntransactions. If you do not want the data to go through the orderers at\nall, and you are only concerned about the input data, then you can use\nvisibility settings. The visibility setting will determine whether input\nand output chaincode data is included in the submitted transaction,\nversus just output data. Therefore, the input data can be private to the\nendorsers only. If you do not want the orderers to see chaincode output,\nthen you can hash or encrypt the data before calling chaincode. If you\nhash the data then you will need to provide a meansto share the source\ndata. If you encrypt the data then you will need to provide a means to\nshare the decryption keys.\n\n\nApplication-side Programming Model\n\n\nTransaction execution result\n:\n\n\nQ.  How do application clients know the outcome of a transaction?\n\n\nA. The transaction simulation results are returned to the client by the\nendorser in the proposal response. If there are multiple endorsers, the\nclient can check that the responses are all the same, and submit the\nresults and endorsements for ordering and commitment. Ultimately the\ncommitting peers will validate or invalidate the transaction, and the\nclient becomes aware of the outcome via an event, that the SDK makes\navailable to the application client.\n\n\nLedger queries\n:\n\n\nQ.  How do I query the ledger data?\n\n\nA. Within chaincode you can query based on keys. Keys can be queried by\nrange, and composite keys can be modeled to enable equivalence queries\nagainst multiple parameters. For example a composite key of\n(owner,asset_id) can be used to query all assets owned by a certain\nentity. These key-based queries can be used for read-only queries\nagainst the ledger, as well as in transactions that update the ledger.\n\n\nIf you model asset data as JSON in chaincode and use CouchDB as the\nstate database, you can also perform complex rich queries against the\nchaincode data values, using the CouchDB JSON query language within\nchaincode. The application client can perform read-only queries, but\nthese responses are not typically submitted as part of transactions to\nthe ordering service.\n\n\nQ.  How do I query the historical data to understand data provenance?\n\n\nA. The chaincode API \nGetHistoryForKey()\n will return history of values\nfor a key.\n\n\nQ. How to guarantee the query result is correct, especially when the\npeer being queried may be recovering and catching up on block\nprocessing?\n\n\nA. The client can query multiple peers, compare their block heights,\ncompare their query results, and favor the peers at the higher block\nheights.\n\n\nChaincode (Smart Contracts and Digital Assets)\n\n\nQ.  Does Hyperledger Fabric support smart contract logic?\n\n\nA. Yes. We call this feature [chaincode]{role=\"ref\"}. It is our\ninterpretation of the smart contract method/algorithm, with additional\nfeatures.\n\n\nA chaincode is programmatic code deployed on the network, where it is\nexecuted and validated by chain validators together during the consensus\nprocess. Developers can use chaincodes to develop business contracts,\nasset definitions, and collectively-managed decentralized applications.\n\n\nQ.  How do I create a business contract?\n\n\nA. There are generally two ways to develop business contracts: the first\nway is to code individual contracts into standalone instances of\nchaincode; the second way, and probably the more efficient way, is to\nuse chaincode to create decentralized applications that manage the life\ncycle of one or multiple types of business contracts, and let end users\ninstantiate instances of contracts within these applications.\n\n\nQ.  How do I create assets?\n\n\nA. Users can use chaincode (for business rules) and membership service\n(for digital tokens) to design assets, as well as the logic that manages\nthem.\n\n\nThere are two popular approaches to defining assets in most blockchain\nsolutions: the stateless UTXO model, where account balances are encoded\ninto past transaction records; and the account model, where account\nbalances are kept in state storage space on the ledger.\n\n\nEach approach carries its own benefits and drawbacks. This blockchain\ntechnology does not advocate either one over the other. Instead, one of\nour first requirements was to ensure that both approaches can be easily\nimplemented.\n\n\nQ.  Which languages are supported for writing chaincode?\n\n\nA. Chaincode can be written in any programming language and executed in\ncontainers. The first fully supported chaincode language is Golang.\n\n\nSupport for additional languages and the development of a templating\nlanguage have been discussed, and more details will be released in the\nnear future.\n\n\nIt is also possible to build Hyperledger Fabric applications using\n\nHyperledger Composer\n.\n\n\nQ.  Does the Hyperledger Fabric have native currency?\n\n\nA. No. However, if you really need a native currency for your chain\nnetwork, you can develop your own native currency with chaincode. One\ncommon attribute of native currency is that some amount will get\ntransacted (the chaincode defining that currency will get called) every\ntime a transaction is processed on its chain.\n\n\nDifferences in Most Recent Releases -----------Q. As part of\nthe v1.0.0 release, what are the highlight differences between v0.6 and\nv1.0?\n\n\nA. The differences between any subsequent releases are provided together\nwith the \nRelease\nNotes\n.\nSince Fabric is a pluggable modular framework, you can refer to the\n\ndesign-docs\n\nfor further information of these difference.\n\n\nQ.  Where to get help for the technical questions not answered above?\nR.  Please use\n    \nStackOverflow\n.", 
            "title": "FAQ"
        }, 
        {
            "location": "/fabric-FAQ/#hyperledger-fabric-faq", 
            "text": "", 
            "title": "Hyperledger Fabric FAQ"
        }, 
        {
            "location": "/fabric-FAQ/#endorsement", 
            "text": "Endorsement architecture :  Q.  How many peers in the network need to endorse a transaction?  A. The number of peers required to endorse a transaction is driven by\nthe endorsement policy that is specified at chaincode deployment time.  Q.  Does an application client need to connect to all peers?  A. Clients only need to connect to as many peers as are required by the\nendorsement policy for the chaincode.", 
            "title": "Endorsement"
        }, 
        {
            "location": "/fabric-FAQ/#security-access-control", 
            "text": "Data Privacy and Access Control :  Q.  How do I ensure data privacy?  A. There are various aspects to data privacy. First, you can segregate\nyour network into channels, where each channel represents a subset of\nparticipants that are authorized to see the data for the chaincodes that\nare deployed to that channel. Second, within a channel you can restrict\nthe input data to chaincode to the set of endorsers only, by using\nvisibility settings. The visibility setting will determine whether input\nand output chaincode data is included in the submitted transaction,\nversus just output data. Third, you can hash or encrypt the data before\ncalling chaincode. If you hash the data then you will need to provide a\nmeans to share the source data. If you encrypt the data then you will\nneed to provide a means to share the decryption keys. Fourth, you can\nrestrict data access to certain roles in your organization, by building\naccess control into the chaincode logic. Fifth, ledger data at rest can\nbe encrypted via file system encryption on the peer, and data in-transit\nis encrypted via TLS.  Q.  Do the orderers see the transaction data?  A. No, the orderers only order transactions, they do not open the\ntransactions. If you do not want the data to go through the orderers at\nall, and you are only concerned about the input data, then you can use\nvisibility settings. The visibility setting will determine whether input\nand output chaincode data is included in the submitted transaction,\nversus just output data. Therefore, the input data can be private to the\nendorsers only. If you do not want the orderers to see chaincode output,\nthen you can hash or encrypt the data before calling chaincode. If you\nhash the data then you will need to provide a meansto share the source\ndata. If you encrypt the data then you will need to provide a means to\nshare the decryption keys.", 
            "title": "Security &amp; Access Control"
        }, 
        {
            "location": "/fabric-FAQ/#application-side-programming-model", 
            "text": "Transaction execution result :  Q.  How do application clients know the outcome of a transaction?  A. The transaction simulation results are returned to the client by the\nendorser in the proposal response. If there are multiple endorsers, the\nclient can check that the responses are all the same, and submit the\nresults and endorsements for ordering and commitment. Ultimately the\ncommitting peers will validate or invalidate the transaction, and the\nclient becomes aware of the outcome via an event, that the SDK makes\navailable to the application client.  Ledger queries :  Q.  How do I query the ledger data?  A. Within chaincode you can query based on keys. Keys can be queried by\nrange, and composite keys can be modeled to enable equivalence queries\nagainst multiple parameters. For example a composite key of\n(owner,asset_id) can be used to query all assets owned by a certain\nentity. These key-based queries can be used for read-only queries\nagainst the ledger, as well as in transactions that update the ledger.  If you model asset data as JSON in chaincode and use CouchDB as the\nstate database, you can also perform complex rich queries against the\nchaincode data values, using the CouchDB JSON query language within\nchaincode. The application client can perform read-only queries, but\nthese responses are not typically submitted as part of transactions to\nthe ordering service.  Q.  How do I query the historical data to understand data provenance?  A. The chaincode API  GetHistoryForKey()  will return history of values\nfor a key.  Q. How to guarantee the query result is correct, especially when the\npeer being queried may be recovering and catching up on block\nprocessing?  A. The client can query multiple peers, compare their block heights,\ncompare their query results, and favor the peers at the higher block\nheights.", 
            "title": "Application-side Programming Model"
        }, 
        {
            "location": "/fabric-FAQ/#chaincode-smart-contracts-and-digital-assets", 
            "text": "Q.  Does Hyperledger Fabric support smart contract logic?  A. Yes. We call this feature [chaincode]{role=\"ref\"}. It is our\ninterpretation of the smart contract method/algorithm, with additional\nfeatures.  A chaincode is programmatic code deployed on the network, where it is\nexecuted and validated by chain validators together during the consensus\nprocess. Developers can use chaincodes to develop business contracts,\nasset definitions, and collectively-managed decentralized applications.  Q.  How do I create a business contract?  A. There are generally two ways to develop business contracts: the first\nway is to code individual contracts into standalone instances of\nchaincode; the second way, and probably the more efficient way, is to\nuse chaincode to create decentralized applications that manage the life\ncycle of one or multiple types of business contracts, and let end users\ninstantiate instances of contracts within these applications.  Q.  How do I create assets?  A. Users can use chaincode (for business rules) and membership service\n(for digital tokens) to design assets, as well as the logic that manages\nthem.  There are two popular approaches to defining assets in most blockchain\nsolutions: the stateless UTXO model, where account balances are encoded\ninto past transaction records; and the account model, where account\nbalances are kept in state storage space on the ledger.  Each approach carries its own benefits and drawbacks. This blockchain\ntechnology does not advocate either one over the other. Instead, one of\nour first requirements was to ensure that both approaches can be easily\nimplemented.  Q.  Which languages are supported for writing chaincode?  A. Chaincode can be written in any programming language and executed in\ncontainers. The first fully supported chaincode language is Golang.  Support for additional languages and the development of a templating\nlanguage have been discussed, and more details will be released in the\nnear future.  It is also possible to build Hyperledger Fabric applications using Hyperledger Composer .  Q.  Does the Hyperledger Fabric have native currency?  A. No. However, if you really need a native currency for your chain\nnetwork, you can develop your own native currency with chaincode. One\ncommon attribute of native currency is that some amount will get\ntransacted (the chaincode defining that currency will get called) every\ntime a transaction is processed on its chain.  Differences in Most Recent Releases -----------Q. As part of\nthe v1.0.0 release, what are the highlight differences between v0.6 and\nv1.0?  A. The differences between any subsequent releases are provided together\nwith the  Release\nNotes .\nSince Fabric is a pluggable modular framework, you can refer to the design-docs \nfor further information of these difference.  Q.  Where to get help for the technical questions not answered above?\nR.  Please use\n     StackOverflow .", 
            "title": "Chaincode (Smart Contracts and Digital Assets)"
        }, 
        {
            "location": "/releases/", 
            "text": "Release Notes\n\n\nv1.1.0-preview\n\nNovember 1, 2017\n\n\nRelease Notes\n\n\nThis is a \npreview\n release of the up-coming 1.1 release. We are not\nfeature complete for 1.1 just yet, but we wanted to get the following\nfunctionality published to gain some early community feedback on the\nfollowing features:\n\n\n\n\n\n\nFAB-2331\n - Node.js\n    Chaincode\n\n\nFAB-5363\n - Node.js\n    SDK Connection Profile\n\n\nFAB-830\n -\n    Encryption library for chaincode\n\n\nFAB-5346\n -\n    Attribute-based Access Control\n\n\nFAB-6089\n -\n    Chaincode APIs to retrieve creator cert info\n\n\nFAB-6421\n -\n    Performance improvements\n\n\n\n\n\n\nAdditionally, there are the usual bug fixes, documentation and test\ncoverage improvements, UX improvements based on user feedback and\nchanges to address a variety of static scan findings (unused code,\nstatic security scanning, spelling, linting and more).\n\n\nKnown Vulnerabilities\n\n\nnone\n\n\nResolved Vulnerabilities\n\n\nnone\n\n\nKnown Issues \n Workarounds\n\n\nThe fabric-ccenv image which is used to build chaincode, currently\nincludes the github.com/hyperledger/fabric/core/chaincode/shim\n(\\\"shim\\\") package. This is convenient, as it provides the ability to\npackage chaincode without the need to include the \\\"shim\\\". However,\nthis may cause issues in future releases (and/or when trying to use\npackages which are included by the \\\"shim\\\").\n\n\nIn order to avoid any issues, users are advised to manually vendor the\n\\\"shim\\\" package with their chaincode prior to using the peer CLI for\npackaging and/or for installing chaincode.\n\n\nPlease refer to \nFAB-5177\n\nfor more details, and kindly be aware that given the above, we may end\nup changing the fabric-ccenv in the future.\n\n\nChange\nLog\n\n\nv1.0.4\n\nOctober 31, 2017\n\n\nBug fixes, documentation and test coverage improvements, UX improvements\nbased on user feedback and changes to address a variety of static scan\nfindings (unused code, static security scanning, spelling, linting and\nmore).\n\n\nKnown Vulnerabilities\n\n\nnone\n\n\nResolved Vulnerabilities\n\n\nnone\n\n\nKnown Issues \n Workarounds\n\n\nThe fabric-ccenv image which is used to build chaincode, currently\nincludes the github.com/hyperledger/fabric/core/chaincode/shim\n(\\\"shim\\\") package. This is convenient, as it provides the ability to\npackage chaincode without the need to include the \\\"shim\\\". However,\nthis may cause issues in future releases (and/or when trying to use\npackages which are included by the \\\"shim\\\").\n\n\nIn order to avoid any issues, users are advised to manually vendor the\n\\\"shim\\\" package with their chaincode prior to using the peer CLI for\npackaging and/or for installing chaincode.\n\n\nPlease refer to \nhttps://jira.hyperledger.org/browse/FAB-5177\n for more\ndetails, and kindly be aware that given the above, we may end up\nchanging the fabric-ccenv in the future.\n\n\nChange\nLog\n\n\nv1.0.3\n\nOctober 3, 2017\n\n\nBug fixes, documentation and test coverage improvements, UX improvements\nbased on user feedback and changes to address a variety of static scan\nfindings (unused code, static security scanning, spelling, linting and\nmore).\n\n\nKnown Vulnerabilities none\n\n\nResolved Vulnerabilities none\n\n\nKnown Issues \n Workarounds The fabric-ccenv image which is used to build\nchaincode, currently includes the\ngithub.com/hyperledger/fabric/core/chaincode/shim (\\\"shim\\\") package.\nThis is convenient, as it provides the ability to package chaincode\nwithout the need to include the \\\"shim\\\". However, this may cause issues\nin future releases (and/or when trying to use packages which are\nincluded by the \\\"shim\\\").\n\n\nIn order to avoid any issues, users are advised to manually vendor the\n\\\"shim\\\" package with their chaincode prior to using the peer CLI for\npackaging and/or for installing chaincode.\n\n\nPlease refer to \nhttps://jira.hyperledger.org/browse/FAB-5177\n for more\ndetails, and kindly be aware that given the above, we may end up\nchanging the fabric-ccenv in the future.\n\n\nChange\nLog\n\n\nv1.0.2\n\nAugust 31, 2017\n\n\nBug fixes, documentation and test coverage improvements, UX improvements\nbased on user feedback and changes to address a variety of static scan\nfindings (unused code, static security scanning, spelling, linting and\nmore).\n\n\nKnown Vulnerabilities none\n\n\nResolved Vulnerabilities \nhttps://jira.hyperledger.org/browse/FAB-5753\n\n\nhttps://jira.hyperledger.org/browse/FAB-5899\n\n\nKnown Issues \n Workarounds The fabric-ccenv image which is used to build\nchaincode, currently includes the\ngithub.com/hyperledger/fabric/core/chaincode/shim (\\\"shim\\\") package.\nThis is convenient, as it provides the ability to package chaincode\nwithout the need to include the \\\"shim\\\". However, this may cause issues\nin future releases (and/or when trying to use packages which are\nincluded by the \\\"shim\\\").\n\n\nIn order to avoid any issues, users are advised to manually vendor the\n\\\"shim\\\" package with their chaincode prior to using the peer CLI for\npackaging and/or for installing chaincode.\n\n\nPlease refer to \nhttps://jira.hyperledger.org/browse/FAB-5177\n for more\ndetails, and kindly be aware that given the above, we may end up\nchanging the fabric-ccenv in the future.\n\n\nChange\nLog\n\n\nv1.0.1\n\nAugust 5, 2017\n\n\nBug fixes, documentation and test coverage improvements, UX improvements\nbased on user feedback and changes to address a variety of static scan\nfindings (unused code, static security scanning, spelling, linting and\nmore).\n\n\nKnown Vulnerabilities none\n\n\nResolved Vulnerabilities \nhttps://jira.hyperledger.org/browse/FAB-5329\n\n\nhttps://jira.hyperledger.org/browse/FAB-5330\n\n\nhttps://jira.hyperledger.org/browse/FAB-5353\n\n\nhttps://jira.hyperledger.org/browse/FAB-5529\n\n\nhttps://jira.hyperledger.org/browse/FAB-5606\n\n\nhttps://jira.hyperledger.org/browse/FAB-5627\n\n\nKnown Issues \n Workarounds The fabric-ccenv image which is used to build\nchaincode, currently includes the\ngithub.com/hyperledger/fabric/core/chaincode/shim (\\\"shim\\\") package.\nThis is convenient, as it provides the ability to package chaincode\nwithout the need to include the \\\"shim\\\". However, this may cause issues\nin future releases (and/or when trying to use packages which are\nincluded by the \\\"shim\\\").\n\n\nIn order to avoid any issues, users are advised to manually vendor the\n\\\"shim\\\" package with their chaincode prior to using the peer CLI for\npackaging and/or for installing chaincode.\n\n\nPlease refer to \nhttps://jira.hyperledger.org/browse/FAB-5177\n for more\ndetails, and kindly be aware that given the above, we may end up\nchanging the fabric-ccenv in the future.\n\n\nChange\nLog\n\n\nv1.0.0\n July\n11, 2017\n\n\nBug fixes, documentation and test coverage improvements, UX improvements\nbased on user feedback and changes to address a variety of static scan\nfindings (removal of unused code, static security scanning, spelling,\nlinting and more).\n\n\nKnown Vulnerabilities none\n\n\nResolved Vulnerabilities \nhttps://jira.hyperledger.org/browse/FAB-5207\n\n\nKnown Issues \n Workarounds The fabric-ccenv image which is used to build\nchaincode, currently includes the\ngithub.com/hyperledger/fabric/core/chaincode/shim (\\\"shim\\\") package.\nThis is convenient, as it provides the ability to package chaincode\nwithout the need to include the \\\"shim\\\". However, this may cause issues\nin future releases (and/or when trying to use packages which are\nincluded by the \\\"shim\\\").\n\n\nIn order to avoid any issues, users are advised to manually vendor the\n\\\"shim\\\" package with their chaincode prior to using the peer CLI for\npackaging and/or for installing chaincode.\n\n\nPlease refer to \nhttps://jira.hyperledger.org/browse/FAB-5177\n for more\ndetails, and kindly be aware that given the above, we may end up\nchanging the fabric-ccenv in the future.\n\n\nChange\nLog\n\n\nv1.0.0-rc1\n\nJune 23, 2017\n\n\nBug fixes, documentation and test coverage improvements, UX improvements\nbased on user feedback and changes to address a variety of static scan\nfindings (unused code, static security scanning, spelling, linting and\nmore).\n\n\nKnown Vulnerabilities none\n\n\nResolved Vulnerabilities \nhttps://jira.hyperledger.org/browse/FAB-4856\n\n\nhttps://jira.hyperledger.org/browse/FAB-4848\n\n\nhttps://jira.hyperledger.org/browse/FAB-4751\n\n\nhttps://jira.hyperledger.org/browse/FAB-4626\n\n\nhttps://jira.hyperledger.org/browse/FAB-4567\n\n\nhttps://jira.hyperledger.org/browse/FAB-3715\n\n\nKnown Issues \n Workarounds none\n\n\nChange\nLog\n\n\nv1.0.0-beta\n\nJune 8, 2017\n\n\nBug fixes, documentation and test coverage improvements, UX improvements\nbased on user feedback and changes to address a variety of static scan\nfindings (unused code, static security scanning, spelling, linting and\nmore).\n\n\nUpgraded to \nlatest version\n\n(a precursor to 1.4.0) of gRPC-go and implemented keep-alive feature for\nimproved resiliency.\n\n\nAdded a \nnew\ntool\n\nconfigtxlator to enable users to translate the contents of a channel\nconfiguration transaction into a human readable form.\n\n\nKnown Vulnerabilities\n\n\nnone\n\n\nResolved Vulnerabilities\n\n\nnone\n\n\nKnown Issues \n Workarounds\n\n\nBCCSP content in the configtx.yaml has been\n\nremoved\n. This\nchange will cause a panic when running configtxgen tool with a\nconfigtx.yaml file that includes the removed BCCSP content.\n\n\nJava Chaincode support has been disabled until post 1.0.0 as it is not\nyet fully mature. It may be re-enabled for experimentation by cloning\nthe hyperledger/fabric repository, reversing \nthis\ncommit\n and\nbuilding your own fork.\n\n\nChange\nLog\n\n\nv1.0.0-alpha2\n\n\nThe second alpha release of the v1.0.0 Hyperledger Fabric. The code is\nnow feature complete. From now until the v1.0.0 release, the community\nis focused on documentation improvements, testing, hardening, bug fixing\nand tooling. We will be releasing successive release candidates\nperiodically as the release firms up.\n\n\nChange\nLog\n\n\nv1.0.0-alpha\n\nMarch 16, 2017\n\n\nThe first alpha release of the v1.0.0 Hyperledger Fabric. The code is\nbeing made available to developers to begin exploring the v1.0\narchitecture.\n\n\nChange\nLog\n\n\nv0.6-preview\n\nSeptember 16, 2016\n\n\nA developer preview release of the Hyperledger Fabric intended to\nexercise the release logistics and stabilize a set of capabilities for\ndevelopers to try out. This will be the last release under the original\narchitecture. All subsequent releases will deliver on the v1.0\narchitecture.\n\n\nChange\nLog\n\n\nv0.5-developer-preview\n\nJune 17, 2016\n\n\nA developer preview release of the Hyperledger Fabric intended to\nexercise the release logistics and stabilize a set of capabilities for\ndevelopers to try out.\n\n\nKey features:\n\n\nPermissioned blockchain with immediate finality Chaincode (aka smart\ncontract) execution environments Docker container (user chaincode)\nIn-process with peer (system chaincode) Pluggable consensus with PBFT,\nNOOPS (development mode), SIEVE (prototype) Event framework supports\npre-defined and custom events Client SDK (Node.js), basic REST APIs and\nCLIs Known Key Bugs and work in progress\n\n\n\n\n1895 - Client SDK interfaces may crash if wrong parameter specified\n\n\n1901 - Slow response after a few hours of stress testing\n\n\n1911 - Missing peer event listener on the client SDK\n\n\n889 - The attributes in the TCert are not encrypted. This work is\n    still on-going", 
            "title": "Release Notes"
        }, 
        {
            "location": "/releases/#release-notes", 
            "text": "v1.1.0-preview \nNovember 1, 2017", 
            "title": "Release Notes"
        }, 
        {
            "location": "/releases/#release-notes_1", 
            "text": "This is a  preview  release of the up-coming 1.1 release. We are not\nfeature complete for 1.1 just yet, but we wanted to get the following\nfunctionality published to gain some early community feedback on the\nfollowing features:    FAB-2331  - Node.js\n    Chaincode  FAB-5363  - Node.js\n    SDK Connection Profile  FAB-830  -\n    Encryption library for chaincode  FAB-5346  -\n    Attribute-based Access Control  FAB-6089  -\n    Chaincode APIs to retrieve creator cert info  FAB-6421  -\n    Performance improvements    Additionally, there are the usual bug fixes, documentation and test\ncoverage improvements, UX improvements based on user feedback and\nchanges to address a variety of static scan findings (unused code,\nstatic security scanning, spelling, linting and more).", 
            "title": "Release Notes"
        }, 
        {
            "location": "/releases/#known-vulnerabilities", 
            "text": "none", 
            "title": "Known Vulnerabilities"
        }, 
        {
            "location": "/releases/#resolved-vulnerabilities", 
            "text": "none", 
            "title": "Resolved Vulnerabilities"
        }, 
        {
            "location": "/releases/#known-issues-workarounds", 
            "text": "The fabric-ccenv image which is used to build chaincode, currently\nincludes the github.com/hyperledger/fabric/core/chaincode/shim\n(\\\"shim\\\") package. This is convenient, as it provides the ability to\npackage chaincode without the need to include the \\\"shim\\\". However,\nthis may cause issues in future releases (and/or when trying to use\npackages which are included by the \\\"shim\\\").  In order to avoid any issues, users are advised to manually vendor the\n\\\"shim\\\" package with their chaincode prior to using the peer CLI for\npackaging and/or for installing chaincode.  Please refer to  FAB-5177 \nfor more details, and kindly be aware that given the above, we may end\nup changing the fabric-ccenv in the future.  Change\nLog  v1.0.4 \nOctober 31, 2017  Bug fixes, documentation and test coverage improvements, UX improvements\nbased on user feedback and changes to address a variety of static scan\nfindings (unused code, static security scanning, spelling, linting and\nmore).", 
            "title": "Known Issues &amp; Workarounds"
        }, 
        {
            "location": "/releases/#known-vulnerabilities_1", 
            "text": "none", 
            "title": "Known Vulnerabilities"
        }, 
        {
            "location": "/releases/#resolved-vulnerabilities_1", 
            "text": "none", 
            "title": "Resolved Vulnerabilities"
        }, 
        {
            "location": "/releases/#known-issues-workarounds_1", 
            "text": "The fabric-ccenv image which is used to build chaincode, currently\nincludes the github.com/hyperledger/fabric/core/chaincode/shim\n(\\\"shim\\\") package. This is convenient, as it provides the ability to\npackage chaincode without the need to include the \\\"shim\\\". However,\nthis may cause issues in future releases (and/or when trying to use\npackages which are included by the \\\"shim\\\").  In order to avoid any issues, users are advised to manually vendor the\n\\\"shim\\\" package with their chaincode prior to using the peer CLI for\npackaging and/or for installing chaincode.  Please refer to  https://jira.hyperledger.org/browse/FAB-5177  for more\ndetails, and kindly be aware that given the above, we may end up\nchanging the fabric-ccenv in the future.  Change\nLog  v1.0.3 \nOctober 3, 2017  Bug fixes, documentation and test coverage improvements, UX improvements\nbased on user feedback and changes to address a variety of static scan\nfindings (unused code, static security scanning, spelling, linting and\nmore).  Known Vulnerabilities none  Resolved Vulnerabilities none  Known Issues   Workarounds The fabric-ccenv image which is used to build\nchaincode, currently includes the\ngithub.com/hyperledger/fabric/core/chaincode/shim (\\\"shim\\\") package.\nThis is convenient, as it provides the ability to package chaincode\nwithout the need to include the \\\"shim\\\". However, this may cause issues\nin future releases (and/or when trying to use packages which are\nincluded by the \\\"shim\\\").  In order to avoid any issues, users are advised to manually vendor the\n\\\"shim\\\" package with their chaincode prior to using the peer CLI for\npackaging and/or for installing chaincode.  Please refer to  https://jira.hyperledger.org/browse/FAB-5177  for more\ndetails, and kindly be aware that given the above, we may end up\nchanging the fabric-ccenv in the future.  Change\nLog  v1.0.2 \nAugust 31, 2017  Bug fixes, documentation and test coverage improvements, UX improvements\nbased on user feedback and changes to address a variety of static scan\nfindings (unused code, static security scanning, spelling, linting and\nmore).  Known Vulnerabilities none  Resolved Vulnerabilities  https://jira.hyperledger.org/browse/FAB-5753  https://jira.hyperledger.org/browse/FAB-5899  Known Issues   Workarounds The fabric-ccenv image which is used to build\nchaincode, currently includes the\ngithub.com/hyperledger/fabric/core/chaincode/shim (\\\"shim\\\") package.\nThis is convenient, as it provides the ability to package chaincode\nwithout the need to include the \\\"shim\\\". However, this may cause issues\nin future releases (and/or when trying to use packages which are\nincluded by the \\\"shim\\\").  In order to avoid any issues, users are advised to manually vendor the\n\\\"shim\\\" package with their chaincode prior to using the peer CLI for\npackaging and/or for installing chaincode.  Please refer to  https://jira.hyperledger.org/browse/FAB-5177  for more\ndetails, and kindly be aware that given the above, we may end up\nchanging the fabric-ccenv in the future.  Change\nLog  v1.0.1 \nAugust 5, 2017  Bug fixes, documentation and test coverage improvements, UX improvements\nbased on user feedback and changes to address a variety of static scan\nfindings (unused code, static security scanning, spelling, linting and\nmore).  Known Vulnerabilities none  Resolved Vulnerabilities  https://jira.hyperledger.org/browse/FAB-5329  https://jira.hyperledger.org/browse/FAB-5330  https://jira.hyperledger.org/browse/FAB-5353  https://jira.hyperledger.org/browse/FAB-5529  https://jira.hyperledger.org/browse/FAB-5606  https://jira.hyperledger.org/browse/FAB-5627  Known Issues   Workarounds The fabric-ccenv image which is used to build\nchaincode, currently includes the\ngithub.com/hyperledger/fabric/core/chaincode/shim (\\\"shim\\\") package.\nThis is convenient, as it provides the ability to package chaincode\nwithout the need to include the \\\"shim\\\". However, this may cause issues\nin future releases (and/or when trying to use packages which are\nincluded by the \\\"shim\\\").  In order to avoid any issues, users are advised to manually vendor the\n\\\"shim\\\" package with their chaincode prior to using the peer CLI for\npackaging and/or for installing chaincode.  Please refer to  https://jira.hyperledger.org/browse/FAB-5177  for more\ndetails, and kindly be aware that given the above, we may end up\nchanging the fabric-ccenv in the future.  Change\nLog  v1.0.0  July\n11, 2017  Bug fixes, documentation and test coverage improvements, UX improvements\nbased on user feedback and changes to address a variety of static scan\nfindings (removal of unused code, static security scanning, spelling,\nlinting and more).  Known Vulnerabilities none  Resolved Vulnerabilities  https://jira.hyperledger.org/browse/FAB-5207  Known Issues   Workarounds The fabric-ccenv image which is used to build\nchaincode, currently includes the\ngithub.com/hyperledger/fabric/core/chaincode/shim (\\\"shim\\\") package.\nThis is convenient, as it provides the ability to package chaincode\nwithout the need to include the \\\"shim\\\". However, this may cause issues\nin future releases (and/or when trying to use packages which are\nincluded by the \\\"shim\\\").  In order to avoid any issues, users are advised to manually vendor the\n\\\"shim\\\" package with their chaincode prior to using the peer CLI for\npackaging and/or for installing chaincode.  Please refer to  https://jira.hyperledger.org/browse/FAB-5177  for more\ndetails, and kindly be aware that given the above, we may end up\nchanging the fabric-ccenv in the future.  Change\nLog  v1.0.0-rc1 \nJune 23, 2017  Bug fixes, documentation and test coverage improvements, UX improvements\nbased on user feedback and changes to address a variety of static scan\nfindings (unused code, static security scanning, spelling, linting and\nmore).  Known Vulnerabilities none  Resolved Vulnerabilities  https://jira.hyperledger.org/browse/FAB-4856  https://jira.hyperledger.org/browse/FAB-4848  https://jira.hyperledger.org/browse/FAB-4751  https://jira.hyperledger.org/browse/FAB-4626  https://jira.hyperledger.org/browse/FAB-4567  https://jira.hyperledger.org/browse/FAB-3715  Known Issues   Workarounds none  Change\nLog  v1.0.0-beta \nJune 8, 2017  Bug fixes, documentation and test coverage improvements, UX improvements\nbased on user feedback and changes to address a variety of static scan\nfindings (unused code, static security scanning, spelling, linting and\nmore).  Upgraded to  latest version \n(a precursor to 1.4.0) of gRPC-go and implemented keep-alive feature for\nimproved resiliency.  Added a  new\ntool \nconfigtxlator to enable users to translate the contents of a channel\nconfiguration transaction into a human readable form.  Known Vulnerabilities  none  Resolved Vulnerabilities  none  Known Issues   Workarounds  BCCSP content in the configtx.yaml has been removed . This\nchange will cause a panic when running configtxgen tool with a\nconfigtx.yaml file that includes the removed BCCSP content.  Java Chaincode support has been disabled until post 1.0.0 as it is not\nyet fully mature. It may be re-enabled for experimentation by cloning\nthe hyperledger/fabric repository, reversing  this\ncommit  and\nbuilding your own fork.  Change\nLog  v1.0.0-alpha2  The second alpha release of the v1.0.0 Hyperledger Fabric. The code is\nnow feature complete. From now until the v1.0.0 release, the community\nis focused on documentation improvements, testing, hardening, bug fixing\nand tooling. We will be releasing successive release candidates\nperiodically as the release firms up.  Change\nLog  v1.0.0-alpha \nMarch 16, 2017  The first alpha release of the v1.0.0 Hyperledger Fabric. The code is\nbeing made available to developers to begin exploring the v1.0\narchitecture.  Change\nLog  v0.6-preview \nSeptember 16, 2016  A developer preview release of the Hyperledger Fabric intended to\nexercise the release logistics and stabilize a set of capabilities for\ndevelopers to try out. This will be the last release under the original\narchitecture. All subsequent releases will deliver on the v1.0\narchitecture.  Change\nLog  v0.5-developer-preview \nJune 17, 2016  A developer preview release of the Hyperledger Fabric intended to\nexercise the release logistics and stabilize a set of capabilities for\ndevelopers to try out.  Key features:  Permissioned blockchain with immediate finality Chaincode (aka smart\ncontract) execution environments Docker container (user chaincode)\nIn-process with peer (system chaincode) Pluggable consensus with PBFT,\nNOOPS (development mode), SIEVE (prototype) Event framework supports\npre-defined and custom events Client SDK (Node.js), basic REST APIs and\nCLIs Known Key Bugs and work in progress   1895 - Client SDK interfaces may crash if wrong parameter specified  1901 - Slow response after a few hours of stress testing  1911 - Missing peer event listener on the client SDK  889 - The attributes in the TCert are not encrypted. This work is\n    still on-going", 
            "title": "Known Issues &amp; Workarounds"
        }, 
        {
            "location": "/questions/", 
            "text": "Still Have Questions?\n\n\nWe try to maintain a comprehensive set of documentation for various\naudiences. However, we realize that often there are questions that\nremain unanswered. For any technical questions relating to Hyperledger\nFabric not answered here, please use\n\nStackOverflow\n.\nAnother approach to getting your questions answered to send an email to\nthe \nmailing\nlist\n\n(\n), or ask your questions on\n\nRocketChat\n (an alternative to Slack) on\nthe #fabric or #fabric-questions channel.\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nPlease, when asking about problems you are facing tell us\n\n\n:   about the environment in which you are experiencing those problems\n    including the OS, which version of Docker you are using, etc.\n:::", 
            "title": "General Help"
        }, 
        {
            "location": "/questions/#still-have-questions", 
            "text": "We try to maintain a comprehensive set of documentation for various\naudiences. However, we realize that often there are questions that\nremain unanswered. For any technical questions relating to Hyperledger\nFabric not answered here, please use StackOverflow .\nAnother approach to getting your questions answered to send an email to\nthe  mailing\nlist \n( ), or ask your questions on RocketChat  (an alternative to Slack) on\nthe #fabric or #fabric-questions channel.  ::: {.note}\n::: {.admonition-title}\nNote\n:::  Please, when asking about problems you are facing tell us  :   about the environment in which you are experiencing those problems\n    including the OS, which version of Docker you are using, etc.\n:::", 
            "title": "Still Have Questions?"
        }, 
        {
            "location": "/CONTRIBUTING/", 
            "text": "Contributions Welcome!\n\n\nWe welcome contributions to Hyperledger in many forms, and there\\'s\nalways plenty to do!\n\n\nFirst things first, please review the Hyperledger \nCode of\nConduct\n\nbefore participating. It is important that we keep things civil.\n\n\nInstall prerequisites\n\n\nBefore we begin, if you haven\\'t already done so, you may wish to check\nthat you have all the [prerequisites \\\nprereqs>]{role=\"doc\"} installed\non the platform(s) on which you\\'ll be developing blockchain\napplications and/or operating Hyperledger Fabric.\n\n\nGetting a Linux Foundation account\n\n\nIn order to participate in the development of the Hyperledger Fabric\nproject, you will need a [Linux Foundation\naccount \\\nGerrit/lf-account>]{role=\"doc\"}. You will need to use your LF\nID to access to all the Hyperledger community development tools,\nincluding \nGerrit\n,\n\nJira\n and the\n\nWiki\n (for editing, only).\n\n\nGetting help\n\n\nIf you are looking for something to work on, or need some expert\nassistance in debugging a problem or working out a fix to an issue, our\n\ncommunity\n is always eager to\nhelp. We hang out on\n\nChat\n, IRC (#hyperledger\non freenode.net) and the \nmailing lists\n.\nMost of us don\\'t bite :grin: and will be glad to help. The only silly\nquestion is the one you don\\'t ask. Questions are in fact a great way to\nhelp improve the project as they highlight where our documentation could\nbe clearer.\n\n\nReporting bugs\n\n\nIf you are a user and you have found a bug, please submit an issue using\n\nJIRA\n.\nBefore you create a new JIRA issue, please try to search the existing\nitems to be sure no one else has previously reported it. If it has been\npreviously reported, then you might add a comment that you also are\ninterested in seeing the defect fixed.\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nIf the defect is security-related, please follow the Hyperledger\n\n\n:   security bug reporting process \\\nhttps://wiki.hyperledger.org/security/bug-handling-process>.\n:::\n\n\nIf it has not been previously reported, create a new JIRA. Please try to\nprovide sufficient information for someone else to reproduce the issue.\nOne of the project\\'s maintainers should respond to your issue within 24\nhours. If not, please bump the issue with a comment and request that it\nbe reviewed. You can also post to the relevant fabric channel in\n\nHyperledger Rocket Chat\n. For example, a\ndoc bug should be broadcast to \n#fabric-documentation\n, a database bug\nto \n#fabric-ledger\n, and so on...\n\n\nSubmitting your fix\n\n\nIf you just submitted a JIRA for a bug you\\'ve discovered, and would\nlike to provide a fix, we would welcome that gladly! Please assign the\nJIRA issue to yourself, then you can submit a change request (CR).\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nIf you need help with submitting your first CR, we have created a\n\n\n:   brief [tutorial \\\nsubmit_cr>]{role=\"doc\"} for you.\n:::\n\n\nFixing issues and working stories\n\n\nReview the \nissues\nlist\n and find\nsomething that interests you. You could also check the\n\n\\\"help-wanted\\\"\n\nlist. It is wise to start with something relatively straight forward and\nachievable, and that no one is already assigned. If no one is assigned,\nthen assign the issue to yourself. Please be considerate and rescind the\nassignment if you cannot finish in a reasonable time, or add a comment\nsaying that you are still actively working the issue if you need a\nlittle more time.\n\n\nMaking Feature/Enhancement Proposals\n\n\nReview\n\nJIRA\n.\nto be sure that there isn\\'t already an open (or recently closed)\nproposal for the same function. If there isn\\'t, to make a proposal we\nrecommend that you open a JIRA Epic, Story or Improvement, whichever\nseems to best fit the circumstance and link or inline a \\\"one pager\\\" of\nthe proposal that states what the feature would do and, if possible, how\nit might be implemented. It would help also to make a case for why the\nfeature should be added, such as identifying specific use case(s) for\nwhich the feature is needed and a case for what the benefit would be\nshould the feature be implemented. Once the JIRA issue is created, and\nthe \\\"one pager\\\" either attached, inlined in the description field, or\na link to a publicly accessible document is added to the description,\nsend an introductory email to the\n\n mailing list linking the JIRA\nissue, and soliciting feedback.\n\n\nDiscussion of the proposed feature should be conducted in the JIRA issue\nitself, so that we have a consistent pattern within our community as to\nwhere to find design discussion.\n\n\nGetting the support of three or more of the Hyperledger Fabric\nmaintainers for the new feature will greatly enhance the probability\nthat the feature\\'s related CRs will be merged.\n\n\nSetting up development environment\n\n\nNext, try [building the project \\\ndev-setup/build>]{role=\"doc\"} in your\nlocal development environment to ensure that everything is set up\ncorrectly.\n\n\nWhat makes a good change request?\n\n\n\n\nOne change at a time. Not five, not three, not ten. One and only\n    one. Why? Because it limits the blast area of the change. If we have\n    a regression, it is much easier to identify the culprit commit than\n    if we have some composite change that impacts more of the code.\n\n\nInclude a link to the JIRA story for the change. Why? Because a) we\n    want to track our velocity to better judge what we think we can\n    deliver and when and b) because we can justify the change more\n    effectively. In many cases, there should be some discussion around a\n    proposed change and we want to link back to that from the change\n    itself.\n\n\nInclude unit and integration tests (or changes to existing tests)\n    with every change. This does not mean just happy path testing,\n    either. It also means negative testing of any defensive code that it\n    correctly catches input errors. When you write code, you are\n    responsible to test it and provide the tests that demonstrate that\n    your change does what it claims. Why? Because without this we have\n    no clue whether our current code base actually works.\n\n\nUnit tests should have NO external dependencies. You should be able\n    to run unit tests in place with \ngo test\n or equivalent for the\n    language. Any test that requires some external dependency (e.g.\n    needs to be scripted to run another component) needs appropriate\n    mocking. Anything else is not unit testing, it is integration\n    testing by definition. Why? Because many open source developers do\n    Test Driven Development. They place a watch on the directory that\n    invokes the tests automagically as the code is changed. This is far\n    more efficient than having to run a whole build between code\n    changes. See \nthis\n    definition\n\n    of unit testing for a good set of criteria to keep in mind for\n    writing effective unit tests.\n\n\nMinimize the lines of code per CR. Why? Maintainers have day jobs,\n    too. If you send a 1,000 or 2,000 LOC change, how long do you think\n    it takes to review all of that code? Keep your changes to \\\n 200-300\n    LOC, if possible. If you have a larger change, decompose it into\n    multiple independent changess. If you are adding a bunch of new\n    functions to fulfill the requirements of a new capability, add them\n    separately with their tests, and then write the code that uses them\n    to deliver the capability. Of course, there are always exceptions.\n    If you add a small change and then add 300 LOC of tests, you will be\n    forgiven;-) If you need to make a change that has broad impact or a\n    bunch of generated code (protobufs, etc.). Again, there can be\n    exceptions.\n\n\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nLarge change requests, e.g. those with more than 300 LOC are more likely\n\n\n:   than not going to receive a -2, and you\\'ll be asked to refactor the\n    change to conform with this guidance.\n:::\n\n\n\n\nDo not stack change requests (e.g. submit a CR from the same local\n    branch as your previous CR) unless they are related. This will\n    minimize merge conflicts and allow changes to be merged more\n    quickly. If you stack requests your subsequent requests may be held\n    up because of review comments in the preceding requests.\n\n\nWrite a meaningful commit message. Include a meaningful 50 (or less)\n    character title, followed by a blank line, followed by a more\n    comprehensive description of the change. Each change MUST include\n    the JIRA identifier corresponding to the change (e.g. [FAB-1234]).\n    This can be in the title but should also be in the body of the\n    commit message. See the\n    [complete requirements \\\nGerrit/changes>]{role=\"doc\"} for an\n    acceptable change request.\n\n\n\n\n::: {.note}\n::: {.admonition-title}\nNote\n:::\n\n\nThat Gerrit will automatically create a hyperlink to the JIRA item.\n\n\n:   e.g.\n\n\n\n\n\n[FAB-1234] fix foobar() panic\n\nFix [FAB-1234] added a check to ensure that when foobar(foo string)\nis called, that there is a non-empty string argument.\n\n\n\n:::\n\n\nFinally, be responsive. Don\\'t let a change request fester with review\ncomments such that it gets to a point that it requires a rebase. It only\nfurther delays getting it merged and adds more work for you - to\nremediate the merge conflicts.\n\n\nCommunication\n\n\nWe use \nRocketChat\n for communication and\nGoogle Hangouts\u2122 for screen sharing between developers. Our development\nplanning and prioritization is done in\n\nJIRA\n, and we take longer running\ndiscussions/decisions to the \nmailing\nlist\n.\n\n\nMaintainers\n\n\nThe project\\'s [maintainers \\\nMAINTAINERS>]{role=\"doc\"} are responsible\nfor reviewing and merging all patches submitted for review and they\nguide the over-all technical direction of the project within the\nguidelines established by the Hyperledger Technical Steering Committee\n(TSC).\n\n\nBecoming a maintainer\n\n\nThis project is managed under an open governance model as described in\nour \ncharter\n. Projects or\nsub-projects will be lead by a set of maintainers. New sub-projects can\ndesignate an initial set of maintainers that will be approved by the\ntop-level project\\'s existing maintainers when the project is first\napproved. The project\\'s maintainers will, from time-to-time, consider\nadding or removing a maintainer. An existing maintainer can submit a\nchange set to the [MAINTAINERS.rst \\\nMAINTAINERS>]{role=\"doc\"} file. A\nnominated Contributor may become a Maintainer by a majority approval of\nthe proposal by the existing Maintainers. Once approved, the change set\nis then merged and the individual is added to (or alternatively, removed\nfrom) the maintainers group. Maintainers may be removed by explicit\nresignation, for prolonged inactivity (3 or more months), or for some\ninfraction of the \ncode of\nconduct\n\nor by consistently demonstrating poor judgement. A maintainer removed\nfor inactivity should be restored following a sustained resumption of\ncontributions and reviews (a month or more) demonstrating a renewed\ncommitment to the project.\n\n\nLegal stuff\n\n\nNote:\n Each source file must include a license header for the Apache\nSoftware License 2.0. See the template of the \nlicense\nheader\n.\n\n\nWe have tried to make it as easy as possible to make contributions. This\napplies to how we handle the legal aspects of contribution. We use the\nsame approach---the \nDeveloper\\'s Certificate of Origin 1.1\n(DCO)\n---that\nthe Linux\u00ae Kernel\n\ncommunity\n uses to\nmanage code contributions.\n\n\nWe simply ask that when submitting a patch for review, the developer\nmust include a sign-off statement in the commit message.\n\n\nHere is an example Signed-off-by line, which indicates that the\nsubmitter accepts the DCO:\n\n\nSigned-off-by: John Doe \njohn.doe@hisdomain.com\n\n\n\n\nYou can include this automatically when you commit a change to your\nlocal git repository using \ngit commit -s\n.", 
            "title": "Contributing"
        }, 
        {
            "location": "/CONTRIBUTING/#contributions-welcome", 
            "text": "We welcome contributions to Hyperledger in many forms, and there\\'s\nalways plenty to do!  First things first, please review the Hyperledger  Code of\nConduct \nbefore participating. It is important that we keep things civil.", 
            "title": "Contributions Welcome!"
        }, 
        {
            "location": "/CONTRIBUTING/#install-prerequisites", 
            "text": "Before we begin, if you haven\\'t already done so, you may wish to check\nthat you have all the [prerequisites \\ prereqs>]{role=\"doc\"} installed\non the platform(s) on which you\\'ll be developing blockchain\napplications and/or operating Hyperledger Fabric.", 
            "title": "Install prerequisites"
        }, 
        {
            "location": "/CONTRIBUTING/#getting-a-linux-foundation-account", 
            "text": "In order to participate in the development of the Hyperledger Fabric\nproject, you will need a [Linux Foundation\naccount \\ Gerrit/lf-account>]{role=\"doc\"}. You will need to use your LF\nID to access to all the Hyperledger community development tools,\nincluding  Gerrit , Jira  and the Wiki  (for editing, only).", 
            "title": "Getting a Linux Foundation account"
        }, 
        {
            "location": "/CONTRIBUTING/#getting-help", 
            "text": "If you are looking for something to work on, or need some expert\nassistance in debugging a problem or working out a fix to an issue, our community  is always eager to\nhelp. We hang out on Chat , IRC (#hyperledger\non freenode.net) and the  mailing lists .\nMost of us don\\'t bite :grin: and will be glad to help. The only silly\nquestion is the one you don\\'t ask. Questions are in fact a great way to\nhelp improve the project as they highlight where our documentation could\nbe clearer.", 
            "title": "Getting help"
        }, 
        {
            "location": "/CONTRIBUTING/#reporting-bugs", 
            "text": "If you are a user and you have found a bug, please submit an issue using JIRA .\nBefore you create a new JIRA issue, please try to search the existing\nitems to be sure no one else has previously reported it. If it has been\npreviously reported, then you might add a comment that you also are\ninterested in seeing the defect fixed.  ::: {.note}\n::: {.admonition-title}\nNote\n:::  If the defect is security-related, please follow the Hyperledger  :   security bug reporting process \\ https://wiki.hyperledger.org/security/bug-handling-process>.\n:::  If it has not been previously reported, create a new JIRA. Please try to\nprovide sufficient information for someone else to reproduce the issue.\nOne of the project\\'s maintainers should respond to your issue within 24\nhours. If not, please bump the issue with a comment and request that it\nbe reviewed. You can also post to the relevant fabric channel in Hyperledger Rocket Chat . For example, a\ndoc bug should be broadcast to  #fabric-documentation , a database bug\nto  #fabric-ledger , and so on...", 
            "title": "Reporting bugs"
        }, 
        {
            "location": "/CONTRIBUTING/#submitting-your-fix", 
            "text": "If you just submitted a JIRA for a bug you\\'ve discovered, and would\nlike to provide a fix, we would welcome that gladly! Please assign the\nJIRA issue to yourself, then you can submit a change request (CR).  ::: {.note}\n::: {.admonition-title}\nNote\n:::  If you need help with submitting your first CR, we have created a  :   brief [tutorial \\ submit_cr>]{role=\"doc\"} for you.\n:::", 
            "title": "Submitting your fix"
        }, 
        {
            "location": "/CONTRIBUTING/#fixing-issues-and-working-stories", 
            "text": "Review the  issues\nlist  and find\nsomething that interests you. You could also check the \\\"help-wanted\\\" \nlist. It is wise to start with something relatively straight forward and\nachievable, and that no one is already assigned. If no one is assigned,\nthen assign the issue to yourself. Please be considerate and rescind the\nassignment if you cannot finish in a reasonable time, or add a comment\nsaying that you are still actively working the issue if you need a\nlittle more time.", 
            "title": "Fixing issues and working stories"
        }, 
        {
            "location": "/CONTRIBUTING/#making-featureenhancement-proposals", 
            "text": "Review JIRA .\nto be sure that there isn\\'t already an open (or recently closed)\nproposal for the same function. If there isn\\'t, to make a proposal we\nrecommend that you open a JIRA Epic, Story or Improvement, whichever\nseems to best fit the circumstance and link or inline a \\\"one pager\\\" of\nthe proposal that states what the feature would do and, if possible, how\nit might be implemented. It would help also to make a case for why the\nfeature should be added, such as identifying specific use case(s) for\nwhich the feature is needed and a case for what the benefit would be\nshould the feature be implemented. Once the JIRA issue is created, and\nthe \\\"one pager\\\" either attached, inlined in the description field, or\na link to a publicly accessible document is added to the description,\nsend an introductory email to the  mailing list linking the JIRA\nissue, and soliciting feedback.  Discussion of the proposed feature should be conducted in the JIRA issue\nitself, so that we have a consistent pattern within our community as to\nwhere to find design discussion.  Getting the support of three or more of the Hyperledger Fabric\nmaintainers for the new feature will greatly enhance the probability\nthat the feature\\'s related CRs will be merged.", 
            "title": "Making Feature/Enhancement Proposals"
        }, 
        {
            "location": "/CONTRIBUTING/#setting-up-development-environment", 
            "text": "Next, try [building the project \\ dev-setup/build>]{role=\"doc\"} in your\nlocal development environment to ensure that everything is set up\ncorrectly.", 
            "title": "Setting up development environment"
        }, 
        {
            "location": "/CONTRIBUTING/#what-makes-a-good-change-request", 
            "text": "One change at a time. Not five, not three, not ten. One and only\n    one. Why? Because it limits the blast area of the change. If we have\n    a regression, it is much easier to identify the culprit commit than\n    if we have some composite change that impacts more of the code.  Include a link to the JIRA story for the change. Why? Because a) we\n    want to track our velocity to better judge what we think we can\n    deliver and when and b) because we can justify the change more\n    effectively. In many cases, there should be some discussion around a\n    proposed change and we want to link back to that from the change\n    itself.  Include unit and integration tests (or changes to existing tests)\n    with every change. This does not mean just happy path testing,\n    either. It also means negative testing of any defensive code that it\n    correctly catches input errors. When you write code, you are\n    responsible to test it and provide the tests that demonstrate that\n    your change does what it claims. Why? Because without this we have\n    no clue whether our current code base actually works.  Unit tests should have NO external dependencies. You should be able\n    to run unit tests in place with  go test  or equivalent for the\n    language. Any test that requires some external dependency (e.g.\n    needs to be scripted to run another component) needs appropriate\n    mocking. Anything else is not unit testing, it is integration\n    testing by definition. Why? Because many open source developers do\n    Test Driven Development. They place a watch on the directory that\n    invokes the tests automagically as the code is changed. This is far\n    more efficient than having to run a whole build between code\n    changes. See  this\n    definition \n    of unit testing for a good set of criteria to keep in mind for\n    writing effective unit tests.  Minimize the lines of code per CR. Why? Maintainers have day jobs,\n    too. If you send a 1,000 or 2,000 LOC change, how long do you think\n    it takes to review all of that code? Keep your changes to \\  200-300\n    LOC, if possible. If you have a larger change, decompose it into\n    multiple independent changess. If you are adding a bunch of new\n    functions to fulfill the requirements of a new capability, add them\n    separately with their tests, and then write the code that uses them\n    to deliver the capability. Of course, there are always exceptions.\n    If you add a small change and then add 300 LOC of tests, you will be\n    forgiven;-) If you need to make a change that has broad impact or a\n    bunch of generated code (protobufs, etc.). Again, there can be\n    exceptions.   ::: {.note}\n::: {.admonition-title}\nNote\n:::  Large change requests, e.g. those with more than 300 LOC are more likely  :   than not going to receive a -2, and you\\'ll be asked to refactor the\n    change to conform with this guidance.\n:::   Do not stack change requests (e.g. submit a CR from the same local\n    branch as your previous CR) unless they are related. This will\n    minimize merge conflicts and allow changes to be merged more\n    quickly. If you stack requests your subsequent requests may be held\n    up because of review comments in the preceding requests.  Write a meaningful commit message. Include a meaningful 50 (or less)\n    character title, followed by a blank line, followed by a more\n    comprehensive description of the change. Each change MUST include\n    the JIRA identifier corresponding to the change (e.g. [FAB-1234]).\n    This can be in the title but should also be in the body of the\n    commit message. See the\n    [complete requirements \\ Gerrit/changes>]{role=\"doc\"} for an\n    acceptable change request.   ::: {.note}\n::: {.admonition-title}\nNote\n:::  That Gerrit will automatically create a hyperlink to the JIRA item.  :   e.g.   [FAB-1234] fix foobar() panic\n\nFix [FAB-1234] added a check to ensure that when foobar(foo string)\nis called, that there is a non-empty string argument.  :::  Finally, be responsive. Don\\'t let a change request fester with review\ncomments such that it gets to a point that it requires a rebase. It only\nfurther delays getting it merged and adds more work for you - to\nremediate the merge conflicts.", 
            "title": "What makes a good change request?"
        }, 
        {
            "location": "/CONTRIBUTING/#communication", 
            "text": "We use  RocketChat  for communication and\nGoogle Hangouts\u2122 for screen sharing between developers. Our development\nplanning and prioritization is done in JIRA , and we take longer running\ndiscussions/decisions to the  mailing\nlist .", 
            "title": "Communication"
        }, 
        {
            "location": "/CONTRIBUTING/#maintainers", 
            "text": "The project\\'s [maintainers \\ MAINTAINERS>]{role=\"doc\"} are responsible\nfor reviewing and merging all patches submitted for review and they\nguide the over-all technical direction of the project within the\nguidelines established by the Hyperledger Technical Steering Committee\n(TSC).", 
            "title": "Maintainers"
        }, 
        {
            "location": "/CONTRIBUTING/#becoming-a-maintainer", 
            "text": "This project is managed under an open governance model as described in\nour  charter . Projects or\nsub-projects will be lead by a set of maintainers. New sub-projects can\ndesignate an initial set of maintainers that will be approved by the\ntop-level project\\'s existing maintainers when the project is first\napproved. The project\\'s maintainers will, from time-to-time, consider\nadding or removing a maintainer. An existing maintainer can submit a\nchange set to the [MAINTAINERS.rst \\ MAINTAINERS>]{role=\"doc\"} file. A\nnominated Contributor may become a Maintainer by a majority approval of\nthe proposal by the existing Maintainers. Once approved, the change set\nis then merged and the individual is added to (or alternatively, removed\nfrom) the maintainers group. Maintainers may be removed by explicit\nresignation, for prolonged inactivity (3 or more months), or for some\ninfraction of the  code of\nconduct \nor by consistently demonstrating poor judgement. A maintainer removed\nfor inactivity should be restored following a sustained resumption of\ncontributions and reviews (a month or more) demonstrating a renewed\ncommitment to the project.", 
            "title": "Becoming a maintainer"
        }, 
        {
            "location": "/CONTRIBUTING/#legal-stuff", 
            "text": "Note:  Each source file must include a license header for the Apache\nSoftware License 2.0. See the template of the  license\nheader .  We have tried to make it as easy as possible to make contributions. This\napplies to how we handle the legal aspects of contribution. We use the\nsame approach---the  Developer\\'s Certificate of Origin 1.1\n(DCO) ---that\nthe Linux\u00ae Kernel community  uses to\nmanage code contributions.  We simply ask that when submitting a patch for review, the developer\nmust include a sign-off statement in the commit message.  Here is an example Signed-off-by line, which indicates that the\nsubmitter accepts the DCO:  Signed-off-by: John Doe  john.doe@hisdomain.com   You can include this automatically when you commit a change to your\nlocal git repository using  git commit -s .", 
            "title": "Legal stuff"
        }
    ]
}